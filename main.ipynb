{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Setup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading packages, setting up gpu, loading models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LukeKorthals\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# required packages\n",
    "from transformers import AutoProcessor, CLIPTextModel, CLIPVisionModel, PreTrainedModel\n",
    "import torch\n",
    "import torch_directml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from PIL import Image\n",
    "import glob\n",
    "import time\n",
    "from sklearn.metrics import euclidean_distances\n",
    "from sklearn.decomposition import IncrementalPCA, PCA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.spatial.distance import squareform\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.stats import pearsonr as corr\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "#from nilearn import datasets\n",
    "#from nilearn import plotting\n",
    "from typing import List, Dict, Tuple"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used an AMD RX 5700XT GPU and AMD Ryzen 5 3600XT CPU to run this code. To enable GPU support we relied on torch_directml == 0.1.13.1.dev230413.\n",
    "\n",
    "If you want to run this notebook on a cuda device, set AMD to False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup cuda device\n",
    "global device\n",
    "AMD = True\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if AMD:\n",
    "    device = torch_directml.device()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We downloaded pretrained CLIPModels and the CLIPProcessor from huggingface. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at openai/clip-vit-base-patch32 were not used when initializing CLIPVisionModel: ['text_model.encoder.layers.1.self_attn.q_proj.weight', 'text_model.encoder.layers.7.mlp.fc2.weight', 'text_model.encoder.layers.9.self_attn.v_proj.bias', 'text_model.encoder.layers.6.self_attn.k_proj.weight', 'text_model.encoder.layers.5.layer_norm2.weight', 'text_model.embeddings.position_ids', 'text_model.encoder.layers.10.mlp.fc2.weight', 'text_model.encoder.layers.6.self_attn.out_proj.bias', 'text_model.encoder.layers.11.layer_norm1.weight', 'text_model.encoder.layers.1.layer_norm1.weight', 'text_model.encoder.layers.7.layer_norm2.bias', 'text_model.encoder.layers.9.self_attn.q_proj.weight', 'text_model.encoder.layers.10.self_attn.v_proj.bias', 'text_projection.weight', 'text_model.encoder.layers.8.self_attn.q_proj.bias', 'text_model.encoder.layers.4.self_attn.out_proj.weight', 'text_model.encoder.layers.0.self_attn.q_proj.bias', 'text_model.encoder.layers.1.self_attn.q_proj.bias', 'text_model.embeddings.token_embedding.weight', 'text_model.encoder.layers.11.mlp.fc2.bias', 'text_model.encoder.layers.11.self_attn.k_proj.bias', 'text_model.encoder.layers.2.self_attn.k_proj.bias', 'text_model.encoder.layers.3.self_attn.out_proj.bias', 'text_model.encoder.layers.8.mlp.fc2.weight', 'text_model.encoder.layers.5.self_attn.v_proj.bias', 'text_model.encoder.layers.2.self_attn.v_proj.weight', 'text_model.encoder.layers.8.self_attn.k_proj.bias', 'text_model.encoder.layers.6.self_attn.v_proj.bias', 'text_model.encoder.layers.10.self_attn.out_proj.weight', 'text_model.encoder.layers.5.layer_norm2.bias', 'text_model.encoder.layers.0.self_attn.out_proj.weight', 'text_model.encoder.layers.5.self_attn.v_proj.weight', 'visual_projection.weight', 'text_model.encoder.layers.10.layer_norm1.weight', 'text_model.encoder.layers.5.mlp.fc1.bias', 'text_model.encoder.layers.9.self_attn.out_proj.weight', 'text_model.encoder.layers.1.mlp.fc1.bias', 'text_model.encoder.layers.5.self_attn.out_proj.bias', 'text_model.encoder.layers.9.self_attn.k_proj.weight', 'text_model.encoder.layers.9.self_attn.v_proj.weight', 'text_model.encoder.layers.7.self_attn.k_proj.bias', 'text_model.encoder.layers.7.layer_norm1.bias', 'text_model.encoder.layers.11.layer_norm2.weight', 'text_model.encoder.layers.7.mlp.fc1.bias', 'text_model.encoder.layers.10.layer_norm2.weight', 'text_model.encoder.layers.5.self_attn.q_proj.bias', 'text_model.encoder.layers.6.self_attn.q_proj.bias', 'text_model.encoder.layers.4.layer_norm1.weight', 'text_model.encoder.layers.4.self_attn.k_proj.weight', 'text_model.encoder.layers.8.self_attn.q_proj.weight', 'text_model.encoder.layers.8.self_attn.k_proj.weight', 'text_model.encoder.layers.6.self_attn.v_proj.weight', 'text_model.encoder.layers.2.self_attn.k_proj.weight', 'text_model.encoder.layers.1.self_attn.v_proj.weight', 'text_model.encoder.layers.3.self_attn.k_proj.bias', 'text_model.encoder.layers.3.self_attn.out_proj.weight', 'text_model.encoder.layers.5.self_attn.k_proj.weight', 'text_model.encoder.layers.8.layer_norm1.weight', 'text_model.encoder.layers.3.self_attn.v_proj.bias', 'text_model.encoder.layers.9.self_attn.k_proj.bias', 'text_model.encoder.layers.4.mlp.fc1.bias', 'text_model.encoder.layers.8.mlp.fc1.weight', 'text_model.encoder.layers.1.layer_norm1.bias', 'text_model.encoder.layers.4.self_attn.out_proj.bias', 'text_model.encoder.layers.11.self_attn.out_proj.bias', 'text_model.encoder.layers.11.self_attn.out_proj.weight', 'text_model.encoder.layers.9.self_attn.out_proj.bias', 'text_model.encoder.layers.0.self_attn.k_proj.bias', 'text_model.encoder.layers.11.mlp.fc2.weight', 'text_model.encoder.layers.11.self_attn.v_proj.bias', 'text_model.encoder.layers.4.self_attn.q_proj.bias', 'logit_scale', 'text_model.encoder.layers.7.mlp.fc2.bias', 'text_model.encoder.layers.9.mlp.fc1.weight', 'text_model.encoder.layers.6.layer_norm1.weight', 'text_model.encoder.layers.10.self_attn.q_proj.bias', 'text_model.encoder.layers.1.layer_norm2.weight', 'text_model.encoder.layers.0.self_attn.k_proj.weight', 'text_model.encoder.layers.1.self_attn.out_proj.bias', 'text_model.encoder.layers.0.layer_norm2.weight', 'text_model.encoder.layers.10.mlp.fc1.weight', 'text_model.encoder.layers.6.mlp.fc2.weight', 'text_model.encoder.layers.0.layer_norm1.bias', 'text_model.encoder.layers.0.mlp.fc2.bias', 'text_model.encoder.layers.6.mlp.fc2.bias', 'text_model.embeddings.position_embedding.weight', 'text_model.encoder.layers.6.mlp.fc1.bias', 'text_model.encoder.layers.6.self_attn.q_proj.weight', 'text_model.encoder.layers.3.layer_norm1.bias', 'text_model.encoder.layers.2.mlp.fc1.weight', 'text_model.encoder.layers.6.layer_norm2.weight', 'text_model.encoder.layers.7.self_attn.out_proj.bias', 'text_model.encoder.layers.8.layer_norm2.weight', 'text_model.encoder.layers.11.mlp.fc1.weight', 'text_model.encoder.layers.0.mlp.fc2.weight', 'text_model.encoder.layers.9.mlp.fc2.weight', 'text_model.encoder.layers.10.self_attn.q_proj.weight', 'text_model.encoder.layers.5.self_attn.out_proj.weight', 'text_model.encoder.layers.8.self_attn.out_proj.bias', 'text_model.encoder.layers.4.layer_norm2.bias', 'text_model.encoder.layers.1.self_attn.k_proj.weight', 'text_model.encoder.layers.5.mlp.fc2.weight', 'text_model.encoder.layers.1.layer_norm2.bias', 'text_model.encoder.layers.1.self_attn.k_proj.bias', 'text_model.encoder.layers.3.self_attn.q_proj.weight', 'text_model.encoder.layers.7.self_attn.q_proj.bias', 'text_model.encoder.layers.7.self_attn.v_proj.bias', 'text_model.encoder.layers.0.self_attn.q_proj.weight', 'text_model.encoder.layers.5.layer_norm1.weight', 'text_model.encoder.layers.10.mlp.fc2.bias', 'text_model.encoder.layers.1.self_attn.out_proj.weight', 'text_model.encoder.layers.2.self_attn.q_proj.weight', 'text_model.encoder.layers.5.layer_norm1.bias', 'text_model.encoder.layers.9.mlp.fc1.bias', 'text_model.encoder.layers.10.self_attn.k_proj.weight', 'text_model.encoder.layers.8.self_attn.v_proj.bias', 'text_model.encoder.layers.3.self_attn.v_proj.weight', 'text_model.encoder.layers.10.layer_norm1.bias', 'text_model.encoder.layers.6.self_attn.k_proj.bias', 'text_model.encoder.layers.0.layer_norm1.weight', 'text_model.encoder.layers.0.layer_norm2.bias', 'text_model.encoder.layers.3.layer_norm2.weight', 'text_model.encoder.layers.2.mlp.fc1.bias', 'text_model.encoder.layers.11.layer_norm1.bias', 'text_model.encoder.layers.2.mlp.fc2.bias', 'text_model.encoder.layers.5.mlp.fc2.bias', 'text_model.encoder.layers.6.layer_norm2.bias', 'text_model.encoder.layers.9.self_attn.q_proj.bias', 'text_model.encoder.layers.10.self_attn.v_proj.weight', 'text_model.encoder.layers.9.layer_norm2.weight', 'text_model.encoder.layers.7.self_attn.q_proj.weight', 'text_model.encoder.layers.3.mlp.fc1.bias', 'text_model.encoder.layers.2.self_attn.v_proj.bias', 'text_model.encoder.layers.1.self_attn.v_proj.bias', 'text_model.encoder.layers.8.layer_norm1.bias', 'text_model.encoder.layers.7.mlp.fc1.weight', 'text_model.encoder.layers.9.layer_norm1.weight', 'text_model.encoder.layers.3.mlp.fc2.bias', 'text_model.encoder.layers.9.layer_norm2.bias', 'text_model.encoder.layers.10.layer_norm2.bias', 'text_model.encoder.layers.3.layer_norm1.weight', 'text_model.encoder.layers.4.mlp.fc2.bias', 'text_model.encoder.layers.5.self_attn.q_proj.weight', 'text_model.encoder.layers.11.mlp.fc1.bias', 'text_model.final_layer_norm.weight', 'text_model.encoder.layers.3.layer_norm2.bias', 'text_model.encoder.layers.0.self_attn.out_proj.bias', 'text_model.encoder.layers.4.mlp.fc2.weight', 'text_model.encoder.layers.2.layer_norm2.weight', 'text_model.encoder.layers.2.self_attn.out_proj.weight', 'text_model.encoder.layers.3.self_attn.q_proj.bias', 'text_model.encoder.layers.8.layer_norm2.bias', 'text_model.encoder.layers.8.mlp.fc1.bias', 'text_model.encoder.layers.3.mlp.fc2.weight', 'text_model.encoder.layers.3.self_attn.k_proj.weight', 'text_model.encoder.layers.2.layer_norm1.weight', 'text_model.encoder.layers.3.mlp.fc1.weight', 'text_model.encoder.layers.2.mlp.fc2.weight', 'text_model.encoder.layers.9.mlp.fc2.bias', 'text_model.encoder.layers.2.self_attn.q_proj.bias', 'text_model.encoder.layers.11.self_attn.q_proj.bias', 'text_model.encoder.layers.11.layer_norm2.bias', 'text_model.encoder.layers.10.self_attn.k_proj.bias', 'text_model.encoder.layers.11.self_attn.q_proj.weight', 'text_model.encoder.layers.4.self_attn.v_proj.weight', 'text_model.encoder.layers.7.layer_norm1.weight', 'text_model.encoder.layers.0.self_attn.v_proj.bias', 'text_model.encoder.layers.11.self_attn.k_proj.weight', 'text_model.encoder.layers.10.self_attn.out_proj.bias', 'text_model.encoder.layers.5.mlp.fc1.weight', 'text_model.encoder.layers.8.self_attn.v_proj.weight', 'text_model.encoder.layers.1.mlp.fc1.weight', 'text_model.encoder.layers.2.self_attn.out_proj.bias', 'text_model.final_layer_norm.bias', 'text_model.encoder.layers.4.self_attn.k_proj.bias', 'text_model.encoder.layers.4.layer_norm2.weight', 'text_model.encoder.layers.2.layer_norm1.bias', 'text_model.encoder.layers.7.self_attn.out_proj.weight', 'text_model.encoder.layers.5.self_attn.k_proj.bias', 'text_model.encoder.layers.4.layer_norm1.bias', 'text_model.encoder.layers.6.layer_norm1.bias', 'text_model.encoder.layers.6.mlp.fc1.weight', 'text_model.encoder.layers.0.self_attn.v_proj.weight', 'text_model.encoder.layers.1.mlp.fc2.weight', 'text_model.encoder.layers.4.mlp.fc1.weight', 'text_model.encoder.layers.7.self_attn.v_proj.weight', 'text_model.encoder.layers.8.mlp.fc2.bias', 'text_model.encoder.layers.10.mlp.fc1.bias', 'text_model.encoder.layers.1.mlp.fc2.bias', 'text_model.encoder.layers.8.self_attn.out_proj.weight', 'text_model.encoder.layers.9.layer_norm1.bias', 'text_model.encoder.layers.2.layer_norm2.bias', 'text_model.encoder.layers.7.self_attn.k_proj.weight', 'text_model.encoder.layers.4.self_attn.v_proj.bias', 'text_model.encoder.layers.11.self_attn.v_proj.weight', 'text_model.encoder.layers.4.self_attn.q_proj.weight', 'text_model.encoder.layers.7.layer_norm2.weight', 'text_model.encoder.layers.6.self_attn.out_proj.weight', 'text_model.encoder.layers.0.mlp.fc1.bias', 'text_model.encoder.layers.0.mlp.fc1.weight']\n",
      "- This IS expected if you are initializing CLIPVisionModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CLIPVisionModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at openai/clip-vit-base-patch32 were not used when initializing CLIPTextModel: ['vision_model.encoder.layers.7.self_attn.k_proj.bias', 'vision_model.encoder.layers.8.layer_norm2.bias', 'vision_model.encoder.layers.1.layer_norm1.weight', 'vision_model.encoder.layers.7.mlp.fc1.bias', 'vision_model.encoder.layers.11.self_attn.k_proj.weight', 'vision_model.encoder.layers.2.self_attn.v_proj.bias', 'vision_model.encoder.layers.7.layer_norm2.bias', 'vision_model.encoder.layers.7.layer_norm2.weight', 'vision_model.encoder.layers.10.self_attn.q_proj.weight', 'vision_model.encoder.layers.0.mlp.fc1.bias', 'vision_model.encoder.layers.10.mlp.fc2.weight', 'vision_model.encoder.layers.8.self_attn.k_proj.bias', 'vision_model.encoder.layers.10.layer_norm1.weight', 'vision_model.encoder.layers.10.self_attn.q_proj.bias', 'vision_model.encoder.layers.7.self_attn.v_proj.weight', 'text_projection.weight', 'vision_model.encoder.layers.3.layer_norm2.weight', 'vision_model.encoder.layers.11.self_attn.q_proj.bias', 'vision_model.post_layernorm.bias', 'vision_model.encoder.layers.3.self_attn.out_proj.weight', 'vision_model.encoder.layers.5.layer_norm2.bias', 'vision_model.encoder.layers.8.layer_norm1.weight', 'vision_model.encoder.layers.10.self_attn.v_proj.weight', 'vision_model.encoder.layers.9.self_attn.out_proj.bias', 'vision_model.encoder.layers.11.self_attn.out_proj.weight', 'vision_model.encoder.layers.9.mlp.fc1.bias', 'vision_model.encoder.layers.2.layer_norm1.bias', 'visual_projection.weight', 'vision_model.encoder.layers.6.self_attn.out_proj.weight', 'vision_model.encoder.layers.9.self_attn.v_proj.weight', 'vision_model.encoder.layers.3.mlp.fc2.bias', 'vision_model.encoder.layers.8.layer_norm1.bias', 'vision_model.encoder.layers.6.self_attn.v_proj.bias', 'vision_model.encoder.layers.1.self_attn.v_proj.bias', 'vision_model.encoder.layers.10.layer_norm2.weight', 'vision_model.encoder.layers.3.layer_norm1.bias', 'vision_model.encoder.layers.8.self_attn.q_proj.weight', 'vision_model.encoder.layers.2.layer_norm2.weight', 'vision_model.encoder.layers.4.mlp.fc1.bias', 'vision_model.encoder.layers.11.mlp.fc1.weight', 'vision_model.encoder.layers.1.layer_norm2.bias', 'vision_model.encoder.layers.5.self_attn.k_proj.weight', 'vision_model.encoder.layers.8.self_attn.out_proj.bias', 'vision_model.encoder.layers.1.self_attn.q_proj.weight', 'vision_model.encoder.layers.5.self_attn.v_proj.bias', 'vision_model.encoder.layers.4.self_attn.v_proj.bias', 'vision_model.encoder.layers.10.mlp.fc2.bias', 'vision_model.encoder.layers.8.mlp.fc1.bias', 'vision_model.post_layernorm.weight', 'vision_model.encoder.layers.7.layer_norm1.weight', 'vision_model.encoder.layers.6.self_attn.out_proj.bias', 'vision_model.encoder.layers.4.self_attn.q_proj.bias', 'vision_model.encoder.layers.9.mlp.fc2.weight', 'vision_model.encoder.layers.8.self_attn.v_proj.bias', 'vision_model.encoder.layers.9.mlp.fc2.bias', 'vision_model.encoder.layers.8.self_attn.out_proj.weight', 'vision_model.encoder.layers.10.layer_norm1.bias', 'vision_model.encoder.layers.9.self_attn.out_proj.weight', 'vision_model.embeddings.position_ids', 'vision_model.encoder.layers.0.mlp.fc2.bias', 'vision_model.encoder.layers.9.mlp.fc1.weight', 'vision_model.encoder.layers.1.self_attn.q_proj.bias', 'vision_model.encoder.layers.0.layer_norm2.bias', 'vision_model.encoder.layers.4.self_attn.v_proj.weight', 'vision_model.encoder.layers.10.self_attn.k_proj.bias', 'vision_model.encoder.layers.4.layer_norm1.bias', 'vision_model.encoder.layers.9.layer_norm2.bias', 'vision_model.encoder.layers.11.mlp.fc2.bias', 'vision_model.encoder.layers.3.self_attn.q_proj.bias', 'vision_model.encoder.layers.4.self_attn.k_proj.bias', 'vision_model.encoder.layers.7.mlp.fc2.bias', 'vision_model.encoder.layers.4.layer_norm1.weight', 'vision_model.encoder.layers.9.self_attn.k_proj.weight', 'vision_model.encoder.layers.5.self_attn.v_proj.weight', 'vision_model.encoder.layers.3.self_attn.v_proj.weight', 'vision_model.encoder.layers.3.layer_norm1.weight', 'vision_model.encoder.layers.11.self_attn.q_proj.weight', 'logit_scale', 'vision_model.encoder.layers.0.self_attn.v_proj.weight', 'vision_model.encoder.layers.5.mlp.fc1.bias', 'vision_model.encoder.layers.7.self_attn.out_proj.weight', 'vision_model.encoder.layers.10.mlp.fc1.weight', 'vision_model.encoder.layers.3.mlp.fc1.weight', 'vision_model.encoder.layers.0.self_attn.out_proj.bias', 'vision_model.encoder.layers.0.mlp.fc2.weight', 'vision_model.encoder.layers.3.self_attn.v_proj.bias', 'vision_model.encoder.layers.1.self_attn.v_proj.weight', 'vision_model.encoder.layers.11.mlp.fc2.weight', 'vision_model.embeddings.patch_embedding.weight', 'vision_model.encoder.layers.0.self_attn.v_proj.bias', 'vision_model.encoder.layers.4.self_attn.q_proj.weight', 'vision_model.encoder.layers.1.mlp.fc1.bias', 'vision_model.encoder.layers.6.self_attn.q_proj.weight', 'vision_model.encoder.layers.0.self_attn.q_proj.weight', 'vision_model.encoder.layers.7.mlp.fc1.weight', 'vision_model.encoder.layers.9.self_attn.q_proj.weight', 'vision_model.encoder.layers.5.layer_norm1.weight', 'vision_model.encoder.layers.6.self_attn.v_proj.weight', 'vision_model.encoder.layers.1.layer_norm1.bias', 'vision_model.encoder.layers.5.self_attn.q_proj.bias', 'vision_model.encoder.layers.0.layer_norm1.bias', 'vision_model.encoder.layers.11.layer_norm1.weight', 'vision_model.encoder.layers.5.self_attn.out_proj.bias', 'vision_model.encoder.layers.2.self_attn.out_proj.weight', 'vision_model.encoder.layers.8.mlp.fc2.bias', 'vision_model.encoder.layers.0.mlp.fc1.weight', 'vision_model.encoder.layers.5.layer_norm2.weight', 'vision_model.encoder.layers.2.mlp.fc1.bias', 'vision_model.encoder.layers.5.layer_norm1.bias', 'vision_model.encoder.layers.0.self_attn.q_proj.bias', 'vision_model.encoder.layers.5.self_attn.q_proj.weight', 'vision_model.encoder.layers.11.self_attn.v_proj.bias', 'vision_model.encoder.layers.6.layer_norm2.weight', 'vision_model.encoder.layers.3.layer_norm2.bias', 'vision_model.encoder.layers.10.self_attn.out_proj.weight', 'vision_model.encoder.layers.6.layer_norm2.bias', 'vision_model.encoder.layers.3.self_attn.out_proj.bias', 'vision_model.encoder.layers.7.mlp.fc2.weight', 'vision_model.encoder.layers.2.self_attn.q_proj.bias', 'vision_model.encoder.layers.0.layer_norm1.weight', 'vision_model.encoder.layers.9.layer_norm2.weight', 'vision_model.encoder.layers.6.layer_norm1.bias', 'vision_model.encoder.layers.6.mlp.fc2.bias', 'vision_model.embeddings.position_embedding.weight', 'vision_model.encoder.layers.6.mlp.fc1.weight', 'vision_model.encoder.layers.3.self_attn.k_proj.bias', 'vision_model.encoder.layers.3.mlp.fc1.bias', 'vision_model.pre_layrnorm.bias', 'vision_model.encoder.layers.2.self_attn.v_proj.weight', 'vision_model.encoder.layers.10.layer_norm2.bias', 'vision_model.encoder.layers.2.mlp.fc2.weight', 'vision_model.encoder.layers.6.self_attn.k_proj.bias', 'vision_model.encoder.layers.5.mlp.fc2.bias', 'vision_model.encoder.layers.4.self_attn.out_proj.bias', 'vision_model.encoder.layers.6.self_attn.q_proj.bias', 'vision_model.encoder.layers.2.layer_norm2.bias', 'vision_model.encoder.layers.5.self_attn.k_proj.bias', 'vision_model.encoder.layers.1.mlp.fc2.weight', 'vision_model.encoder.layers.2.self_attn.k_proj.weight', 'vision_model.encoder.layers.9.self_attn.k_proj.bias', 'vision_model.encoder.layers.2.mlp.fc1.weight', 'vision_model.encoder.layers.0.self_attn.k_proj.bias', 'vision_model.encoder.layers.4.mlp.fc2.weight', 'vision_model.encoder.layers.10.self_attn.k_proj.weight', 'vision_model.encoder.layers.4.layer_norm2.weight', 'vision_model.encoder.layers.7.self_attn.v_proj.bias', 'vision_model.encoder.layers.7.self_attn.k_proj.weight', 'vision_model.encoder.layers.11.mlp.fc1.bias', 'vision_model.encoder.layers.9.self_attn.q_proj.bias', 'vision_model.encoder.layers.1.layer_norm2.weight', 'vision_model.encoder.layers.1.self_attn.k_proj.weight', 'vision_model.encoder.layers.7.layer_norm1.bias', 'vision_model.encoder.layers.8.self_attn.k_proj.weight', 'vision_model.encoder.layers.8.self_attn.v_proj.weight', 'vision_model.encoder.layers.11.layer_norm2.weight', 'vision_model.encoder.layers.7.self_attn.out_proj.bias', 'vision_model.encoder.layers.9.layer_norm1.bias', 'vision_model.encoder.layers.3.mlp.fc2.weight', 'vision_model.encoder.layers.8.mlp.fc1.weight', 'vision_model.encoder.layers.5.mlp.fc2.weight', 'vision_model.encoder.layers.6.layer_norm1.weight', 'vision_model.encoder.layers.11.self_attn.v_proj.weight', 'vision_model.encoder.layers.10.self_attn.v_proj.bias', 'vision_model.encoder.layers.4.self_attn.k_proj.weight', 'vision_model.encoder.layers.8.mlp.fc2.weight', 'vision_model.encoder.layers.1.self_attn.out_proj.weight', 'vision_model.encoder.layers.11.layer_norm2.bias', 'vision_model.encoder.layers.11.self_attn.out_proj.bias', 'vision_model.encoder.layers.2.self_attn.out_proj.bias', 'vision_model.encoder.layers.2.layer_norm1.weight', 'vision_model.pre_layrnorm.weight', 'vision_model.encoder.layers.9.self_attn.v_proj.bias', 'vision_model.encoder.layers.4.layer_norm2.bias', 'vision_model.encoder.layers.0.self_attn.out_proj.weight', 'vision_model.encoder.layers.10.mlp.fc1.bias', 'vision_model.encoder.layers.1.mlp.fc1.weight', 'vision_model.encoder.layers.2.self_attn.k_proj.bias', 'vision_model.encoder.layers.8.self_attn.q_proj.bias', 'vision_model.encoder.layers.4.self_attn.out_proj.weight', 'vision_model.encoder.layers.7.self_attn.q_proj.weight', 'vision_model.encoder.layers.11.self_attn.k_proj.bias', 'vision_model.encoder.layers.4.mlp.fc1.weight', 'vision_model.encoder.layers.7.self_attn.q_proj.bias', 'vision_model.encoder.layers.5.mlp.fc1.weight', 'vision_model.encoder.layers.1.self_attn.out_proj.bias', 'vision_model.encoder.layers.4.mlp.fc2.bias', 'vision_model.embeddings.class_embedding', 'vision_model.encoder.layers.0.layer_norm2.weight', 'vision_model.encoder.layers.6.self_attn.k_proj.weight', 'vision_model.encoder.layers.0.self_attn.k_proj.weight', 'vision_model.encoder.layers.1.self_attn.k_proj.bias', 'vision_model.encoder.layers.2.self_attn.q_proj.weight', 'vision_model.encoder.layers.10.self_attn.out_proj.bias', 'vision_model.encoder.layers.6.mlp.fc2.weight', 'vision_model.encoder.layers.3.self_attn.q_proj.weight', 'vision_model.encoder.layers.8.layer_norm2.weight', 'vision_model.encoder.layers.9.layer_norm1.weight', 'vision_model.encoder.layers.2.mlp.fc2.bias', 'vision_model.encoder.layers.6.mlp.fc1.bias', 'vision_model.encoder.layers.11.layer_norm1.bias', 'vision_model.encoder.layers.1.mlp.fc2.bias', 'vision_model.encoder.layers.3.self_attn.k_proj.weight', 'vision_model.encoder.layers.5.self_attn.out_proj.weight']\n",
      "- This IS expected if you are initializing CLIPTextModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CLIPTextModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CLIPTextModel(\n",
       "  (text_model): CLIPTextTransformer(\n",
       "    (embeddings): CLIPTextEmbeddings(\n",
       "      (token_embedding): Embedding(49408, 512)\n",
       "      (position_embedding): Embedding(77, 512)\n",
       "    )\n",
       "    (encoder): CLIPEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (6): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (7): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (8): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (9): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (10): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (11): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global vis_model, txt_model, processor\n",
    "vis_model = CLIPVisionModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "txt_model = CLIPTextModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "processor = AutoProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "vis_model.eval()\n",
    "txt_model.eval()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classes & Functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ImageDataset & TextDataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ImageDataset and TextDataset classes are used to create datasets for torch dataloaders.\n",
    "The ImageDataset is used for the images and the TextDataset for the captions of the coco images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Classes for Batching\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, image_list, processor):\n",
    "        self.image_list = image_list\n",
    "        self.processor = processor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.image_list[idx])\n",
    "        image = self.processor(images=image, return_tensors=\"pt\", padding=True)\n",
    "        return image[\"pixel_values\"].squeeze()\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, text, max_length, processor):\n",
    "        self.text = processor(text=text, return_tensors=\"pt\", padding=\"max_length\", max_length=max_length)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text[\"input_ids\"])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.text[\"input_ids\"][idx]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subject Class"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Subject class is initialized with a valid subject id (e.g., \"subj01\"). It stores all relevant paths and can load the data for the given subject."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Subject:\n",
    "    \"\"\"Class to access all relevant data for a given subject\"\"\"\n",
    "    def __init__(self, subject=\"subj01\"):\n",
    "        assert subject in [\"subj01\", \"subj02\", \"subj03\", \"subj04\", \"subj05\", \"subj06\", \"subj07\", \"subj08\",], \"Invalid subject\"\n",
    "        self.subject = subject\n",
    "        self.data_dir = \"data/algonauts_2023_challenge_data\"\n",
    "        self.training_images_dir = f\"{self.data_dir}/{subject}/training_split/training_images\"\n",
    "        self.test_images_dir = f\"{self.data_dir}/{subject}/test_split/test_images\"\n",
    "        self.training_fmri_dir = f\"{self.data_dir}/{subject}/training_split/training_fmri\"\n",
    "        self.roi_masks_dir = f\"{self.data_dir}/{subject}/roi_masks\"\n",
    "        self.submission_dir = f\"algonauts_2023_challenge_submission\"\n",
    "        # Load these as needed\n",
    "        self.train_img_list = None\n",
    "        self.test_img_list = None\n",
    "        self.train_cap_list = None\n",
    "        self.test_cap_list = None\n",
    "        self.lh_fmri = None\n",
    "        self.rh_fmri = None\n",
    "        self.lh_roi_masks = None\n",
    "        self.rh_roi_masks = None\n",
    "        self.roi_name_maps = None\n",
    "        self.lh_challenge_rois = None\n",
    "        self.rh_challenge_rois = None\n",
    "        self.train_img_dataloader = None\n",
    "        self.test_img_dataloader = None\n",
    "        self.train_cap_dataloader = None\n",
    "        self.test_cap_dataloader = None            \n",
    "        \n",
    "    def load_image_paths(self) -> None:\n",
    "        \"\"\"Loads the image paths from the training and test directories\"\"\"\n",
    "        self.train_img_list = glob.glob(f\"{self.training_images_dir}/*.png\")\n",
    "        self.train_img_list.sort()\n",
    "        self.test_img_list = glob.glob(f\"{self.test_images_dir}/*.png\")\n",
    "        self.test_img_list.sort()\n",
    "        print(f\"Training images: {len(self.train_img_list)}\")\n",
    "        print(f\"Test images: {len(self.test_img_list)}\")\n",
    "\n",
    "    def load_captions(self) -> None:\n",
    "        \"\"\"Loads and matches the captions from the csv file\"\"\"\n",
    "        if self.train_img_list is None:\n",
    "            self.load_image_paths()\n",
    "        train_cap_file = pd.read_csv(f'{self.data_dir}/algonauts_2023_caption_data.csv')\n",
    "        img_match = [int(i[-9:-4]) for i in self.train_img_list]\n",
    "        self.train_cap_list = train_cap_file[(train_cap_file['subject'] == self.subject) & (train_cap_file['nsdId'].isin(img_match))]['caption'].tolist()\n",
    "        self.test_cap_list = train_cap_file[(train_cap_file['subject'] == self.subject) & (~train_cap_file['nsdId'].isin(img_match))]['caption'].tolist()\n",
    "        print(f\"Training captions: {len(self.train_cap_list)}\")\n",
    "        print(f\"Test captions: {len(self.test_cap_list)}\")\n",
    "    \n",
    "    def load_neural_data(self) -> None:\n",
    "        \"\"\"Loads the neural data from the .npy files\"\"\"\n",
    "        self.lh_fmri = np.load(f\"{self.training_fmri_dir}/lh_training_fmri.npy\")\n",
    "        self.rh_fmri = np.load(f\"{self.training_fmri_dir}/rh_training_fmri.npy\")\n",
    "        print(f\"Left hemisphere neural data loaded. Shape: {self.lh_fmri.shape}\")\n",
    "        print(f\"Right hemisphere neural data loaded. Shape: {self.rh_fmri.shape}\")\n",
    "\n",
    "    def create_dataloaders(self, processor, batch_size) -> None:\n",
    "        \"\"\"Creates the dataloaders for the images and captions\"\"\"\n",
    "        if self.train_img_list is None:\n",
    "            self.load_image_paths()\n",
    "        if self.train_cap_list is None:\n",
    "            self.load_captions()\n",
    "        max_caption_len = processor(text=self.train_cap_list + self.test_cap_list, return_tensors=\"pt\", padding=True)[\"input_ids\"].shape[1]   \n",
    "        train_txt_dataset = TextDataset(self.train_cap_list, max_caption_len, processor)\n",
    "        test_txt_dataset = TextDataset(self.test_cap_list, max_caption_len, processor)\n",
    "        train_img_dataset = ImageDataset(self.train_img_list, processor)\n",
    "        test_img_dataset = ImageDataset(self.test_img_list, processor)\n",
    "        self.train_img_dataloader = DataLoader(train_img_dataset, batch_size=batch_size, shuffle=False)\n",
    "        self.test_img_dataloader = DataLoader(test_img_dataset, batch_size=batch_size, shuffle=False)\n",
    "        self.train_txt_dataloader = DataLoader(train_txt_dataset, batch_size=batch_size, shuffle=False)\n",
    "        self.test_txt_dataloader = DataLoader(test_txt_dataset, batch_size=batch_size, shuffle=False)\n",
    "        print(f\"Train image dataloader: {len(self.train_img_dataloader)} batches\")\n",
    "        print(f\"Test image dataloader: {len(self.test_img_dataloader)} batches\")\n",
    "        print(f\"Train caption dataloader: {len(self.train_txt_dataloader)} batches\")\n",
    "        print(f\"Test caption dataloader: {len(self.test_txt_dataloader)} batches\")\n",
    "\n",
    "    def load_challenge_rois(self) -> None:\n",
    "        \"\"\"Loads the challenge rois from the .npy files\"\"\"\n",
    "        # Load the ROI classes mapping dictionaries\n",
    "        roi_mapping_files = ['mapping_prf-visualrois.npy', 'mapping_floc-bodies.npy',\n",
    "            'mapping_floc-faces.npy', 'mapping_floc-places.npy',\n",
    "            'mapping_floc-words.npy', 'mapping_streams.npy']\n",
    "        self.roi_name_maps = []\n",
    "        for r in roi_mapping_files:\n",
    "            self.roi_name_maps.append(np.load(f\"{self.roi_masks_dir}/{r}\", allow_pickle=True).item())\n",
    "\n",
    "        # Load the ROI brain surface maps\n",
    "        lh_challenge_roi_files = ['lh.prf-visualrois_challenge_space.npy',\n",
    "            'lh.floc-bodies_challenge_space.npy', 'lh.floc-faces_challenge_space.npy',\n",
    "            'lh.floc-places_challenge_space.npy', 'lh.floc-words_challenge_space.npy',\n",
    "            'lh.streams_challenge_space.npy']\n",
    "        rh_challenge_roi_files = ['rh.prf-visualrois_challenge_space.npy',\n",
    "            'rh.floc-bodies_challenge_space.npy', 'rh.floc-faces_challenge_space.npy',\n",
    "            'rh.floc-places_challenge_space.npy', 'rh.floc-words_challenge_space.npy',\n",
    "            'rh.streams_challenge_space.npy']\n",
    "        self.lh_challenge_rois = []\n",
    "        self.rh_challenge_rois = []\n",
    "        for r in range(len(lh_challenge_roi_files)):\n",
    "            self.lh_challenge_rois.append(np.load(f\"{self.roi_masks_dir}/{lh_challenge_roi_files[r]}\"))\n",
    "            self.rh_challenge_rois.append(np.load(f\"{self.roi_masks_dir}/{rh_challenge_roi_files[r]}\"))\n",
    "\n",
    "    def load_roi_masks(self, roi=\"V1v\", hemisphere=\"lh\"):\n",
    "        valid_roi = [\"V1v\", \"V1d\", \"V2v\", \"V2d\", \"V3v\", \n",
    "                     \"V3d\", \"hV4\", \"EBA\", \"FBA-1\", \"FBA-2\", \n",
    "                     \"mTL-bodies\", \"OFA\", \"FFA-1\", \"FFA-2\", \n",
    "                     \"mTL-faces\", \"aTL-faces\", \"OPA\", \"PPA\", \n",
    "                     \"RSC\", \"OWFA\", \"VWFA-1\", \"VWFA-2\", \"mfs-words\", \n",
    "                     \"mTL-words\", \"early\", \"midventral\", \"midlateral\", \n",
    "                     \"midparietal\", \"ventral\", \"lateral\", \"parietal\",\n",
    "                     \"all-vertices\"]\n",
    "        valid_hemisphere = [\"lh\", \"rh\"]\n",
    "        assert roi in valid_roi, \"Invalid ROI\"\n",
    "        assert hemisphere in valid_hemisphere, \"Invalid hemisphere\"\n",
    "\n",
    "        # Define the ROI class based on the selected ROI\n",
    "        if roi in [\"V1v\", \"V1d\", \"V2v\", \"V2d\", \"V3v\", \"V3d\", \"hV4\"]:\n",
    "            roi_class = 'prf-visualrois'\n",
    "        elif roi in [\"EBA\", \"FBA-1\", \"FBA-2\", \"mTL-bodies\"]:\n",
    "            roi_class = 'floc-bodies'\n",
    "        elif roi in [\"OFA\", \"FFA-1\", \"FFA-2\", \"mTL-faces\", \"aTL-faces\"]:\n",
    "            roi_class = 'floc-faces'\n",
    "        elif roi in [\"OPA\", \"PPA\", \"RSC\"]:\n",
    "            roi_class = 'floc-places'\n",
    "        elif roi in [\"OWFA\", \"VWFA-1\", \"VWFA-2\", \"mfs-words\", \"mTL-words\"]:\n",
    "            roi_class = 'floc-words'\n",
    "        elif roi in [\"early\", \"midventral\", \"midlateral\", \"midparietal\", \"ventral\", \"lateral\", \"parietal\"]:\n",
    "            roi_class = 'streams'\n",
    "        else:\n",
    "            roi_class = roi\n",
    "        roi_class_dir = f\"{hemisphere}.{roi_class}_fsaverage_space.npy\"\n",
    "        roi_map_dir = f\"mapping_{roi_class}.npy\"\n",
    "        fsaverage_roi_class = np.load(f\"{self.roi_masks_dir}/{roi_class_dir}\")\n",
    "        roi_map = None\n",
    "        if roi != \"all-vertices\":\n",
    "            roi_map = np.load(f\"{self.roi_masks_dir}/{roi_map_dir}\", allow_pickle=True).item()\n",
    "        return fsaverage_roi_class, roi_map"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CLIPFeatureExtractor Class"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CLIPFeatureExtractor class is used to extract the hidden states from a clip model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CLIPFeatureExtractor():\n",
    "    \"\"\"Extracts the features from hidden states of a CLIP model.\"\"\"\n",
    "    def __init__(\n",
    "            self, \n",
    "            idxs: list = [i for i in range(13)], # hidden layer indices to extract features from. Standard CLIP has an embedding layer and 12 transformer layers.\n",
    "            last_hidden_layer: bool = False, # whether to extract features from the last hidden layer\n",
    "            model: PreTrainedModel = None, # CLIP model\n",
    "            dataloader: DataLoader = None, # dataloader for batching\n",
    "            ) -> None:\n",
    "        self.idxs = idxs\n",
    "        self.last_hidden_layer = last_hidden_layer\n",
    "        self.generate_feature_dict()\n",
    "        if self.last_hidden_layer:\n",
    "            self.idxs.append(13) # adds an additional idx to allow for loop zip()\n",
    "        self.model = model\n",
    "        self.dataloader = dataloader\n",
    "        print(f\"idxs: {self.idxs}\")\n",
    "        print(f\"feature dict keys: {self.feature_dict.keys()}\")\n",
    "    \n",
    "    def generate_feature_dict(self) -> None:\n",
    "        \"\"\"Generates a feature dict according to the idxs and last_hidden_layer attributes.\"\"\"\n",
    "        feature_dict = {}\n",
    "        for idx in self.idxs:\n",
    "            if idx == 0:\n",
    "                feature_dict[\"Embedding Layer\"] = None\n",
    "            else:\n",
    "                feature_dict[f\"Transformer Layer {idx}\"] = None\n",
    "        if self.last_hidden_layer:\n",
    "            feature_dict[\"Final Layer\"] = None\n",
    "        self.feature_dict = feature_dict\n",
    "    \n",
    "    def concat_features(self, features: dict) -> None:\n",
    "        \"\"\"Adds extracted features to the feature dict.\n",
    "        Args:\n",
    "            features: features extracted from the output of a CLIP model\"\"\"\n",
    "        keys = list(self.feature_dict.keys())\n",
    "        # check if feature_dict is empty\n",
    "        if self.feature_dict[keys[0]] is None:\n",
    "            self.feature_dict = features\n",
    "        else:\n",
    "            for key in keys:\n",
    "                self.feature_dict[key] = np.concatenate((self.feature_dict[key], features[key]), axis=0)\n",
    "\n",
    "    def extract_raw_features(self, output) -> None: \n",
    "        \"\"\"Extracts features from the hidden states of a CLIP model and concates them to the feature_dict.\n",
    "        Args:\n",
    "            output: output of a CLIP model\n",
    "        \"\"\"\n",
    "        features = {}\n",
    "        for idx, key in zip(self.idxs, self.feature_dict.keys()):\n",
    "            if key == \"Final Layer\":\n",
    "                features[key] = output.last_hidden_state.cpu().detach().numpy()\n",
    "            else:\n",
    "                features[key] = output.hidden_states[idx].cpu().detach().numpy()\n",
    "        self.concat_features(features)\n",
    "    \n",
    "    def extract_raw_features_from_model(self) -> None:\n",
    "        \"\"\"Runs the CLIP model on the dataloader and extracts features from the hidden states.\"\"\"\n",
    "        self.model = self.model.to(device)\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(self.dataloader):\n",
    "                batch = batch.to(device)\n",
    "                output = self.model(batch, output_hidden_states=True)\n",
    "                self.extract_raw_features(output)\n",
    "                batch = None # clear batch from memory\n",
    "                output = None # clear output from memory\n",
    "        self.model = self.model.to(\"cpu\")        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KFoldProcedure & KFold Classes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The KFoldProcedure class is used to define a procedure that is supposed to be executed during each fold of the k-fold validation. \n",
    "It can be supplied to a KFold class which executes its run() function on all folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KFoldProcedure:\n",
    "    \"\"\"This class is used to define a procedure that is run on each fold of a k-fold cross validation.\"\"\"\n",
    "    def __init__(self) -> None:\n",
    "        assert isinstance(self.model_name, str) and len(self.model_name) > 0, \"Please define a model name as part of the KFold Procedure.\"\n",
    "        assert isinstance(self.description, str ) and len(self.description) > 0 , \"Please define a description as part of the KFold Procedure.\"\n",
    "\n",
    "    def prepare(self) -> None:\n",
    "        \"\"\"Operations that should be executed before the fold loop\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def run(self, train_idxs: np.ndarray, val_idxs: np.ndarray) -> Dict[str, Dict[str, np.ndarray]]:\n",
    "        \"\"\"This should return a dict of correlations.\n",
    "        dict format: {\"layer\": {\"lh\": np.ndarray, \"lh\": np.ndarray}}\"\"\"\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def return_idxs(self):\n",
    "        \"\"\"Returns idxs to create folds in the KFold class.\"\"\"\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def return_roi_names(self) -> List[str]:\n",
    "        \"\"\"Required for the plot function in the KFold class.\"\"\"\n",
    "        return self.roi_names    \n",
    "    \n",
    "    def return_model_name_and_description(self) -> Tuple[str, str]:\n",
    "        return self.model_name, self.description\n",
    "\n",
    "    def calculate_correlations(self, lh_pred, rh_pred, lh_fmri, rh_fmri) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"Calculate correlation between prediction and fmri activation\"\"\"\n",
    "        lh_correlation = np.zeros(lh_pred.shape[1])\n",
    "        for v in tqdm(range(lh_pred.shape[1])):\n",
    "            lh_correlation[v] = corr(lh_pred[:,v], lh_fmri[:,v])[0]\n",
    "        # Right hemisphere\n",
    "        rh_correlation = np.zeros(rh_pred.shape[1])\n",
    "        for v in tqdm(range(rh_pred.shape[1])):\n",
    "            rh_correlation[v] = corr(rh_pred[:,v], rh_fmri[:,v])[0]\n",
    "        return lh_correlation, rh_correlation\n",
    "\n",
    "    def calculate_median_correlations(self, lh_correlation, rh_correlation) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"Calculate median correlation for each ROI.\"\"\"\n",
    "        # Select the correlation results vertices of each ROI\n",
    "        lh_challange_rois = self.lh_challenge_rois\n",
    "        rh_challange_rois = self.rh_challenge_rois\n",
    "        self.roi_names = []\n",
    "        lh_roi_correlation = []\n",
    "        rh_roi_correlation = []\n",
    "        for r1 in range(len(lh_challange_rois)):\n",
    "            for r2 in self.roi_name_maps[r1].items():\n",
    "                if r2[0] != 0: # zeros indicate to vertices falling outside the ROI of interest\n",
    "                    self.roi_names.append(r2[1])\n",
    "                    lh_roi_idx = np.where(lh_challange_rois[r1] == r2[0])[0]\n",
    "                    rh_roi_idx = np.where(rh_challange_rois[r1] == r2[0])[0]\n",
    "                    lh_roi_correlation.append(lh_correlation[lh_roi_idx])\n",
    "                    rh_roi_correlation.append(rh_correlation[rh_roi_idx])\n",
    "        self.roi_names.append('All vertices')\n",
    "        lh_roi_correlation.append(lh_correlation)\n",
    "        rh_roi_correlation.append(rh_correlation)\n",
    "        lh_median_roi_correlation = [np.median(lh_roi_correlation[r])\n",
    "            for r in range(len(lh_roi_correlation))]\n",
    "        rh_median_roi_correlation = [np.median(rh_roi_correlation[r])\n",
    "            for r in range(len(rh_roi_correlation))]\n",
    "        return lh_median_roi_correlation, rh_median_roi_correlation\n",
    "    \n",
    "class KFold:\n",
    "    \"\"\"Run a k-fold cross validation with a given procedure.\"\"\"\n",
    "    def __init__(self, folds: int = 8, seed: int = 5, procedure: KFoldProcedure = None) -> None:\n",
    "        assert folds > 1, \"folds must be greater than 1\"\n",
    "        assert seed > 0, \"seed must be greater than 0\"\n",
    "        assert isinstance(folds, int), \"folds must be an integer\"\n",
    "        assert isinstance(seed, int), \"seed must be an integer\"\n",
    "        #assert isinstance(procedure, KFoldProcedure), \"procedure must be an instance of KFoldProcedure\"\n",
    "        self.folds = folds\n",
    "        self.seed = seed\n",
    "        self.procedure = procedure\n",
    "        self.fold_correlations = {}\n",
    "        self.mean_correlations = None\n",
    "\n",
    "    def run(self) -> None:\n",
    "        \"\"\"Runs the procedure on each fold and accesses the correlations.\"\"\"\n",
    "        self.procedure.prepare()\n",
    "        # Create k folds   \n",
    "        fold_idxs = self.procedure.return_idxs()\n",
    "        np.random.seed(self.seed)\n",
    "        np.random.shuffle(fold_idxs)\n",
    "        self.fold_idxs = np.array_split(fold_idxs, self.folds)\n",
    "\n",
    "        for fold in range(self.folds):\n",
    "            # Select validation and train set\n",
    "            val_idxs = self.fold_idxs[fold]\n",
    "            train_idxs = np.concatenate([self.fold_idxs[j] for j in range(self.folds) if j != fold])\n",
    "            \n",
    "            # Info for current fold\n",
    "            print(f\"#############################################\")\n",
    "            print(f\"# Fold: {fold+1}/ {self.folds}\")         \n",
    "            print(f\"# Train size: {len(train_idxs)}\")\n",
    "            print(f\"# Validation size: {len(val_idxs)}\")\n",
    "            print(f\"#############################################\")\n",
    "\n",
    "            # Run procedure\n",
    "            self.fold_correlations[fold] = self.procedure.run(train_idxs, val_idxs)\n",
    "        # Get model name and description\n",
    "        self.model_name, self.description = self.procedure.return_model_name_and_description()\n",
    "        self.roi_names = self.procedure.return_roi_names()\n",
    "        self.calculate_mean_accross_folds()\n",
    "        self.mean_correlations_to_csv()\n",
    "    \n",
    "    def calculate_mean_accross_folds(self):\n",
    "        \"\"\"Calculates the mean across folds for each layer\"\"\"\n",
    "        self.mean_correlations = {}\n",
    "        for layer in self.fold_correlations[0].keys():\n",
    "            self.mean_correlations[layer] = {}\n",
    "            for hemi in self.fold_correlations[0][layer].keys():\n",
    "                self.mean_correlations[layer][hemi] = np.nanmean([self.fold_correlations[fold][layer][hemi] for fold in range(self.folds)], axis=0)\n",
    "    \n",
    "    def mean_correlations_to_csv(self) -> None:\n",
    "        df = pd.DataFrame(columns=[\"model\", \"layer\", \"hemisphere\", \"roi\", \"correlation\"])\n",
    "        for layer in self.mean_correlations.keys():\n",
    "                for hemisphere in self.mean_correlations[layer].keys():\n",
    "                    for i in range(len(self.roi_names)):\n",
    "                        df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
    "\n",
    "        validations = glob.glob(f\"validations/validation*\")\n",
    "        if len(validations) == 0:\n",
    "            # create first validation folder\n",
    "            folder_name = \"validation001\"\n",
    "            os.mkdir(f\"validations/{folder_name}\")\n",
    "        else:\n",
    "            # create next validation folder\n",
    "            last_validation = sorted(validations)[-1]\n",
    "            last_validation_number = int(last_validation.split(\"/\")[-1].split(\"validation\")[-1])\n",
    "            next_validation_number = last_validation_number + 1\n",
    "            folder_name = f\"validation{str(next_validation_number).zfill(3)}\"\n",
    "            os.mkdir(f\"validations/{folder_name}\")\n",
    "\n",
    "        # Write text file with model description\n",
    "        with open(f\"validations/{folder_name}/info.txt\", \"w\") as f:\n",
    "            f.write(self.description)\n",
    "\n",
    "        # Save dataframe\n",
    "        df.to_csv(f\"validations/{folder_name}/results.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally we define a function to plot the validation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_kfold_result(validation = \"001\"):\n",
    "    \"\"\"Plots the validation results from the csv file in the given validaiton folder.\"\"\"\n",
    "    folder = f\"validations/validation{validation}\"\n",
    "    with open(f\"{folder}/info.txt\", 'r') as f:\n",
    "        info = f.read()\n",
    "    df = pd.read_csv(f\"{folder}/results.csv\")\n",
    "    # drop model column\n",
    "    df = df.drop(\"model\", axis=1)\n",
    "\n",
    "    # Define color palette and assign colors to layers\n",
    "    palette = sns.color_palette(\"colorblind\", 14)\n",
    "    layer_colors = {layer: palette[i] for i, layer in enumerate(df.layer.unique())}\n",
    "\n",
    "    # Split data into left and right hemispheres\n",
    "    left_df = df[df['hemisphere'] == 'lh']\n",
    "    right_df = df[df['hemisphere'] == 'rh']\n",
    "\n",
    "    # Create bar plots\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(30, 10))\n",
    "    fig.suptitle(info)\n",
    "    plt.subplots_adjust(hspace=0.5)\n",
    "    # reduce white space before first x tick\n",
    "    plt.margins(x=0.01)\n",
    "\n",
    "    bar_width = 0.05\n",
    "    # Plot left hemisphere data\n",
    "    for i, layer in enumerate(df.layer.unique()):\n",
    "        layer_data = left_df[left_df['layer'] == layer]\n",
    "        x = np.arange(len(layer_data['roi']))\n",
    "        # center bars around xtick\n",
    "        axes[0].bar(x - len(df.layer.unique())/2 * 0.05 + i * 0.05, layer_data['correlation'], width=bar_width, label=layer, color=layer_colors[layer])\n",
    "\n",
    "    axes[0].set_xticks([i for i in range(len(layer_data['roi']))])\n",
    "    axes[0].set_xticklabels([roi for roi in layer_data['roi']])\n",
    "    axes[0].set_title('Left Hemisphere')\n",
    "    axes[0].set_xlabel('ROI')\n",
    "    axes[0].tick_params(axis='x', labelrotation=45)\n",
    "    axes[0].set_ylabel('Correlation')\n",
    "    axes[0].legend(loc='upper center', bbox_to_anchor=(0.5, 1), ncol=5)\n",
    "    axes[0].set_ylim([0, 1])\n",
    "    row_colors = [layer_colors[layer] for layer in left_df.groupby('layer').mean().sort_values(by='correlation', ascending=False).index]\n",
    "    axes[0].table(cellText=left_df.groupby('layer').mean().sort_values(by='correlation', ascending=False).round(3).values, rowLabels=df.groupby('layer').mean().sort_values(by='correlation', ascending=False).index, colLabels=[\"Mean Correlation\"], rowColours=row_colors, bbox = [0.95, 0.5, 0.05, 0.5])\n",
    "\n",
    "\n",
    "    # Plot right hemisphere data\n",
    "    for i, layer in enumerate(df.layer.unique()):\n",
    "        layer_data = right_df[right_df['layer'] == layer]\n",
    "        x = np.arange(len(layer_data['roi']))\n",
    "        axes[1].bar(x - len(df.layer.unique())/2 * 0.05 + i * 0.05, layer_data['correlation'], width=bar_width, label=layer, color=layer_colors[layer])\n",
    "\n",
    "    axes[1].set_xticks([i for i in range(len(layer_data['roi']))])\n",
    "    axes[1].set_xticklabels([roi for roi in layer_data['roi']])\n",
    "    axes[1].set_title('Right Hemisphere')\n",
    "    axes[1].set_xlabel('ROI')\n",
    "    axes[1].tick_params(axis='x', labelrotation=45)\n",
    "    axes[1].set_ylabel('Correlation')\n",
    "    axes[1].legend(loc='upper center', bbox_to_anchor=(0.5, 1), ncol=5)\n",
    "    axes[1].set_ylim([0, 1])\n",
    "    row_colors = [layer_colors[layer] for layer in right_df.groupby('layer').mean().sort_values(by='correlation', ascending=False).index]\n",
    "    axes[1].table(cellText=right_df.groupby('layer').mean().sort_values(by='correlation', ascending=False).round(3).values, rowLabels=df.groupby('layer').mean().sort_values(by='correlation', ascending=False).index, colLabels=[\"Mean Correlation\"], rowColours=row_colors, bbox = [0.95, 0.5, 0.05, 0.5])\n",
    "\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SubmissionProcedure & CreateSubmission Classes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SubmissionProcedure class is used to define a procedure which fits a model to predict the test fmri activity. \n",
    "It can be supplied to a CreateSubmission class which executes its run() function on all subjects to generate a submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubmissionProcedure:\n",
    "    \"\"\"Used to create a submission procedure that is executed for each subject in the CreateSubmission class.\"\"\"\n",
    "\n",
    "    def run(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "class CreateSubmission:\n",
    "    \"\"\"Create a new challenge submission.\"\"\"\n",
    "    def __init__(self, \n",
    "                 subjects : List[Subject],\n",
    "                 procedure: SubmissionProcedure):\n",
    "        self.subjects = subjects\n",
    "        self.procedure = procedure\n",
    "\n",
    "    def create_submission_folder(self) -> None:\n",
    "        # create new submission folder with newest name\n",
    "        submissions = glob.glob(f\"submissions/submission*\")\n",
    "        if len(submissions) == 0:\n",
    "            # create first submission folder\n",
    "            self.folder_name = \"submission001\"\n",
    "            os.mkdir(f\"submissions/{self.folder_name}\")\n",
    "        else:\n",
    "            # create next submission folder\n",
    "            last_submission = sorted(submissions)[-1]\n",
    "            last_submission_number = int(last_submission.split(\"/\")[-1].split(\"submission\")[-1])\n",
    "            next_submission_number = last_submission_number + 1\n",
    "            self.folder_name = f\"submission{str(next_submission_number).zfill(3)}\"\n",
    "            os.mkdir(f\"submissions/{self.folder_name}\")\n",
    "        # Write text file with model description\n",
    "        with open(f\"submissions/{self.folder_name}/info.txt\", \"w\") as f:\n",
    "            f.write(self.procedure.description)\n",
    "        # create a folder for each subject\n",
    "        for subject in self.subjects:\n",
    "            os.mkdir(f\"submissions/{self.folder_name}/{subject.subject}\")\n",
    "\n",
    "    def save_predictions(self, subject: Subject, lh_predictions: np.ndarray, rh_predictions: np.ndarray) -> None:\n",
    "        \"\"\"Save predictions for a subject.\"\"\"\n",
    "        lh_predictions = lh_predictions.astype(np.float32)\n",
    "        rh_predictions = rh_predictions.astype(np.float32)\n",
    "        save_path = f\"submissions/{self.folder_name}/{subject.subject}\"\n",
    "        # Save predictions\n",
    "        np.save(f\"{save_path}/lh_pred_test.npy\", lh_predictions)\n",
    "        np.save(f\"{save_path}/rh_pred_test.npy\", rh_predictions)\n",
    "\n",
    "    def run(self):\n",
    "        self.create_submission_folder()\n",
    "        for subject in self.subjects:\n",
    "            print(f\"############################\")\n",
    "            print(f\"# Subject: {subject.subject}\")\n",
    "            print(f\"############################\")\n",
    "            lh_predictions, rh_predictions = self.procedure.run(subject)\n",
    "            self.save_predictions(subject, lh_predictions, rh_predictions)\n",
    "            print(f\"\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the models we submitted to the algonauts 2023 competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CLIPVisionFinalLayerPCA100LinearRegression(SubmissionProcedure):\n",
    "    def __init__(self):\n",
    "        self.description = \"CLIP Vision Model, Final Layer, PCA 100, Linear Regression, First test submission.\"\n",
    "\n",
    "    def run(self, subject: Subject) -> np.ndarray:\n",
    "        \"\"\"Run the model on a subject.\"\"\"\n",
    "        # Prepare data\n",
    "        subject.create_dataloaders(processor=processor, batch_size=300)\n",
    "        subject.load_neural_data()\n",
    "        train_img_dataloader = subject.train_img_dataloader\n",
    "        test_img_dataloader = subject.test_img_dataloader\n",
    "        lh_fmri = subject.lh_fmri\n",
    "        rh_fmri = subject.rh_fmri\n",
    "        del subject # free up memory\n",
    "\n",
    "        # Prepare feature extractor\n",
    "        train_feature_extractor = CLIPFeatureExtractor(idxs=[], last_hidden_layer=True, model=vis_model, dataloader=train_img_dataloader)\n",
    "        test_feature_extractor = CLIPFeatureExtractor(idxs=[], last_hidden_layer=True, model=vis_model, dataloader=test_img_dataloader)\n",
    "\n",
    "        # Extract features\n",
    "        train_feature_extractor.extract_raw_features_from_model()\n",
    "        raw_train_features = train_feature_extractor.feature_dict[\"Final Layer\"]\n",
    "        del train_feature_extractor\n",
    "\n",
    "        # Fit PCA\n",
    "        pca = PCA(n_components=100)\n",
    "        pca_transformed_train_features = pca.fit_transform(torch.tensor(raw_train_features).flatten(1).numpy())\n",
    "        del raw_train_features\n",
    "\n",
    "        # Fit linear regression\n",
    "        lh_lin_reg = LinearRegression().fit(pca_transformed_train_features, lh_fmri)\n",
    "        rh_lin_reg = LinearRegression().fit(pca_transformed_train_features, rh_fmri)\n",
    "        del pca_transformed_train_features\n",
    "\n",
    "        # Extract test features\n",
    "        test_feature_extractor.extract_raw_features_from_model()\n",
    "        raw_test_features = test_feature_extractor.feature_dict[\"Final Layer\"]\n",
    "        del test_feature_extractor\n",
    "\n",
    "        # Transform test features\n",
    "        pca_transformed_test_features = pca.transform(torch.tensor(raw_test_features).flatten(1).numpy())\n",
    "        del raw_test_features\n",
    "        \n",
    "        # Predict\n",
    "        lh_predictions = lh_lin_reg.predict(pca_transformed_test_features)\n",
    "        rh_predictions = rh_lin_reg.predict(pca_transformed_test_features)\n",
    "        return lh_predictions, rh_predictions\n",
    "\n",
    "class CLIPTextFinalLayerPCA100LinearRegression(SubmissionProcedure):\n",
    "    def __init__(self):\n",
    "        self.description = \"CLIP Text Model, Final Layer, PCA 100, Linear Regression, Second test submission.\"\n",
    "\n",
    "    def run(self, subject: Subject) -> np.ndarray:\n",
    "        \"\"\"Run the model on a subject.\"\"\"\n",
    "        # Prepare data\n",
    "        subject.create_dataloaders(processor=processor, batch_size=300)\n",
    "        subject.load_neural_data()\n",
    "        train_txt_dataloader = subject.train_txt_dataloader\n",
    "        test_txt_dataloader = subject.test_txt_dataloader\n",
    "        lh_fmri = subject.lh_fmri\n",
    "        rh_fmri = subject.rh_fmri\n",
    "        del subject # free up memory\n",
    "\n",
    "        # Prepare feature extractor\n",
    "        train_feature_extractor = CLIPFeatureExtractor(idxs=[], last_hidden_layer=True, model=txt_model, dataloader=train_txt_dataloader)\n",
    "        test_feature_extractor = CLIPFeatureExtractor(idxs=[], last_hidden_layer=True, model=txt_model, dataloader=test_txt_dataloader)\n",
    "\n",
    "        # Extract features\n",
    "        train_feature_extractor.extract_raw_features_from_model()\n",
    "        raw_train_features = train_feature_extractor.feature_dict[\"Final Layer\"]\n",
    "        del train_feature_extractor\n",
    "\n",
    "        # Fit PCA\n",
    "        pca = PCA(n_components=100)\n",
    "        pca_transformed_train_features = pca.fit_transform(torch.tensor(raw_train_features).flatten(1).numpy())\n",
    "        del raw_train_features\n",
    "\n",
    "        # Fit linear regression\n",
    "        lh_lin_reg = LinearRegression().fit(pca_transformed_train_features, lh_fmri)\n",
    "        rh_lin_reg = LinearRegression().fit(pca_transformed_train_features, rh_fmri)\n",
    "        del pca_transformed_train_features\n",
    "\n",
    "        # Extract test features\n",
    "        test_feature_extractor.extract_raw_features_from_model()\n",
    "        raw_test_features = test_feature_extractor.feature_dict[\"Final Layer\"]\n",
    "        del test_feature_extractor\n",
    "\n",
    "        # Transform test features\n",
    "        pca_transformed_test_features = pca.transform(torch.tensor(raw_test_features).flatten(1).numpy())\n",
    "        del raw_test_features\n",
    "        \n",
    "        # Predict\n",
    "        lh_predictions = lh_lin_reg.predict(pca_transformed_test_features)\n",
    "        rh_predictions = rh_lin_reg.predict(pca_transformed_test_features)\n",
    "        return lh_predictions, rh_predictions\n",
    "\n",
    "\n",
    "class CLIPVisionLayer7PCA200LinearRegression(SubmissionProcedure):\n",
    "    def __init__(self):\n",
    "        self.description = \"CLIP Vision Model, Transformer Layer 7, PCA 200, Linear Regression, Determined by 8-fold cross validation against all other layers.\"\n",
    "\n",
    "    def run(self, subject: Subject) -> np.ndarray:\n",
    "        \"\"\"Run the model on a subject.\"\"\"\n",
    "        # Prepare data\n",
    "        subject.create_dataloaders(processor=processor, batch_size=300)\n",
    "        subject.load_neural_data()\n",
    "        train_img_dataloader = subject.train_img_dataloader\n",
    "        test_img_dataloader = subject.test_img_dataloader\n",
    "        lh_fmri = subject.lh_fmri\n",
    "        rh_fmri = subject.rh_fmri\n",
    "        del subject # free up memory\n",
    "\n",
    "        # Prepare feature extractor\n",
    "        train_feature_extractor = CLIPFeatureExtractor(idxs=[7], last_hidden_layer=False, model=vis_model, dataloader=train_img_dataloader)\n",
    "        test_feature_extractor = CLIPFeatureExtractor(idxs=[7], last_hidden_layer=False, model=vis_model, dataloader=test_img_dataloader)\n",
    "\n",
    "        # Extract features\n",
    "        train_feature_extractor.extract_raw_features_from_model()\n",
    "        raw_train_features = train_feature_extractor.feature_dict[\"Transformer Layer 7\"]\n",
    "        del train_feature_extractor\n",
    "\n",
    "        # Fit PCA\n",
    "        pca = PCA(n_components=200)\n",
    "        pca_transformed_train_features = pca.fit_transform(torch.tensor(raw_train_features).flatten(1).numpy())\n",
    "        del raw_train_features\n",
    "\n",
    "        # Fit linear regression\n",
    "        lh_lin_reg = LinearRegression().fit(pca_transformed_train_features, lh_fmri)\n",
    "        rh_lin_reg = LinearRegression().fit(pca_transformed_train_features, rh_fmri)\n",
    "        del pca_transformed_train_features\n",
    "\n",
    "        # Extract test features\n",
    "        test_feature_extractor.extract_raw_features_from_model()\n",
    "        raw_test_features = test_feature_extractor.feature_dict[\"Transformer Layer 7\"]\n",
    "        del test_feature_extractor\n",
    "\n",
    "        # Transform test features\n",
    "        pca_transformed_test_features = pca.transform(torch.tensor(raw_test_features).flatten(1).numpy())\n",
    "        del raw_test_features\n",
    "        \n",
    "        # Predict\n",
    "        lh_predictions = lh_lin_reg.predict(pca_transformed_test_features)\n",
    "        rh_predictions = rh_lin_reg.predict(pca_transformed_test_features)\n",
    "        return lh_predictions, rh_predictions\n",
    "    \n",
    "class CLIPCombinedLayer7PCA200LinearRegression(SubmissionProcedure):\n",
    "    def __init__(self):\n",
    "        self.description = \"CLIP Vision + Text Model, Transformer Layer 7, PCA 200, Linear Regression, Determined by 8-fold cross validation against all other layers.\"\n",
    "\n",
    "    def run(self, subject: Subject) -> np.ndarray:\n",
    "        \"\"\"Run the model on a subject.\"\"\"\n",
    "        # Prepare data\n",
    "        subject.create_dataloaders(processor=processor, batch_size=300)\n",
    "        subject.load_neural_data()\n",
    "        train_img_dataloader = subject.train_img_dataloader\n",
    "        test_img_dataloader = subject.test_img_dataloader\n",
    "        train_txt_dataloader = subject.train_txt_dataloader\n",
    "        test_txt_dataloader = subject.test_txt_dataloader\n",
    "        lh_fmri = subject.lh_fmri\n",
    "        rh_fmri = subject.rh_fmri\n",
    "        del subject # free up memory\n",
    "\n",
    "        # Prepare feature extractor\n",
    "        train_txt_feature_extractor = CLIPFeatureExtractor(idxs=[7], last_hidden_layer=False, model=txt_model, dataloader=train_txt_dataloader)\n",
    "        test_txt_feature_extractor = CLIPFeatureExtractor(idxs=[7], last_hidden_layer=False, model=txt_model, dataloader=test_txt_dataloader)\n",
    "        train_img_feature_extractor = CLIPFeatureExtractor(idxs=[7], last_hidden_layer=False, model=vis_model, dataloader=train_img_dataloader)\n",
    "        test_img_feature_extractor = CLIPFeatureExtractor(idxs=[7], last_hidden_layer=False, model=vis_model, dataloader=test_img_dataloader)\n",
    "\n",
    "        # Text features\n",
    "        # Extract features\n",
    "        train_txt_feature_extractor.extract_raw_features_from_model()\n",
    "        raw_train_txt_features = train_txt_feature_extractor.feature_dict[\"Transformer Layer 7\"]\n",
    "        del train_txt_feature_extractor\n",
    "\n",
    "        # Fit PCA\n",
    "        txt_pca = PCA(n_components=200)\n",
    "        pca_transformed_train_txt_features = txt_pca.fit_transform(torch.tensor(raw_train_txt_features).flatten(1).numpy())\n",
    "        del raw_train_txt_features\n",
    "\n",
    "        # Image features\n",
    "        # Extract features\n",
    "        train_img_feature_extractor.extract_raw_features_from_model()\n",
    "        raw_train_img_features = train_img_feature_extractor.feature_dict[\"Transformer Layer 7\"]\n",
    "        del train_img_feature_extractor\n",
    "\n",
    "        # Fit PCA\n",
    "        img_pca = PCA(n_components=200)\n",
    "        pca_transformed_train_img_features = img_pca.fit_transform(torch.tensor(raw_train_img_features).flatten(1).numpy())\n",
    "        del raw_train_img_features\n",
    "\n",
    "        # Fit linear regression\n",
    "        lh_lin_reg = LinearRegression().fit(np.hstack([pca_transformed_train_txt_features, pca_transformed_train_img_features]), lh_fmri)\n",
    "        rh_lin_reg = LinearRegression().fit(np.hstack([pca_transformed_train_txt_features, pca_transformed_train_img_features]), rh_fmri)\n",
    "        del pca_transformed_train_txt_features, pca_transformed_train_img_features\n",
    "\n",
    "        # Text features\n",
    "        # Extract test features\n",
    "        test_txt_feature_extractor.extract_raw_features_from_model()\n",
    "        raw_test_txt_features = test_txt_feature_extractor.feature_dict[\"Transformer Layer 7\"]\n",
    "        del test_txt_feature_extractor\n",
    "\n",
    "        # Transform test features\n",
    "        pca_transformed_test_txt_features = txt_pca.transform(torch.tensor(raw_test_txt_features).flatten(1).numpy())\n",
    "        del raw_test_txt_features\n",
    "\n",
    "        # Image features\n",
    "        # Extract test features\n",
    "        test_img_feature_extractor.extract_raw_features_from_model()\n",
    "        raw_test_img_features = test_img_feature_extractor.feature_dict[\"Transformer Layer 7\"]\n",
    "        del test_img_feature_extractor\n",
    "\n",
    "        # Transform test features\n",
    "        pca_transformed_test_img_features = img_pca.transform(torch.tensor(raw_test_img_features).flatten(1).numpy())\n",
    "        del raw_test_img_features   \n",
    "        \n",
    "        # Predict\n",
    "        lh_predictions = lh_lin_reg.predict(np.hstack([pca_transformed_test_txt_features, pca_transformed_test_img_features]))\n",
    "        rh_predictions = rh_lin_reg.predict(np.hstack([pca_transformed_test_txt_features, pca_transformed_test_img_features]))\n",
    "        return lh_predictions, rh_predictions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We ran three 8-fold cross validation procedures on a vision only model, text only model and combined model; all on data of subject 1.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLIP Vision Model, PCA200, Linear Regression <a id='cv_vis_pca200_linreg'></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We ran 8 folds on image data of subject 1. For each iteration the current fold was selected as the validation set and the remaining folds were used as the training set.\n",
    "\n",
    "The validation procedure for each fold was as follows: \n",
    "\n",
    "- Supplying the training set to a CLIPVisionModel.\n",
    "- Extracting the raw features for all layers (Embedding, Transformer 1 - 12, Final Layer).\n",
    "- Looping over folds:\n",
    "    - Assing training and validation sets for images and fmri activity.\n",
    "    - Looping over each layer:\n",
    "        - Fitting a PCA with 200 components using the raw training features.\n",
    "        - Transforming the raw training features using the fitted PCA.\n",
    "        - Fitting a linear regression, predicting training fmri activity from the pca transformed training features. (for left and right hemisphere)\n",
    "        - Transforming the raw validation features using the fitted PCA.\n",
    "        - Using the fitted linear models to predict validation fmri activity from the pca transformed validation features. (for left and right hemisphere)\n",
    "        - Calculating correlations between predicted and actual fmri activity for the validation set. (for left and right hemisphere)\n",
    "        - Calculating median correlations for each of the 36 challenge ROI. (for left and right hemisphere)\n",
    "    - Storing the median correlations for each hemisphere and each layer for the current fold.\n",
    "- Calculating mean median correlations accross all folds for each layer. (for left and right hemisphere)\n",
    "- Plotting the mean median correlations for each layer for each ROI and select the layer with the highest mean median correlation averaged over all ROIs.\n",
    "\n",
    "Transformer layer 7 achieved the highest overall performance (left hemisphere = 0.472, right hemisphere = 0.484) and was selected for submission (submission score = 49.3178).\n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly the plot below suggests, that earlier layers are better at predicting the activity of the earlier visual cortex (V1, V2, V3, V4) and later layers are better at predicting the activity of the other ROIs."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"plots/8-fold cross validation vision model pca 200 all layers.png\" alt=\"Alternative text\" />"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KFoldProcedure Class <a id='kfpc_single_clip_single_subject'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KFoldSingleCLIPSingleSubject(KFoldProcedure):\n",
    "    \"\"\"A procedure that runs k-fold on all layers of a single CLIP model on a single subject.\"\"\"\n",
    "    def __init__(self, \n",
    "                 feature_extractor: CLIPFeatureExtractor,\n",
    "                 subject: Subject, \n",
    "                 pca: PCA,\n",
    "                 model_name: str = None,\n",
    "                 description: str = None) -> None:\n",
    "        assert isinstance(feature_extractor, CLIPFeatureExtractor), \"feature_extractor must be an instance of CLIPFeatureExtractor\"\n",
    "        assert isinstance(subject, Subject), \"subject must be an instance of Subject\"\n",
    "        self.feature_extractor = feature_extractor\n",
    "        self.subject = subject\n",
    "        self.pca = pca\n",
    "        self.model_name = model_name\n",
    "        self.description = description\n",
    "        self.correlations = {}\n",
    "        super().__init__()\n",
    "\n",
    "    def prepare(self):\n",
    "        # Extract raw features\n",
    "        self.feature_extractor.extract_raw_features_from_model()\n",
    "        self.raw_features = self.feature_extractor.feature_dict\n",
    "        self.feature_extractor = None # free memory\n",
    "\n",
    "        # Load challenge rois\n",
    "        self.subject.load_challenge_rois()\n",
    "        self.lh_challenge_rois = self.subject.lh_challenge_rois\n",
    "        self.rh_challenge_rois = self.subject.rh_challenge_rois\n",
    "        self.roi_name_maps = self.subject.roi_name_maps\n",
    "\n",
    "        # Load neural data\n",
    "        self.subject.load_neural_data()\n",
    "        self.lh_fmri = self.subject.lh_fmri\n",
    "        self.rh_fmri = self.subject.rh_fmri\n",
    "        self.subject = None # free memory\n",
    "\n",
    "        # Prepare correlation dict\n",
    "        self.fold_correlations = {}\n",
    "\n",
    "    def run(self, train_idxs: np.ndarray, val_idxs: np.ndarray) -> Dict[str, Dict[str, np.ndarray]]:\n",
    "        # Loop over all layers          \n",
    "        correlations = {}\n",
    "        for layer in self.raw_features.keys():\n",
    "            print(f\"> {layer}\")\n",
    "            # Assign train and val features\n",
    "            train_features = self.raw_features[layer][train_idxs]\n",
    "            val_features = self.raw_features[layer][val_idxs]\n",
    "\n",
    "            # Assign train and val fmri\n",
    "            train_lh_fmri = self.lh_fmri[train_idxs]\n",
    "            train_rh_fmri = self.rh_fmri[train_idxs]\n",
    "            val_lh_fmri = self.lh_fmri[val_idxs]\n",
    "            val_rh_fmri = self.rh_fmri[val_idxs]\n",
    "\n",
    "            # Fit PCA models\n",
    "            print(f\"Fitting PCA model for {layer}...\")\n",
    "            train_pca_features = self.pca.fit_transform(torch.tensor(train_features).flatten(1).numpy())\n",
    "            del train_features # free memory\n",
    "\n",
    "            # Fit linear regression\n",
    "            print(f\"Fitting linear regression models for {layer}...\")\n",
    "            lh_lin_reg = LinearRegression().fit(train_pca_features, train_lh_fmri)\n",
    "            rh_lin_reg = LinearRegression().fit(train_pca_features, train_rh_fmri)\n",
    "            del train_pca_features, train_lh_fmri, train_rh_fmri # free memory\n",
    "\n",
    "            # Transform validation features\n",
    "            print(f\"Transforming validation features for {layer}...\")\n",
    "            val_txt_pca_features = self.pca.transform(torch.tensor(val_features).flatten(1).numpy())\n",
    "            del val_features # free memory\n",
    "\n",
    "            # Predict validation set\n",
    "            print(f\"Predicting validation set for {layer}...\")\n",
    "            lh_val_pred = lh_lin_reg.predict(val_txt_pca_features)\n",
    "            rh_val_pred = rh_lin_reg.predict(val_txt_pca_features)\n",
    "            del val_txt_pca_features, lh_lin_reg, rh_lin_reg # free memory\n",
    "            \n",
    "            # Calculate correlations\n",
    "            print(f\"Calculating correlations for {layer}...\\n\")\n",
    "            lh_correlation, rh_correlation = self.calculate_correlations(lh_val_pred, rh_val_pred, val_lh_fmri, val_rh_fmri)\n",
    "            lh_median_roi_correlation, rh_median_roi_correlation = self.calculate_median_correlations(lh_correlation, rh_correlation)\n",
    "            \n",
    "            # Store correlations\n",
    "            correlations[layer] = {\"lh\": lh_median_roi_correlation, \"rh\": rh_median_roi_correlation} \n",
    "        return correlations\n",
    "\n",
    "    def return_idxs(self) -> np.ndarray:\n",
    "        return np.arange(len(self.raw_features[list(self.raw_features.keys())[0]])) \n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raise exception to prevent accidental execution\n",
    "raise Exception(\"This code is not meant to be run. It is only meant to be used as a reference for the code used to generate the submission.\")\n",
    "\n",
    "# Initializing all required objects\n",
    "subject = Subject(\"subj01\")\n",
    "subject.create_dataloaders(processor=processor, batch_size=300)\n",
    "feature_extractor = CLIPFeatureExtractor(\n",
    "    idxs=[0,1,2,3,4,5,6,7,8,9,10,11,12], \n",
    "    last_hidden_layer=True, \n",
    "    model=vis_model, # here we use the vis_model\n",
    "    dataloader=subject.train_img_dataloader) # and the img_dataloader\n",
    "\n",
    "# Initialize the kfold procedure\n",
    "kfold_procedure = KFoldSingleCLIPSingleSubject(\n",
    "    feature_extractor=feature_extractor,\n",
    "    subject=subject,\n",
    "    pca=PCA(n_components=200),\n",
    "    model_name=\"CLIP Vision\",\n",
    "    description=\"CLIP Vision Model, all layers, PCA 200, Single layer linear regression, 8-fold cross validation\"\n",
    ")\n",
    "\n",
    "# Run KFold\n",
    "KFold(folds=8, seed=5, procedure=kfold_procedure).run()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Additional Data Analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because The cross validation plot indicated that earlier layers are better at predicting earlier ROIs, we checked which layer would have the highest mean median correlation averaged over early ROI (V1, V2, V3) and which layer has the highest mean median correlation averaged over all other ROI. \n",
    "\n",
    "The results indicate that Transformer Layer 4 is best at predicting activity in the early visual cortex, while layer 8 is the best layer of the rest of the cortex. \n",
    "Because of these findings we decided cross validate another model agains our strongest model so far. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best layer for early ROI on the left hemisphere is\t\t==>\tTransformer Layer 4 (0.566)\n",
      "The best layer for early ROI on the right hemisphere is\t\t==>\tTransformer Layer 4 (0.568)\n",
      "The best layer for later ROI on the left hemisphere is\t\t==>\tTransformer Layer 8 (0.458)\n",
      "The best layer for later ROI on the right hemisphere is\t\t==>\tTransformer Layer 8 (0.473)\n"
     ]
    }
   ],
   "source": [
    "validation_folder = \"validations\"\n",
    "validation = \"001\"\n",
    "\n",
    "df = pd.read_csv(f\"{validation_folder}/validation{validation}/results.csv\")\n",
    "df = df.drop(columns=\"model\")\n",
    "\n",
    "early_roi = [\"V1v\", \"V1d\", \"V2v\", \"V2d\", \"V3v\", \"V3d\"]\n",
    "best_early_lh = df[(df.roi.isin(early_roi)) & (df.hemisphere == \"lh\")].groupby([\"layer\"]).mean([\"correlations\"]).sort_values(by='correlation', ascending=False).round(3).head(1).index.values[0]\n",
    "best_early_lh_cor = df[(df.roi.isin(early_roi)) & (df.hemisphere == \"lh\")].groupby([\"layer\"]).mean([\"correlations\"]).sort_values(by='correlation', ascending=False).round(3).head(1).values[0][0]\n",
    "best_early_rh = df[(df.roi.isin(early_roi)) & (df.hemisphere == \"rh\")].groupby([\"layer\"]).mean([\"correlations\"]).sort_values(by='correlation', ascending=False).round(3).head(1).index.values[0]\n",
    "best_early_rh_cor = df[(df.roi.isin(early_roi)) & (df.hemisphere == \"rh\")].groupby([\"layer\"]).mean([\"correlations\"]).sort_values(by='correlation', ascending=False).round(3).head(1).values[0][0]\n",
    "best_late_lh = df[~(df.roi.isin(early_roi)) & (df.hemisphere == \"lh\")].groupby([\"layer\"]).mean([\"correlations\"]).sort_values(by='correlation', ascending=False).round(3).head(1).index.values[0]\n",
    "best_late_lh_cor = df[~(df.roi.isin(early_roi)) & (df.hemisphere == \"lh\")].groupby([\"layer\"]).mean([\"correlations\"]).sort_values(by='correlation', ascending=False).round(3).head(1).values[0][0]\n",
    "best_late_rh = df[~(df.roi.isin(early_roi)) & (df.hemisphere == \"rh\")].groupby([\"layer\"]).mean([\"correlations\"]).sort_values(by='correlation', ascending=False).round(3).head(1).index.values[0]\n",
    "best_late_rh_cor = df[~(df.roi.isin(early_roi)) & (df.hemisphere == \"rh\")].groupby([\"layer\"]).mean([\"correlations\"]).sort_values(by='correlation', ascending=False).round(3).head(1).values[0][0]\n",
    "print(f\"The best layer for early ROI on the left hemisphere is\\t\\t==>\\t{best_early_lh} ({best_early_lh_cor})\")\n",
    "print(f\"The best layer for early ROI on the right hemisphere is\\t\\t==>\\t{best_early_rh} ({best_early_rh_cor})\")\n",
    "print(f\"The best layer for later ROI on the left hemisphere is\\t\\t==>\\t{best_late_lh} ({best_late_lh_cor})\")\n",
    "print(f\"The best layer for later ROI on the right hemisphere is\\t\\t==>\\t{best_late_rh} ({best_late_rh_cor})\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLIP Text Model, PCA200, Linear Regression <a id='cv_txt_pca200_linreg'></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We ran 8 folds on caption data of subject 1. For each iteration the current fold was selected as the validation set and the remaining folds were used as the training set.\n",
    "\n",
    "The validation procedure for each fold was as follows: \n",
    "\n",
    "- Supplying the training set to a CLIPTextModel.\n",
    "- Extracting the raw features for all layers (Embedding, Transformer 1 - 12, Final Layer).\n",
    "- Looping over folds:\n",
    "    - Assing training and validation sets for coco captions and fmri activity.\n",
    "    - Looping over each layer:\n",
    "        - Fitting a PCA with 200 components using the raw training features.\n",
    "        - Transforming the raw training features using the fitted PCA.\n",
    "        - Fitting a linear regression, predicting training fmri activity from the pca transformed training features. (for left and right hemisphere)\n",
    "        - Transforming the raw validation features using the fitted PCA.\n",
    "        - Using the fitted linear models to predict validation fmri activity from the pca transformed validation features. (for left and right hemisphere)\n",
    "        - Calculating correlations between predicted and actual fmri activity for the validation set. (for left and right hemisphere)\n",
    "        - Calculating median correlations for each of the 36 challenge ROI. (for left and right hemisphere)\n",
    "    - Storing the median correlations for each hemisphere and each layer for the current fold.\n",
    "- Calculating mean median correlations accross all folds for each layer. (for left and right hemisphere)\n",
    "- Plotting the mean median correlations for each layer for each ROI and select the layer with the highest mean median correlation averaged over all ROIs.\n",
    "\n",
    "Transformer layer 11 achieved the highest overall performance (left hemisphere = 0.293, right hemisphere = 0.306) but was much worse than transformer layer 7 of the vision only model (left hemisphere = 0.472, right hemisphere = 0.484), therefore we didnt submit this.\n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As opposed to the vision only model, the plot below indicates that later levels of the text only model are better to predict activity in all ROIs. Additionally, the text only model performed much worse on the early visual cortex (V1, V2, V3, V4) than the vision only model but performed comparably for the later layers."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"plots/8-fold cross validation text model pca 200 all layers.png\" alt=\"Alternative text\" />"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KFoldProcedure Class ([Same as for the Vision Model](#kfpc_single_clip_single_subject))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raise exception to prevent accidental execution\n",
    "raise Exception(\"This code is not meant to be run. It is only meant to be used as a reference for the code used to generate the submission.\")\n",
    "\n",
    "# Initializing all required objects\n",
    "subject = Subject(\"subj01\")\n",
    "subject.create_dataloaders(processor=processor, batch_size=300)\n",
    "feature_extractor = CLIPFeatureExtractor(\n",
    "    idxs=[0,1,2,3,4,5,6,7,8,9,10,11,12], \n",
    "    last_hidden_layer=True, \n",
    "    model=txt_model, # here we use the txt_model \n",
    "    dataloader=subject.train_txt_dataloader) # and the txt_dataloader\n",
    "\n",
    "# Initialize the kfold procedure\n",
    "kfold_procedure = KFoldSingleCLIPSingleSubject(\n",
    "    feature_extractor=feature_extractor,\n",
    "    subject=subject,\n",
    "    pca=PCA(n_components=200),\n",
    "    model_name=\"CLIP Text\",\n",
    "    description=\"CLIP Text Model, all layers, PCA 200, Single layer linear regression, 8-fold cross validation\"\n",
    ")\n",
    "\n",
    "# Run KFold\n",
    "KFold(folds=8, seed=5, procedure=kfold_procedure).run()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLIP Text + Vision Model, PCA200, Linear Regression <a id='cv_txtvis_pca200_linreg'></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We ran 8 folds on caption and image data of subject 1. For each iteration the current fold was selected as the validation set and the remaining folds were used as the training set.\n",
    "Because of RAM limitations we ran the cross validation for the combined model in three batches (Embedding Layer to Transformer Layer 4, Transformer Layers 5 to 9, Transformer Layer 10 to Final Layer). Afterwards we manually combined the csv files that contained the results to provide one plot including all layers.\n",
    "\n",
    "The validation procedure for each fold was as follows: \n",
    "\n",
    "- Supplying the caption training set to a CLIPTextModel and the image training set to a CLIPVisionModel.\n",
    "- Extracting the raw features for all layers (Embedding, Transformer 1 - 12, Final Layer). (for text and images)\n",
    "- Looping over folds:\n",
    "    - Assing training and validation sets for images, coco captions and fmri activity.\n",
    "    - Looping over each layer:\n",
    "        - Fitting a PCA with 200 components using the raw training features. (for text and images)\n",
    "        - Transforming the raw training features using the fitted PCA. (for text and images)\n",
    "        - Fitting a linear regression, predicting training fmri activity from the combination of pca transformed image and caption training features. (for left and right hemisphere)\n",
    "        - Transforming the raw validation features using the fitted PCA. (for text and images)\n",
    "        - Using the fitted linear models to predict validation fmri activity from the combination of pca transformed image and caption validation features. (for left and right hemisphere)\n",
    "        - Calculating correlations between predicted and actual fmri activity for the validation set. (for left and right hemisphere)\n",
    "        - Calculating median correlations for each of the 36 challenge ROI. (for left and right hemisphere)\n",
    "    - Storing the median correlations for each hemisphere and each layer for the current fold.\n",
    "- Calculating mean median correlations accross all folds for each layer. (for left and right hemisphere)\n",
    "- Plotting the mean median correlations for each layer for each ROI and select the layer with the highest mean median correlation averaged over all ROIs.\n",
    "\n",
    "Similar to the vision only model, transformer layer 7 achieved the highest overall performance (left hemisphere = 0.468, right hemisphere = 0.48) and was selected for submission (submission score = NA).\n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"plots/8-fold cross validation combined model pca 200 all layers.png\" alt=\"Alternative text\" />"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KFoldProcedure Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KFoldCombinedCLIPSingleSubject(KFoldProcedure):\n",
    "    \"\"\"A procedure that runs k-fold on all layers of a combination of the text and vision CLIP model on a single subject.\"\"\"\n",
    "    def __init__(self, \n",
    "                 subject: Subject, \n",
    "                 txt_pca: PCA,\n",
    "                 img_pca: PCA,\n",
    "                 model_name: str = None,\n",
    "                 description: str = None,\n",
    "                 layers: list = [],\n",
    "                 last_hidden_state = False) -> None:\n",
    "        self.subject = subject\n",
    "        self.txt_pca = txt_pca\n",
    "        self.img_pca = img_pca\n",
    "        self.model_name = model_name\n",
    "        self.description = description\n",
    "        self.layers = layers.copy()\n",
    "        self.layers2 = layers.copy()\n",
    "        self.last_hidden_state = last_hidden_state\n",
    "        self.correlations = {}\n",
    "        super().__init__()\n",
    "\n",
    "    def prepare(self):\n",
    "        # Prepare data\n",
    "        self.subject.create_dataloaders(processor, batch_size=400)\n",
    "        train_img_dataloader = self.subject.train_img_dataloader\n",
    "        train_txt_dataloader = self.subject.train_txt_dataloader\n",
    "\n",
    "        # Extract raw features from text model\n",
    "        feature_extractor = CLIPFeatureExtractor(idxs=self.layers, last_hidden_layer=self.last_hidden_state, model=txt_model, dataloader=train_txt_dataloader)\n",
    "        feature_extractor.extract_raw_features_from_model()\n",
    "        self.raw_txt_features = feature_extractor.feature_dict\n",
    "        del feature_extractor # free memory\n",
    "\n",
    "        # Extract raw features from vision model\n",
    "        feature_extractor = CLIPFeatureExtractor(idxs=self.layers2, last_hidden_layer=self.last_hidden_state, model=vis_model, dataloader=train_img_dataloader)\n",
    "        feature_extractor.extract_raw_features_from_model()\n",
    "        self.raw_img_features = feature_extractor.feature_dict\n",
    "        del feature_extractor # free memory\n",
    "\n",
    "        # Load challenge rois\n",
    "        self.subject.load_challenge_rois()\n",
    "        self.lh_challenge_rois = self.subject.lh_challenge_rois\n",
    "        self.rh_challenge_rois = self.subject.rh_challenge_rois\n",
    "        self.roi_name_maps = self.subject.roi_name_maps\n",
    "\n",
    "        # Load neural data\n",
    "        self.subject.load_neural_data()\n",
    "        self.lh_fmri = self.subject.lh_fmri\n",
    "        self.rh_fmri = self.subject.rh_fmri\n",
    "        self.subject = None # free memory\n",
    "\n",
    "        # Prepare correlation dict\n",
    "        self.fold_correlations = {}\n",
    "\n",
    "    def run(self, train_idxs: np.ndarray, val_idxs: np.ndarray) -> Dict[str, Dict[str, np.ndarray]]:\n",
    "        # Loop over all layers          \n",
    "        correlations = {}\n",
    "        for layer in self.raw_txt_features.keys():\n",
    "            print(f\"> {layer}\")\n",
    "            # Assign train and val text features\n",
    "            train_txt_features = self.raw_txt_features[layer][train_idxs]\n",
    "            val_txt_features = self.raw_txt_features[layer][val_idxs]\n",
    "            # Assign train and val vision features\n",
    "            train_img_features = self.raw_img_features[layer][train_idxs]\n",
    "            val_img_features = self.raw_img_features[layer][val_idxs]\n",
    "\n",
    "            # Assign train and val fmri\n",
    "            train_lh_fmri = self.lh_fmri[train_idxs]\n",
    "            train_rh_fmri = self.rh_fmri[train_idxs]\n",
    "            val_lh_fmri = self.lh_fmri[val_idxs]\n",
    "            val_rh_fmri = self.rh_fmri[val_idxs]\n",
    "\n",
    "            # Fit PCA models\n",
    "            print(f\"Fitting PCA model for {layer}...\")\n",
    "            train_txt_pca_features = self.txt_pca.fit_transform(torch.tensor(train_txt_features).flatten(1).numpy())\n",
    "            del train_txt_features # free memory\n",
    "            train_img_pca_features = self.img_pca.fit_transform(torch.tensor(train_img_features).flatten(1).numpy())\n",
    "            del train_img_features # free memory\n",
    "\n",
    "            # Fit linear regression\n",
    "            print(f\"Fitting linear regression models for {layer}...\")\n",
    "            lh_lin_reg = LinearRegression().fit(np.hstack([train_txt_pca_features, train_img_pca_features]), train_lh_fmri)\n",
    "            rh_lin_reg = LinearRegression().fit(np.hstack([train_txt_pca_features, train_img_pca_features]), train_rh_fmri)\n",
    "            del train_txt_pca_features, train_img_pca_features, train_lh_fmri, train_rh_fmri # free memory\n",
    "\n",
    "            # Transform validation features\n",
    "            print(f\"Transforming validation features for {layer}...\")\n",
    "            val_txt_pca_features = self.txt_pca.transform(torch.tensor(val_txt_features).flatten(1).numpy())\n",
    "            del val_txt_features # free memory\n",
    "            val_img_pca_features = self.img_pca.transform(torch.tensor(val_img_features).flatten(1).numpy())\n",
    "            del val_img_features # free memory\n",
    "\n",
    "            # Predict validation set\n",
    "            print(f\"Predicting validation set for {layer}...\")\n",
    "            lh_val_pred = lh_lin_reg.predict(np.hstack([val_txt_pca_features, val_img_pca_features]))\n",
    "            rh_val_pred = rh_lin_reg.predict(np.hstack([val_txt_pca_features, val_img_pca_features]))\n",
    "            del val_txt_pca_features, val_img_pca_features, lh_lin_reg, rh_lin_reg # free memory\n",
    "            \n",
    "            # Calculate correlations\n",
    "            print(f\"Calculating correlations for {layer}...\\n\")\n",
    "            lh_correlation, rh_correlation = self.calculate_correlations(lh_val_pred, rh_val_pred, val_lh_fmri, val_rh_fmri)\n",
    "            lh_median_roi_correlation, rh_median_roi_correlation = self.calculate_median_correlations(lh_correlation, rh_correlation)\n",
    "            \n",
    "            # Store correlations\n",
    "            correlations[layer] = {\"lh\": lh_median_roi_correlation, \"rh\": rh_median_roi_correlation} \n",
    "        return correlations\n",
    "\n",
    "    def return_idxs(self) -> np.ndarray:\n",
    "        return np.arange(len(self.raw_txt_features[list(self.raw_txt_features.keys())[0]])) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raise exception to prevent accidental execution\n",
    "raise Exception(\"This code is not meant to be run. It is only meant to be used as a reference for the code used to generate the submission.\")\n",
    "\n",
    "# Initialize required objects\n",
    "subject = Subject(\"subj01\")\n",
    "\n",
    "# Initialize kfold procedure\n",
    "kfold_procedure = KFoldCombinedCLIPSingleSubject(\n",
    "    subject=subject, \n",
    "    txt_pca=PCA(n_components=200), \n",
    "    img_pca=PCA(n_components=200), \n",
    "    model_name=\"CLIP Vision + Text\", \n",
    "    description=\"CLIP Vision + Text Model, Embedding layer and first 4 Transformer Layers, PCA 200, Single layer linear regression, 8-fold cross validation\", \n",
    "    layers=[0,1,2,3,4], # only first 5 layers\n",
    "    last_hidden_state=False\n",
    "    )\n",
    "\n",
    "# Run first kfold\n",
    "KFold(folds=8, procedure=kfold_procedure).run()\n",
    "\n",
    "# Initalize kfold procedure for second batch\n",
    "kfold_procedure = KFoldCombinedCLIPSingleSubject(\n",
    "    subject=subject, \n",
    "    txt_pca=PCA(n_components=200), \n",
    "    img_pca=PCA(n_components=200), \n",
    "    model_name=\"CLIP Vision + Text\", \n",
    "    description=\"CLIP Vision + Text Model, Transformer layers 5 to 9, PCA 200, Single layer linear regression, 8-fold cross validation\", \n",
    "    layers=[5,6,7,8,9], # the next 5 layers\n",
    "    last_hidden_state=False\n",
    "    )\n",
    "# Run second kfold\n",
    "KFold(folds=8, procedure=kfold_procedure).run()\n",
    "\n",
    "# Initalize kfold procedure for third batch\n",
    "kfold_procedure = KFoldCombinedCLIPSingleSubject(\n",
    "    subject=subject, \n",
    "    txt_pca=PCA(n_components=200), \n",
    "    img_pca=PCA(n_components=200), \n",
    "    model_name=\"CLIP Vision + Text\", \n",
    "    description=\"CLIP Vision + Text Model, Transformer layers 10 to 12 and Final Layer, PCA 200, Single layer linear regression, 8-fold cross validation\", \n",
    "    layers=[10,11,12], # the next 4 layers\n",
    "    last_hidden_state=True # and final layer\n",
    "    )\n",
    "# Run third kfold\n",
    "KFold(folds=8, procedure=kfold_procedure).run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training images: 9841\n",
      "Test images: 159\n",
      "Training captions: 9841\n",
      "Test captions: 159\n",
      "Train image dataloader: 25 batches\n",
      "Test image dataloader: 1 batches\n",
      "Train caption dataloader: 25 batches\n",
      "Test caption dataloader: 1 batches\n",
      "idxs: [10, 11, 12, 13]\n",
      "feature dict keys: dict_keys(['Transformer Layer 10', 'Transformer Layer 11', 'Transformer Layer 12', 'Final Layer'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:41<00:00,  1.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idxs: [10, 11, 12, 13]\n",
      "feature dict keys: dict_keys(['Transformer Layer 10', 'Transformer Layer 11', 'Transformer Layer 12', 'Final Layer'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [02:33<00:00,  6.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left hemisphere neural data loaded. Shape: (9841, 19004)\n",
      "Right hemisphere neural data loaded. Shape: (9841, 20544)\n",
      "#############################################\n",
      "# Fold: 1/ 8\n",
      "# Train size: 8610\n",
      "# Validation size: 1231\n",
      "#############################################\n",
      "> Transformer Layer 10\n",
      "Fitting PCA model for Transformer Layer 10...\n",
      "Fitting linear regression models for Transformer Layer 10...\n",
      "Transforming validation features for Transformer Layer 10...\n",
      "Predicting validation set for Transformer Layer 10...\n",
      "Calculating correlations for Transformer Layer 10...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19004/19004 [00:16<00:00, 1121.59it/s]\n",
      "100%|██████████| 20544/20544 [00:18<00:00, 1138.82it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Transformer Layer 11\n",
      "Fitting PCA model for Transformer Layer 11...\n",
      "Fitting linear regression models for Transformer Layer 11...\n",
      "Transforming validation features for Transformer Layer 11...\n",
      "Predicting validation set for Transformer Layer 11...\n",
      "Calculating correlations for Transformer Layer 11...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19004/19004 [00:16<00:00, 1134.27it/s]\n",
      "100%|██████████| 20544/20544 [00:17<00:00, 1158.85it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Transformer Layer 12\n",
      "Fitting PCA model for Transformer Layer 12...\n",
      "Fitting linear regression models for Transformer Layer 12...\n",
      "Transforming validation features for Transformer Layer 12...\n",
      "Predicting validation set for Transformer Layer 12...\n",
      "Calculating correlations for Transformer Layer 12...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19004/19004 [00:16<00:00, 1128.81it/s]\n",
      "100%|██████████| 20544/20544 [00:17<00:00, 1144.03it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Final Layer\n",
      "Fitting PCA model for Final Layer...\n",
      "Fitting linear regression models for Final Layer...\n",
      "Transforming validation features for Final Layer...\n",
      "Predicting validation set for Final Layer...\n",
      "Calculating correlations for Final Layer...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19004/19004 [00:17<00:00, 1116.38it/s]\n",
      "100%|██████████| 20544/20544 [00:18<00:00, 1091.75it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#############################################\n",
      "# Fold: 2/ 8\n",
      "# Train size: 8611\n",
      "# Validation size: 1230\n",
      "#############################################\n",
      "> Transformer Layer 10\n",
      "Fitting PCA model for Transformer Layer 10...\n",
      "Fitting linear regression models for Transformer Layer 10...\n",
      "Transforming validation features for Transformer Layer 10...\n",
      "Predicting validation set for Transformer Layer 10...\n",
      "Calculating correlations for Transformer Layer 10...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19004/19004 [00:17<00:00, 1100.65it/s]\n",
      "100%|██████████| 20544/20544 [00:18<00:00, 1100.03it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Transformer Layer 11\n",
      "Fitting PCA model for Transformer Layer 11...\n",
      "Fitting linear regression models for Transformer Layer 11...\n",
      "Transforming validation features for Transformer Layer 11...\n",
      "Predicting validation set for Transformer Layer 11...\n",
      "Calculating correlations for Transformer Layer 11...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19004/19004 [00:16<00:00, 1152.78it/s]\n",
      "100%|██████████| 20544/20544 [00:17<00:00, 1159.93it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Transformer Layer 12\n",
      "Fitting PCA model for Transformer Layer 12...\n",
      "Fitting linear regression models for Transformer Layer 12...\n",
      "Transforming validation features for Transformer Layer 12...\n",
      "Predicting validation set for Transformer Layer 12...\n",
      "Calculating correlations for Transformer Layer 12...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19004/19004 [00:16<00:00, 1136.83it/s]\n",
      "100%|██████████| 20544/20544 [00:18<00:00, 1121.05it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Final Layer\n",
      "Fitting PCA model for Final Layer...\n",
      "Fitting linear regression models for Final Layer...\n",
      "Transforming validation features for Final Layer...\n",
      "Predicting validation set for Final Layer...\n",
      "Calculating correlations for Final Layer...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19004/19004 [00:16<00:00, 1137.22it/s]\n",
      "100%|██████████| 20544/20544 [00:18<00:00, 1132.70it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#############################################\n",
      "# Fold: 3/ 8\n",
      "# Train size: 8611\n",
      "# Validation size: 1230\n",
      "#############################################\n",
      "> Transformer Layer 10\n",
      "Fitting PCA model for Transformer Layer 10...\n",
      "Fitting linear regression models for Transformer Layer 10...\n",
      "Transforming validation features for Transformer Layer 10...\n",
      "Predicting validation set for Transformer Layer 10...\n",
      "Calculating correlations for Transformer Layer 10...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19004/19004 [00:17<00:00, 1081.33it/s]\n",
      "100%|██████████| 20544/20544 [00:19<00:00, 1070.39it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Transformer Layer 11\n",
      "Fitting PCA model for Transformer Layer 11...\n",
      "Fitting linear regression models for Transformer Layer 11...\n",
      "Transforming validation features for Transformer Layer 11...\n",
      "Predicting validation set for Transformer Layer 11...\n",
      "Calculating correlations for Transformer Layer 11...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19004/19004 [00:18<00:00, 1044.84it/s]\n",
      "100%|██████████| 20544/20544 [00:18<00:00, 1106.47it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Transformer Layer 12\n",
      "Fitting PCA model for Transformer Layer 12...\n",
      "Fitting linear regression models for Transformer Layer 12...\n",
      "Transforming validation features for Transformer Layer 12...\n",
      "Predicting validation set for Transformer Layer 12...\n",
      "Calculating correlations for Transformer Layer 12...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19004/19004 [00:17<00:00, 1079.66it/s]\n",
      "100%|██████████| 20544/20544 [00:18<00:00, 1087.87it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Final Layer\n",
      "Fitting PCA model for Final Layer...\n",
      "Fitting linear regression models for Final Layer...\n",
      "Transforming validation features for Final Layer...\n",
      "Predicting validation set for Final Layer...\n",
      "Calculating correlations for Final Layer...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19004/19004 [00:17<00:00, 1087.05it/s]\n",
      "100%|██████████| 20544/20544 [00:19<00:00, 1071.70it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#############################################\n",
      "# Fold: 4/ 8\n",
      "# Train size: 8611\n",
      "# Validation size: 1230\n",
      "#############################################\n",
      "> Transformer Layer 10\n",
      "Fitting PCA model for Transformer Layer 10...\n",
      "Fitting linear regression models for Transformer Layer 10...\n",
      "Transforming validation features for Transformer Layer 10...\n",
      "Predicting validation set for Transformer Layer 10...\n",
      "Calculating correlations for Transformer Layer 10...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19004/19004 [00:17<00:00, 1076.53it/s]\n",
      "100%|██████████| 20544/20544 [00:19<00:00, 1038.85it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Transformer Layer 11\n",
      "Fitting PCA model for Transformer Layer 11...\n",
      "Fitting linear regression models for Transformer Layer 11...\n",
      "Transforming validation features for Transformer Layer 11...\n",
      "Predicting validation set for Transformer Layer 11...\n",
      "Calculating correlations for Transformer Layer 11...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19004/19004 [00:17<00:00, 1092.02it/s]\n",
      "100%|██████████| 20544/20544 [00:18<00:00, 1106.14it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Transformer Layer 12\n",
      "Fitting PCA model for Transformer Layer 12...\n",
      "Fitting linear regression models for Transformer Layer 12...\n",
      "Transforming validation features for Transformer Layer 12...\n",
      "Predicting validation set for Transformer Layer 12...\n",
      "Calculating correlations for Transformer Layer 12...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19004/19004 [00:17<00:00, 1103.89it/s]\n",
      "100%|██████████| 20544/20544 [00:19<00:00, 1056.06it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Final Layer\n",
      "Fitting PCA model for Final Layer...\n",
      "Fitting linear regression models for Final Layer...\n",
      "Transforming validation features for Final Layer...\n",
      "Predicting validation set for Final Layer...\n",
      "Calculating correlations for Final Layer...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19004/19004 [00:17<00:00, 1095.95it/s]\n",
      "100%|██████████| 20544/20544 [00:18<00:00, 1115.05it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#############################################\n",
      "# Fold: 5/ 8\n",
      "# Train size: 8611\n",
      "# Validation size: 1230\n",
      "#############################################\n",
      "> Transformer Layer 10\n",
      "Fitting PCA model for Transformer Layer 10...\n",
      "Fitting linear regression models for Transformer Layer 10...\n",
      "Transforming validation features for Transformer Layer 10...\n",
      "Predicting validation set for Transformer Layer 10...\n",
      "Calculating correlations for Transformer Layer 10...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19004/19004 [00:18<00:00, 1027.86it/s]\n",
      "100%|██████████| 20544/20544 [00:19<00:00, 1063.31it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Transformer Layer 11\n",
      "Fitting PCA model for Transformer Layer 11...\n",
      "Fitting linear regression models for Transformer Layer 11...\n",
      "Transforming validation features for Transformer Layer 11...\n",
      "Predicting validation set for Transformer Layer 11...\n",
      "Calculating correlations for Transformer Layer 11...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19004/19004 [00:16<00:00, 1156.14it/s]\n",
      "100%|██████████| 20544/20544 [00:18<00:00, 1112.06it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Transformer Layer 12\n",
      "Fitting PCA model for Transformer Layer 12...\n",
      "Fitting linear regression models for Transformer Layer 12...\n",
      "Transforming validation features for Transformer Layer 12...\n",
      "Predicting validation set for Transformer Layer 12...\n",
      "Calculating correlations for Transformer Layer 12...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19004/19004 [00:17<00:00, 1091.91it/s]\n",
      "100%|██████████| 20544/20544 [00:19<00:00, 1072.27it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Final Layer\n",
      "Fitting PCA model for Final Layer...\n",
      "Fitting linear regression models for Final Layer...\n",
      "Transforming validation features for Final Layer...\n",
      "Predicting validation set for Final Layer...\n",
      "Calculating correlations for Final Layer...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19004/19004 [00:17<00:00, 1086.43it/s]\n",
      "100%|██████████| 20544/20544 [00:19<00:00, 1064.26it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#############################################\n",
      "# Fold: 6/ 8\n",
      "# Train size: 8611\n",
      "# Validation size: 1230\n",
      "#############################################\n",
      "> Transformer Layer 10\n",
      "Fitting PCA model for Transformer Layer 10...\n",
      "Fitting linear regression models for Transformer Layer 10...\n",
      "Transforming validation features for Transformer Layer 10...\n",
      "Predicting validation set for Transformer Layer 10...\n",
      "Calculating correlations for Transformer Layer 10...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19004/19004 [00:17<00:00, 1088.44it/s]\n",
      "100%|██████████| 20544/20544 [00:17<00:00, 1179.68it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Transformer Layer 11\n",
      "Fitting PCA model for Transformer Layer 11...\n",
      "Fitting linear regression models for Transformer Layer 11...\n",
      "Transforming validation features for Transformer Layer 11...\n",
      "Predicting validation set for Transformer Layer 11...\n",
      "Calculating correlations for Transformer Layer 11...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19004/19004 [00:16<00:00, 1119.46it/s]\n",
      "100%|██████████| 20544/20544 [00:17<00:00, 1149.43it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Transformer Layer 12\n",
      "Fitting PCA model for Transformer Layer 12...\n",
      "Fitting linear regression models for Transformer Layer 12...\n",
      "Transforming validation features for Transformer Layer 12...\n",
      "Predicting validation set for Transformer Layer 12...\n",
      "Calculating correlations for Transformer Layer 12...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19004/19004 [00:17<00:00, 1116.77it/s]\n",
      "100%|██████████| 20544/20544 [00:18<00:00, 1112.69it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Final Layer\n",
      "Fitting PCA model for Final Layer...\n",
      "Fitting linear regression models for Final Layer...\n",
      "Transforming validation features for Final Layer...\n",
      "Predicting validation set for Final Layer...\n",
      "Calculating correlations for Final Layer...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19004/19004 [00:16<00:00, 1136.86it/s]\n",
      "100%|██████████| 20544/20544 [00:17<00:00, 1148.23it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#############################################\n",
      "# Fold: 7/ 8\n",
      "# Train size: 8611\n",
      "# Validation size: 1230\n",
      "#############################################\n",
      "> Transformer Layer 10\n",
      "Fitting PCA model for Transformer Layer 10...\n",
      "Fitting linear regression models for Transformer Layer 10...\n",
      "Transforming validation features for Transformer Layer 10...\n",
      "Predicting validation set for Transformer Layer 10...\n",
      "Calculating correlations for Transformer Layer 10...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19004/19004 [00:17<00:00, 1108.14it/s]\n",
      "100%|██████████| 20544/20544 [00:18<00:00, 1084.32it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Transformer Layer 11\n",
      "Fitting PCA model for Transformer Layer 11...\n",
      "Fitting linear regression models for Transformer Layer 11...\n",
      "Transforming validation features for Transformer Layer 11...\n",
      "Predicting validation set for Transformer Layer 11...\n",
      "Calculating correlations for Transformer Layer 11...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19004/19004 [00:17<00:00, 1077.49it/s]\n",
      "100%|██████████| 20544/20544 [00:19<00:00, 1080.62it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Transformer Layer 12\n",
      "Fitting PCA model for Transformer Layer 12...\n",
      "Fitting linear regression models for Transformer Layer 12...\n",
      "Transforming validation features for Transformer Layer 12...\n",
      "Predicting validation set for Transformer Layer 12...\n",
      "Calculating correlations for Transformer Layer 12...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19004/19004 [00:18<00:00, 1035.44it/s]\n",
      "100%|██████████| 20544/20544 [00:18<00:00, 1092.36it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Final Layer\n",
      "Fitting PCA model for Final Layer...\n",
      "Fitting linear regression models for Final Layer...\n",
      "Transforming validation features for Final Layer...\n",
      "Predicting validation set for Final Layer...\n",
      "Calculating correlations for Final Layer...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19004/19004 [00:17<00:00, 1105.09it/s]\n",
      "100%|██████████| 20544/20544 [00:18<00:00, 1088.41it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#############################################\n",
      "# Fold: 8/ 8\n",
      "# Train size: 8611\n",
      "# Validation size: 1230\n",
      "#############################################\n",
      "> Transformer Layer 10\n",
      "Fitting PCA model for Transformer Layer 10...\n",
      "Fitting linear regression models for Transformer Layer 10...\n",
      "Transforming validation features for Transformer Layer 10...\n",
      "Predicting validation set for Transformer Layer 10...\n",
      "Calculating correlations for Transformer Layer 10...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19004/19004 [00:17<00:00, 1090.88it/s]\n",
      "100%|██████████| 20544/20544 [00:18<00:00, 1106.99it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Transformer Layer 11\n",
      "Fitting PCA model for Transformer Layer 11...\n",
      "Fitting linear regression models for Transformer Layer 11...\n",
      "Transforming validation features for Transformer Layer 11...\n",
      "Predicting validation set for Transformer Layer 11...\n",
      "Calculating correlations for Transformer Layer 11...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19004/19004 [00:18<00:00, 1054.01it/s]\n",
      "100%|██████████| 20544/20544 [00:18<00:00, 1094.89it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Transformer Layer 12\n",
      "Fitting PCA model for Transformer Layer 12...\n",
      "Fitting linear regression models for Transformer Layer 12...\n",
      "Transforming validation features for Transformer Layer 12...\n",
      "Predicting validation set for Transformer Layer 12...\n",
      "Calculating correlations for Transformer Layer 12...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19004/19004 [00:17<00:00, 1084.76it/s]\n",
      "100%|██████████| 20544/20544 [00:18<00:00, 1105.22it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Final Layer\n",
      "Fitting PCA model for Final Layer...\n",
      "Fitting linear regression models for Final Layer...\n",
      "Transforming validation features for Final Layer...\n",
      "Predicting validation set for Final Layer...\n",
      "Calculating correlations for Final Layer...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19004/19004 [00:16<00:00, 1134.22it/s]\n",
      "100%|██████████| 20544/20544 [00:18<00:00, 1093.07it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:112: RuntimeWarning: Mean of empty slice\n",
      "  self.mean_correlations[layer][hemi] = np.nanmean([self.fold_correlations[fold][layer][hemi] for fold in range(self.folds)], axis=0)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n",
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_24516\\1260140408.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"model\": self.model_name, \"layer\": layer, \"hemisphere\": hemisphere, \"roi\": self.roi_names[i], \"correlation\": self.mean_correlations[layer][hemisphere][i]}, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "######################### Still need to run this! ###########################\n",
    "subject = Subject(\"subj01\")\n",
    "\n",
    "# Initalize kfold procedure for third batch\n",
    "kfold_procedure = KFoldCombinedCLIPSingleSubject(\n",
    "    subject=subject, \n",
    "    txt_pca=PCA(n_components=200), \n",
    "    img_pca=PCA(n_components=200), \n",
    "    model_name=\"CLIP Vision + Text\", \n",
    "    description=\"CLIP Vision + Text Model, Transformer layers 10 to 12 and Final Layer, PCA 200, Single layer linear regression, 8-fold cross validation\", \n",
    "    layers=[10,11,12], # the next 4 layers\n",
    "    last_hidden_state=True # and final layer\n",
    "    )\n",
    "\n",
    "# Run second kfold\n",
    "KFold(folds=8, procedure=kfold_procedure).run()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLIP Vision Model, Transformer Layer 4 + Transformer Layer 8, PCA200, Linear Regression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of our findings in the first cross validation we decided to compare our best Vision Model (PCA200, Layer 7) with a combined Vision Model (PCA200, Layer4 + Layer8). \n",
    "\n",
    "We ran 8 folds on image data of subject 1. For each iteration the current fold was selected as the validation set and the remaining folds were used as the training set.\n",
    "\n",
    "The validation procedure for each fold was as follows: \n",
    "\n",
    "Preparation\n",
    "\n",
    "- Supplying the training set to a CLIPVisionModel.\n",
    "- Extracting the raw features for Transformer Layers 4, 7 and 8.\n",
    "\n",
    "Looping over all folds\n",
    "- For each fold:\n",
    "    - Assigning training and validation sets for images and fmri activity.\n",
    "    \n",
    "    Layer 7\n",
    "    \n",
    "    - Fit PCA with 200 components using the raw training features of layer 7.\n",
    "    - Transforming the raw training features using the fitted PCA.\n",
    "    - Fitting a linear regression, predicting training fmri activity from the pca transformed training features. (for left and right hemisphere)\n",
    "    - Transforming the raw validation features using the fitted PCA.\n",
    "    - Using the fitted linear models to predict validation fmri activity from the pca transformed validation features. (for left and right hemisphere)\n",
    "    - Calculating correlations between predicted and actual fmri activity for the validation set. (for left and right hemisphere)\n",
    "    - Calculating median correlations for each of the 36 challenge ROI. (for left and right hemisphere)\n",
    "    - Storing the median correlations for each hemisphere for layer 7 for the current fold.\n",
    "\n",
    "    Layers 4 and 8\n",
    "    \n",
    "    - Combine raw training features of layer 4 and 8.\n",
    "    - Fit PCA with 200 components using the combined raw training features of layers 4 and 8.\n",
    "    - Transforming the raw training features using the fitted PCA.\n",
    "    - Fitting a linear regression, predicting training fmri activity from the pca transformed training features. (for left and right hemisphere)\n",
    "    - Transforming the raw validation features using the fitted PCA.\n",
    "    - Using the fitted linear models to predict validation fmri activity from the pca transformed validation features. (for left and right hemisphere)\n",
    "    - Calculating correlations between predicted and actual fmri activity for the validation set. (for left and right hemisphere)\n",
    "    - Calculating median correlations for each of the 36 challenge ROI. (for left and right hemisphere)\n",
    "    - Storing the median correlations for each hemisphere for the combination of layers 4 and 8 for the current fold.\n",
    "    \n",
    "After the validation\n",
    "\n",
    "- Calculating mean median correlations accross all folds for each layer. (for left and right hemisphere)\n",
    "- Plotting the mean median correlations for each layer for each ROI and select the layer with the highest mean median correlation averaged over all ROIs.   \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KFoldProcedure CLass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KFoldVisPCA200L7VersusL4L8(KFoldProcedure):\n",
    "    \"\"\"A procedure that runs k-fold on all layers of a single CLIP model on a single subject.\"\"\"\n",
    "    def __init__(self, \n",
    "                 subject: Subject, \n",
    "                 pca: PCA,\n",
    "                 model_name: str = None,\n",
    "                 description: str = None) -> None:\n",
    "        assert isinstance(subject, Subject), \"subject must be an instance of Subject\"\n",
    "        self.subject = subject\n",
    "        self.pca = pca\n",
    "        self.model_name = model_name\n",
    "        self.description = description\n",
    "        self.correlations = {}\n",
    "        super().__init__()\n",
    "\n",
    "    def prepare(self):\n",
    "        # Prepare data\n",
    "        subject.create_dataloaders()\n",
    "        train_dataloader = subject.train_img_dataloader\n",
    "        \n",
    "        # Extract raw features\n",
    "        feature_extractor = CLIPFeatureExtractor(idxs=[4,7,8], last_hidden_layer=False, model=vis_model, dataloader=train_dataloader)\n",
    "        feature_extractor.extract_raw_features_from_model()\n",
    "        self.raw_features = self.feature_extractor.feature_dict\n",
    "        del feature_extractor # free memory\n",
    "\n",
    "        # Load challenge rois\n",
    "        self.subject.load_challenge_rois()\n",
    "        self.lh_challenge_rois = self.subject.lh_challenge_rois\n",
    "        self.rh_challenge_rois = self.subject.rh_challenge_rois\n",
    "        self.roi_name_maps = self.subject.roi_name_maps\n",
    "\n",
    "        # Load neural data\n",
    "        self.subject.load_neural_data()\n",
    "        self.lh_fmri = self.subject.lh_fmri\n",
    "        self.rh_fmri = self.subject.rh_fmri\n",
    "        self.subject = None # free memory\n",
    "\n",
    "        # Prepare correlation dict\n",
    "        self.fold_correlations = {}\n",
    "\n",
    "    def run(self, train_idxs: np.ndarray, val_idxs: np.ndarray) -> Dict[str, Dict[str, np.ndarray]]:        \n",
    "        correlations = {}\n",
    "\n",
    "        # Assign train and val fmri\n",
    "        train_lh_fmri = self.lh_fmri[train_idxs]\n",
    "        train_rh_fmri = self.rh_fmri[train_idxs]\n",
    "        val_lh_fmri = self.lh_fmri[val_idxs]\n",
    "        val_rh_fmri = self.rh_fmri[val_idxs]\n",
    "        \n",
    "        ####### Layer 7 #######\n",
    "        # Assign train and val features\n",
    "        train_features = self.raw_features[\"Transformer Layer 7\"][train_idxs]\n",
    "        val_features = self.raw_features[\"Transformer Layer 7\"][val_idxs]\n",
    "\n",
    "        # Fit PCA model\n",
    "        train_pca_features = self.pca.fit_transform(torch.tensor(train_features).flatten(1).numpy())\n",
    "        del train_features # free memory\n",
    "\n",
    "        # Fit linear regressions\n",
    "        lh_lin_reg = LinearRegression().fit(train_pca_features, train_lh_fmri)\n",
    "        rh_lin_reg = LinearRegression().fit(train_pca_features, train_rh_fmri)\n",
    "        del train_pca_features # free memory\n",
    "\n",
    "        # Transform validation features\n",
    "        val_txt_pca_features = self.pca.transform(torch.tensor(val_features).flatten(1).numpy())\n",
    "        del val_features # free memory\n",
    "\n",
    "        # Predict validation dict\n",
    "        lh_val_pred = lh_lin_reg.predict(val_txt_pca_features)\n",
    "        rh_val_pred = rh_lin_reg.predict(val_txt_pca_features)\n",
    "        del val_txt_pca_features, lh_lin_reg, rh_lin_reg # free memory\n",
    "\n",
    "        # Calculate correlations\n",
    "        lh_correlation, rh_correlation = self.calculate_correlations(lh_val_pred, rh_val_pred, val_lh_fmri, val_rh_fmri)\n",
    "        lh_median_roi_correlation, rh_median_roi_correlation = self.calculate_median_correlations(lh_correlation, rh_correlation)\n",
    "        \n",
    "        # Store correlations\n",
    "        correlations[\"Transformer Layer 7\"] = {\"lh\": lh_median_roi_correlation, \"rh\": rh_median_roi_correlation} \n",
    "\n",
    "        ####### Layers 4 and 8 #######\n",
    "        # Assign train and val features\n",
    "        train_features = self.raw_features[\"Transformer Layer 4\"][train_idxs]\n",
    "        train_features = np.hstack([train_features, self.raw_features[\"Transformer Layer 8\"][train_idxs]])\n",
    "        val_features = self.raw_features[\"Transformer Layer 4\"][val_idxs]\n",
    "        val_features = np.hstack([val_features, self.raw_features[\"Transformer Layer 8\"][val_idxs]])\n",
    "\n",
    "        # Fit PCA model\n",
    "        train_pca_features = self.pca.fit_transform(torch.tensor(train_features).flatten(1).numpy())\n",
    "        del train_features # free memory\n",
    "\n",
    "        # Fit linear regressions\n",
    "        lh_lin_reg = LinearRegression().fit(train_pca_features, train_lh_fmri)\n",
    "        rh_lin_reg = LinearRegression().fit(train_pca_features, train_rh_fmri)\n",
    "        del train_pca_features # free memory\n",
    "\n",
    "        # Transform validation features\n",
    "        val_txt_pca_features = self.pca.transform(torch.tensor(val_features).flatten(1).numpy())\n",
    "        del val_features # free memory\n",
    "\n",
    "        # Predict validation dict\n",
    "        lh_val_pred = lh_lin_reg.predict(val_txt_pca_features)\n",
    "        rh_val_pred = rh_lin_reg.predict(val_txt_pca_features)\n",
    "        del val_txt_pca_features, lh_lin_reg, rh_lin_reg # free memory\n",
    "\n",
    "        # Calculate correlations\n",
    "        lh_correlation, rh_correlation = self.calculate_correlations(lh_val_pred, rh_val_pred, val_lh_fmri, val_rh_fmri)\n",
    "        lh_median_roi_correlation, rh_median_roi_correlation = self.calculate_median_correlations(lh_correlation, rh_correlation)\n",
    "        \n",
    "        # Store correlations\n",
    "        correlations[\"Transformer Layer 4 + 8\"] = {\"lh\": lh_median_roi_correlation, \"rh\": rh_median_roi_correlation} \n",
    "        return correlations\n",
    "\n",
    "    def return_idxs(self) -> np.ndarray:\n",
    "        return np.arange(len(self.raw_features[list(self.raw_features.keys())[0]])) \n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raise exception to prevent accidental execution\n",
    "raise Exception(\"This code is not meant to be run. It is only meant to be used as a reference for the code used to generate the submission.\")\n",
    "\n",
    "# Initialize required objects\n",
    "subject = Subject(\"subj01\")\n",
    "\n",
    "# Initialize kfold procedure\n",
    "kfold_procedure = KFoldVisPCA200L7VersusL4L8(\n",
    "    subject=subject, \n",
    "    pca=PCA(n_components=200), \n",
    "    model_name=\"CLIP Vision\", \n",
    "    description=\"CLIP Vision, Layer 7 versus Layer 4+8, PCA 200, Linear regression, 8-fold cross validation\", \n",
    "    )\n",
    "\n",
    "# Run kfold\n",
    "KFold(folds=8, procedure=kfold_procedure).run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################## This still needs to run ###################\n",
    "\n",
    "# Initialize required objects\n",
    "subject = Subject(\"subj01\")\n",
    "\n",
    "# Initialize kfold procedure\n",
    "kfold_procedure = KFoldVisPCA200L7VersusL4L8(\n",
    "    subject=subject, \n",
    "    pca=PCA(n_components=200), \n",
    "    model_name=\"CLIP Vision\", \n",
    "    description=\"CLIP Vision, Layer 7 versus Layer 4+8, PCA 200, Linear regression, 8-fold cross validation\", \n",
    "    )\n",
    "\n",
    "# Run kfold\n",
    "KFold(folds=8, procedure=kfold_procedure).run()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge Submissions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We wrote two classes CreateSubmission and SubmissionProcedure to make the process of generating predictions for submission as straight forward as possible. \n",
    "\n",
    "The CreateSubmission class creates folders for submission and loops over all subjects to apply the specific SubmissionProcedure."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First and Second Submission - Vision Only Final Layer/ Text Only Final Layer, PCA 100"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To familiarize ourselves with the CodaLab submission system we selected our first two models without cross validation and used a 90%-10% train-validation split to guide our decision instead. \n",
    "\n",
    "We ended up submitting two linear models based on PCA (100 components) transformed features of the final layer of the CLIPVisionModel (submission score = 43.262) and CLIPTextModel (submission score = 34.210). "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise Exception(\"This code is not meant to be run. It is only meant to be used as a reference for the code used to generate the submission.\")\n",
    "\n",
    "# First test submission\n",
    "subjects = [Subject(f\"subj0{i}\") for i in range(1, 9)]\n",
    "CreateSubmission(subjects, procedure=CLIPVisionFinalLayerPCA100LinearRegression()).run()\n",
    "\n",
    "# Second test submission\n",
    "CreateSubmission(subjects, procedure=CLIPTextFinalLayerPCA100LinearRegression()).run()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Third Submission - Vision Only Layer 7 PCA 200"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our third submission we used the 8-fold cross validation described above [Vision Only Model, PCA200, Linear Regression](#cv_vis_pca200_linreg)\n",
    ". This submission resulted in our highest score to date (49.318)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise Exception(\"This code is not meant to be run. It is only meant to be used as a reference for the code used to generate the submission.\")\n",
    "\n",
    "# Third submission\n",
    "subjects = [Subject(f\"subj0{i}\") for i in range(1, 9)]\n",
    "CreateSubmission(subjects, procedure=CLIPVisionLayer7PCA200LinearRegression()).run()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fourth Submission - Combined Model Layer 7 PCA 200 (PLANNED)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our fourth submission we used the 8-fold cross validation described above [CLIP Text + Vision Model, PCA200, Linear Regression](#cv_txtvis_pca200_linreg). This submission STILL HAS TO BE DONE EXECUTE CODE BELOW."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise Exception(\"This code is not meant to be run. It is only meant to be used as a reference for the code used to generate the submission.\")\n",
    "\n",
    "# Fourth submission\n",
    "subjects = [Subject(f\"subj0{i}\") for i in range(1, 9)]\n",
    "CreateSubmission(subjects, procedure=CLIPCombinedLayer7PCA200LinearRegression()).run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## THIS ACTUALLY STILL HAS TO BE RUN ################\n",
    "# Fourth submission\n",
    "subjects = [Subject(f\"subj0{i}\") for i in range(1, 9)]\n",
    "CreateSubmission(subjects, procedure=CLIPVisionLayer7PCA200LinearRegression()).run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
