{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading packages, setting up gpu, loading models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# required packages\n",
    "from transformers import AutoProcessor, CLIPTextModel, CLIPVisionModel, PreTrainedModel\n",
    "import torch\n",
    "import torch_directml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image\n",
    "import glob\n",
    "import time\n",
    "from sklearn.metrics import euclidean_distances\n",
    "from sklearn.decomposition import IncrementalPCA, PCA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.spatial.distance import squareform\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.stats import pearsonr as corr\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from nilearn import datasets\n",
    "from nilearn import plotting\n",
    "from typing import List, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup cuda device\n",
    "AMD = True\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if AMD:\n",
    "    device = torch_directml.device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at openai/clip-vit-base-patch32 were not used when initializing CLIPVisionModel: ['text_model.encoder.layers.7.self_attn.out_proj.weight', 'text_model.encoder.layers.10.layer_norm2.weight', 'text_model.encoder.layers.0.layer_norm1.bias', 'text_model.encoder.layers.10.self_attn.out_proj.weight', 'text_model.encoder.layers.0.self_attn.k_proj.bias', 'text_model.embeddings.position_ids', 'text_model.encoder.layers.4.layer_norm2.bias', 'text_model.encoder.layers.6.self_attn.out_proj.weight', 'text_model.encoder.layers.2.layer_norm2.bias', 'text_model.encoder.layers.1.mlp.fc1.weight', 'text_model.embeddings.position_embedding.weight', 'text_model.encoder.layers.3.self_attn.v_proj.bias', 'text_model.encoder.layers.3.self_attn.k_proj.bias', 'text_model.encoder.layers.2.mlp.fc1.weight', 'text_model.encoder.layers.3.self_attn.q_proj.weight', 'text_model.encoder.layers.5.mlp.fc2.bias', 'text_model.encoder.layers.3.layer_norm1.bias', 'text_model.encoder.layers.6.mlp.fc2.bias', 'text_model.encoder.layers.1.mlp.fc2.weight', 'text_model.encoder.layers.2.self_attn.q_proj.bias', 'text_model.encoder.layers.5.self_attn.q_proj.weight', 'text_model.encoder.layers.2.layer_norm2.weight', 'text_model.encoder.layers.11.mlp.fc1.weight', 'text_model.encoder.layers.4.self_attn.k_proj.weight', 'text_model.encoder.layers.0.mlp.fc1.bias', 'text_model.encoder.layers.0.self_attn.out_proj.weight', 'text_model.encoder.layers.11.self_attn.q_proj.weight', 'text_model.encoder.layers.11.layer_norm1.bias', 'text_model.encoder.layers.7.layer_norm2.bias', 'text_model.encoder.layers.4.self_attn.v_proj.bias', 'text_model.encoder.layers.5.self_attn.v_proj.weight', 'text_model.embeddings.token_embedding.weight', 'text_model.encoder.layers.8.mlp.fc2.weight', 'text_model.encoder.layers.8.self_attn.v_proj.weight', 'text_model.encoder.layers.7.layer_norm1.weight', 'text_model.encoder.layers.7.mlp.fc1.bias', 'text_model.encoder.layers.1.self_attn.v_proj.weight', 'text_model.encoder.layers.2.mlp.fc2.weight', 'text_model.encoder.layers.11.self_attn.k_proj.bias', 'text_model.encoder.layers.6.mlp.fc1.weight', 'text_model.encoder.layers.3.mlp.fc2.bias', 'text_model.encoder.layers.10.layer_norm1.bias', 'text_model.encoder.layers.2.layer_norm1.weight', 'text_model.encoder.layers.4.self_attn.out_proj.bias', 'text_model.encoder.layers.4.self_attn.q_proj.weight', 'text_model.encoder.layers.6.self_attn.q_proj.bias', 'text_model.encoder.layers.1.self_attn.q_proj.bias', 'text_model.encoder.layers.4.self_attn.v_proj.weight', 'text_model.encoder.layers.1.layer_norm2.bias', 'text_model.encoder.layers.1.self_attn.q_proj.weight', 'text_model.encoder.layers.8.self_attn.q_proj.bias', 'text_model.encoder.layers.4.self_attn.out_proj.weight', 'text_model.encoder.layers.4.layer_norm2.weight', 'text_model.encoder.layers.9.mlp.fc1.weight', 'text_model.encoder.layers.3.mlp.fc2.weight', 'text_model.encoder.layers.11.self_attn.v_proj.weight', 'text_model.encoder.layers.1.self_attn.k_proj.bias', 'text_model.encoder.layers.10.self_attn.q_proj.weight', 'text_model.encoder.layers.0.self_attn.q_proj.weight', 'text_model.final_layer_norm.weight', 'text_model.encoder.layers.10.self_attn.k_proj.weight', 'text_model.encoder.layers.9.layer_norm1.weight', 'text_model.encoder.layers.10.mlp.fc2.weight', 'text_model.encoder.layers.8.layer_norm1.bias', 'text_model.encoder.layers.9.layer_norm2.weight', 'text_model.encoder.layers.6.self_attn.k_proj.weight', 'text_model.encoder.layers.0.self_attn.out_proj.bias', 'text_model.encoder.layers.6.mlp.fc1.bias', 'text_model.encoder.layers.1.mlp.fc1.bias', 'text_model.encoder.layers.9.mlp.fc2.weight', 'text_model.encoder.layers.8.mlp.fc1.bias', 'logit_scale', 'text_model.encoder.layers.8.self_attn.k_proj.bias', 'text_model.encoder.layers.3.mlp.fc1.weight', 'text_model.encoder.layers.5.mlp.fc1.weight', 'text_model.encoder.layers.5.layer_norm2.bias', 'text_model.encoder.layers.0.layer_norm2.weight', 'text_model.encoder.layers.1.mlp.fc2.bias', 'text_model.encoder.layers.1.layer_norm2.weight', 'text_model.encoder.layers.2.mlp.fc2.bias', 'text_model.encoder.layers.6.self_attn.v_proj.weight', 'text_model.encoder.layers.0.self_attn.v_proj.weight', 'text_model.encoder.layers.3.layer_norm2.weight', 'text_model.encoder.layers.11.self_attn.q_proj.bias', 'text_model.encoder.layers.9.self_attn.q_proj.weight', 'text_model.encoder.layers.3.self_attn.out_proj.bias', 'text_model.encoder.layers.0.self_attn.k_proj.weight', 'text_model.encoder.layers.6.self_attn.k_proj.bias', 'text_model.encoder.layers.10.mlp.fc2.bias', 'text_model.encoder.layers.11.mlp.fc2.weight', 'text_model.encoder.layers.11.layer_norm2.bias', 'text_model.encoder.layers.11.self_attn.k_proj.weight', 'text_model.encoder.layers.9.layer_norm1.bias', 'text_model.encoder.layers.4.self_attn.k_proj.bias', 'text_model.encoder.layers.0.self_attn.q_proj.bias', 'text_model.encoder.layers.7.self_attn.k_proj.bias', 'text_model.encoder.layers.7.self_attn.out_proj.bias', 'text_model.encoder.layers.5.layer_norm1.bias', 'text_model.encoder.layers.7.self_attn.k_proj.weight', 'text_model.encoder.layers.7.layer_norm2.weight', 'text_model.encoder.layers.8.self_attn.k_proj.weight', 'text_model.encoder.layers.4.layer_norm1.weight', 'text_model.encoder.layers.9.mlp.fc1.bias', 'text_model.encoder.layers.6.layer_norm2.bias', 'text_model.encoder.layers.10.self_attn.k_proj.bias', 'text_model.encoder.layers.7.mlp.fc1.weight', 'text_model.encoder.layers.4.self_attn.q_proj.bias', 'text_model.encoder.layers.7.self_attn.q_proj.bias', 'text_model.encoder.layers.8.layer_norm1.weight', 'text_model.encoder.layers.0.mlp.fc2.weight', 'text_model.encoder.layers.2.mlp.fc1.bias', 'text_model.encoder.layers.7.self_attn.v_proj.bias', 'text_model.encoder.layers.9.self_attn.q_proj.bias', 'text_model.encoder.layers.5.self_attn.v_proj.bias', 'text_model.encoder.layers.10.layer_norm1.weight', 'text_model.encoder.layers.0.mlp.fc1.weight', 'text_model.encoder.layers.1.self_attn.out_proj.weight', 'text_model.encoder.layers.0.self_attn.v_proj.bias', 'text_model.encoder.layers.10.mlp.fc1.weight', 'text_model.encoder.layers.9.self_attn.out_proj.weight', 'text_model.encoder.layers.10.self_attn.out_proj.bias', 'text_model.encoder.layers.8.mlp.fc2.bias', 'text_model.encoder.layers.2.self_attn.v_proj.bias', 'text_model.encoder.layers.7.mlp.fc2.weight', 'text_model.encoder.layers.2.self_attn.q_proj.weight', 'text_model.encoder.layers.2.self_attn.out_proj.weight', 'text_model.encoder.layers.3.mlp.fc1.bias', 'text_model.encoder.layers.8.self_attn.out_proj.weight', 'text_model.final_layer_norm.bias', 'text_model.encoder.layers.10.mlp.fc1.bias', 'text_model.encoder.layers.8.self_attn.q_proj.weight', 'text_model.encoder.layers.11.layer_norm1.weight', 'text_projection.weight', 'text_model.encoder.layers.9.mlp.fc2.bias', 'text_model.encoder.layers.3.self_attn.q_proj.bias', 'text_model.encoder.layers.11.self_attn.out_proj.bias', 'text_model.encoder.layers.2.self_attn.out_proj.bias', 'text_model.encoder.layers.11.self_attn.v_proj.bias', 'text_model.encoder.layers.11.layer_norm2.weight', 'text_model.encoder.layers.10.layer_norm2.bias', 'text_model.encoder.layers.9.self_attn.out_proj.bias', 'text_model.encoder.layers.11.mlp.fc2.bias', 'text_model.encoder.layers.5.mlp.fc1.bias', 'text_model.encoder.layers.6.layer_norm1.weight', 'text_model.encoder.layers.1.self_attn.k_proj.weight', 'text_model.encoder.layers.8.layer_norm2.weight', 'text_model.encoder.layers.3.layer_norm2.bias', 'text_model.encoder.layers.2.self_attn.k_proj.weight', 'text_model.encoder.layers.5.mlp.fc2.weight', 'text_model.encoder.layers.9.self_attn.v_proj.weight', 'visual_projection.weight', 'text_model.encoder.layers.11.mlp.fc1.bias', 'text_model.encoder.layers.3.self_attn.out_proj.weight', 'text_model.encoder.layers.3.self_attn.v_proj.weight', 'text_model.encoder.layers.6.layer_norm1.bias', 'text_model.encoder.layers.2.self_attn.k_proj.bias', 'text_model.encoder.layers.4.mlp.fc2.bias', 'text_model.encoder.layers.6.layer_norm2.weight', 'text_model.encoder.layers.9.self_attn.k_proj.weight', 'text_model.encoder.layers.5.self_attn.out_proj.weight', 'text_model.encoder.layers.7.self_attn.q_proj.weight', 'text_model.encoder.layers.4.mlp.fc1.bias', 'text_model.encoder.layers.4.mlp.fc1.weight', 'text_model.encoder.layers.8.layer_norm2.bias', 'text_model.encoder.layers.2.layer_norm1.bias', 'text_model.encoder.layers.0.layer_norm1.weight', 'text_model.encoder.layers.5.self_attn.k_proj.bias', 'text_model.encoder.layers.7.mlp.fc2.bias', 'text_model.encoder.layers.6.self_attn.v_proj.bias', 'text_model.encoder.layers.5.layer_norm2.weight', 'text_model.encoder.layers.8.self_attn.out_proj.bias', 'text_model.encoder.layers.1.self_attn.v_proj.bias', 'text_model.encoder.layers.5.self_attn.q_proj.bias', 'text_model.encoder.layers.3.self_attn.k_proj.weight', 'text_model.encoder.layers.10.self_attn.v_proj.weight', 'text_model.encoder.layers.4.mlp.fc2.weight', 'text_model.encoder.layers.7.layer_norm1.bias', 'text_model.encoder.layers.5.layer_norm1.weight', 'text_model.encoder.layers.5.self_attn.out_proj.bias', 'text_model.encoder.layers.6.self_attn.out_proj.bias', 'text_model.encoder.layers.2.self_attn.v_proj.weight', 'text_model.encoder.layers.6.self_attn.q_proj.weight', 'text_model.encoder.layers.7.self_attn.v_proj.weight', 'text_model.encoder.layers.10.self_attn.q_proj.bias', 'text_model.encoder.layers.11.self_attn.out_proj.weight', 'text_model.encoder.layers.3.layer_norm1.weight', 'text_model.encoder.layers.9.self_attn.v_proj.bias', 'text_model.encoder.layers.10.self_attn.v_proj.bias', 'text_model.encoder.layers.9.self_attn.k_proj.bias', 'text_model.encoder.layers.0.layer_norm2.bias', 'text_model.encoder.layers.4.layer_norm1.bias', 'text_model.encoder.layers.0.mlp.fc2.bias', 'text_model.encoder.layers.6.mlp.fc2.weight', 'text_model.encoder.layers.1.self_attn.out_proj.bias', 'text_model.encoder.layers.8.mlp.fc1.weight', 'text_model.encoder.layers.8.self_attn.v_proj.bias', 'text_model.encoder.layers.9.layer_norm2.bias', 'text_model.encoder.layers.1.layer_norm1.bias', 'text_model.encoder.layers.1.layer_norm1.weight', 'text_model.encoder.layers.5.self_attn.k_proj.weight']\n",
      "- This IS expected if you are initializing CLIPVisionModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CLIPVisionModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CLIPVisionModel(\n",
       "  (vision_model): CLIPVisionTransformer(\n",
       "    (embeddings): CLIPVisionEmbeddings(\n",
       "      (patch_embedding): Conv2d(3, 768, kernel_size=(32, 32), stride=(32, 32), bias=False)\n",
       "      (position_embedding): Embedding(50, 768)\n",
       "    )\n",
       "    (pre_layrnorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (encoder): CLIPEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (6): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (7): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (8): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (9): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (10): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (11): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (post_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global vis_model\n",
    "vis_model = CLIPVisionModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "vis_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at openai/clip-vit-base-patch32 were not used when initializing CLIPTextModel: ['vision_model.encoder.layers.8.self_attn.q_proj.weight', 'vision_model.encoder.layers.1.self_attn.q_proj.bias', 'vision_model.encoder.layers.6.layer_norm1.weight', 'vision_model.encoder.layers.8.self_attn.v_proj.bias', 'vision_model.encoder.layers.2.self_attn.out_proj.weight', 'vision_model.post_layernorm.weight', 'vision_model.encoder.layers.9.mlp.fc1.weight', 'vision_model.encoder.layers.5.mlp.fc1.bias', 'vision_model.encoder.layers.9.self_attn.q_proj.bias', 'vision_model.encoder.layers.3.self_attn.k_proj.weight', 'vision_model.encoder.layers.0.mlp.fc2.bias', 'vision_model.encoder.layers.3.mlp.fc1.weight', 'vision_model.encoder.layers.11.layer_norm2.weight', 'vision_model.encoder.layers.1.mlp.fc1.weight', 'vision_model.encoder.layers.5.mlp.fc1.weight', 'vision_model.encoder.layers.4.layer_norm2.weight', 'vision_model.encoder.layers.2.self_attn.k_proj.weight', 'vision_model.encoder.layers.4.self_attn.out_proj.bias', 'vision_model.encoder.layers.7.mlp.fc1.weight', 'vision_model.encoder.layers.5.mlp.fc2.bias', 'vision_model.encoder.layers.11.layer_norm2.bias', 'vision_model.encoder.layers.7.mlp.fc1.bias', 'vision_model.encoder.layers.6.mlp.fc1.bias', 'vision_model.encoder.layers.4.self_attn.v_proj.bias', 'vision_model.encoder.layers.6.self_attn.k_proj.weight', 'vision_model.encoder.layers.10.self_attn.v_proj.weight', 'vision_model.encoder.layers.6.self_attn.v_proj.weight', 'vision_model.embeddings.position_ids', 'vision_model.encoder.layers.9.mlp.fc2.weight', 'vision_model.encoder.layers.9.layer_norm1.bias', 'vision_model.encoder.layers.4.mlp.fc2.bias', 'vision_model.encoder.layers.1.self_attn.v_proj.weight', 'vision_model.encoder.layers.10.mlp.fc2.weight', 'vision_model.encoder.layers.5.layer_norm2.bias', 'vision_model.encoder.layers.1.layer_norm1.bias', 'vision_model.encoder.layers.7.layer_norm1.bias', 'vision_model.embeddings.patch_embedding.weight', 'vision_model.encoder.layers.5.self_attn.q_proj.bias', 'vision_model.encoder.layers.8.mlp.fc2.weight', 'vision_model.encoder.layers.6.self_attn.q_proj.bias', 'vision_model.encoder.layers.1.mlp.fc2.weight', 'vision_model.encoder.layers.1.self_attn.out_proj.bias', 'vision_model.encoder.layers.10.self_attn.q_proj.bias', 'vision_model.encoder.layers.3.self_attn.out_proj.bias', 'vision_model.encoder.layers.2.layer_norm1.weight', 'vision_model.encoder.layers.0.layer_norm1.weight', 'vision_model.encoder.layers.7.self_attn.q_proj.bias', 'vision_model.encoder.layers.0.mlp.fc2.weight', 'vision_model.encoder.layers.4.layer_norm1.bias', 'vision_model.encoder.layers.0.self_attn.out_proj.weight', 'vision_model.encoder.layers.10.layer_norm1.weight', 'vision_model.encoder.layers.2.mlp.fc2.bias', 'vision_model.encoder.layers.0.layer_norm2.weight', 'vision_model.encoder.layers.9.self_attn.k_proj.bias', 'vision_model.encoder.layers.0.mlp.fc1.weight', 'vision_model.encoder.layers.4.self_attn.k_proj.weight', 'vision_model.encoder.layers.10.self_attn.v_proj.bias', 'vision_model.encoder.layers.11.layer_norm1.weight', 'logit_scale', 'vision_model.encoder.layers.0.mlp.fc1.bias', 'vision_model.encoder.layers.3.self_attn.k_proj.bias', 'vision_model.encoder.layers.5.self_attn.k_proj.weight', 'vision_model.encoder.layers.5.layer_norm1.weight', 'vision_model.encoder.layers.10.layer_norm1.bias', 'vision_model.encoder.layers.3.self_attn.out_proj.weight', 'vision_model.encoder.layers.5.self_attn.v_proj.bias', 'vision_model.encoder.layers.11.self_attn.q_proj.bias', 'vision_model.encoder.layers.10.layer_norm2.weight', 'vision_model.encoder.layers.9.self_attn.q_proj.weight', 'vision_model.encoder.layers.8.mlp.fc1.weight', 'vision_model.encoder.layers.10.self_attn.out_proj.bias', 'vision_model.encoder.layers.1.layer_norm2.bias', 'vision_model.encoder.layers.7.self_attn.v_proj.bias', 'vision_model.encoder.layers.9.self_attn.out_proj.weight', 'vision_model.encoder.layers.6.self_attn.out_proj.weight', 'vision_model.encoder.layers.0.layer_norm2.bias', 'vision_model.encoder.layers.5.self_attn.v_proj.weight', 'vision_model.encoder.layers.8.mlp.fc1.bias', 'vision_model.encoder.layers.7.mlp.fc2.weight', 'vision_model.encoder.layers.10.self_attn.out_proj.weight', 'vision_model.encoder.layers.9.layer_norm2.weight', 'vision_model.encoder.layers.11.mlp.fc1.weight', 'vision_model.encoder.layers.4.self_attn.k_proj.bias', 'vision_model.encoder.layers.5.self_attn.out_proj.weight', 'vision_model.encoder.layers.11.mlp.fc1.bias', 'vision_model.encoder.layers.3.layer_norm1.bias', 'vision_model.encoder.layers.9.self_attn.out_proj.bias', 'vision_model.encoder.layers.7.self_attn.q_proj.weight', 'vision_model.encoder.layers.3.layer_norm1.weight', 'vision_model.encoder.layers.0.self_attn.q_proj.bias', 'vision_model.encoder.layers.5.self_attn.k_proj.bias', 'vision_model.encoder.layers.7.self_attn.k_proj.bias', 'vision_model.encoder.layers.11.self_attn.q_proj.weight', 'vision_model.encoder.layers.5.layer_norm1.bias', 'vision_model.encoder.layers.11.self_attn.k_proj.bias', 'vision_model.encoder.layers.4.self_attn.q_proj.bias', 'vision_model.encoder.layers.7.self_attn.out_proj.bias', 'vision_model.encoder.layers.0.self_attn.k_proj.bias', 'vision_model.encoder.layers.9.self_attn.k_proj.weight', 'vision_model.encoder.layers.6.self_attn.q_proj.weight', 'vision_model.encoder.layers.1.layer_norm1.weight', 'vision_model.encoder.layers.3.layer_norm2.bias', 'vision_model.encoder.layers.11.self_attn.v_proj.bias', 'vision_model.encoder.layers.11.layer_norm1.bias', 'vision_model.encoder.layers.0.self_attn.q_proj.weight', 'vision_model.encoder.layers.1.self_attn.out_proj.weight', 'vision_model.encoder.layers.7.mlp.fc2.bias', 'vision_model.encoder.layers.8.layer_norm1.weight', 'vision_model.encoder.layers.6.layer_norm2.bias', 'vision_model.pre_layrnorm.bias', 'vision_model.encoder.layers.4.mlp.fc1.bias', 'vision_model.encoder.layers.8.self_attn.q_proj.bias', 'vision_model.encoder.layers.8.mlp.fc2.bias', 'vision_model.encoder.layers.4.self_attn.out_proj.weight', 'vision_model.encoder.layers.9.layer_norm1.weight', 'vision_model.encoder.layers.3.self_attn.v_proj.weight', 'vision_model.encoder.layers.3.self_attn.q_proj.bias', 'vision_model.encoder.layers.7.layer_norm2.weight', 'vision_model.encoder.layers.2.mlp.fc1.bias', 'vision_model.encoder.layers.10.self_attn.k_proj.bias', 'vision_model.encoder.layers.6.mlp.fc2.weight', 'vision_model.encoder.layers.2.mlp.fc2.weight', 'text_projection.weight', 'vision_model.encoder.layers.7.layer_norm1.weight', 'vision_model.encoder.layers.2.layer_norm2.bias', 'vision_model.encoder.layers.8.self_attn.out_proj.bias', 'vision_model.encoder.layers.8.self_attn.k_proj.weight', 'vision_model.pre_layrnorm.weight', 'vision_model.encoder.layers.2.self_attn.v_proj.bias', 'vision_model.encoder.layers.0.layer_norm1.bias', 'vision_model.encoder.layers.8.self_attn.out_proj.weight', 'vision_model.encoder.layers.1.self_attn.k_proj.bias', 'vision_model.embeddings.position_embedding.weight', 'vision_model.encoder.layers.4.mlp.fc1.weight', 'vision_model.encoder.layers.4.mlp.fc2.weight', 'vision_model.encoder.layers.4.self_attn.v_proj.weight', 'vision_model.encoder.layers.7.self_attn.out_proj.weight', 'vision_model.encoder.layers.11.self_attn.out_proj.weight', 'vision_model.encoder.layers.9.self_attn.v_proj.bias', 'vision_model.encoder.layers.8.layer_norm2.bias', 'vision_model.encoder.layers.6.self_attn.k_proj.bias', 'visual_projection.weight', 'vision_model.encoder.layers.0.self_attn.v_proj.weight', 'vision_model.encoder.layers.2.self_attn.k_proj.bias', 'vision_model.encoder.layers.1.mlp.fc2.bias', 'vision_model.encoder.layers.7.self_attn.v_proj.weight', 'vision_model.encoder.layers.6.layer_norm2.weight', 'vision_model.encoder.layers.3.self_attn.v_proj.bias', 'vision_model.encoder.layers.7.layer_norm2.bias', 'vision_model.encoder.layers.11.self_attn.out_proj.bias', 'vision_model.encoder.layers.4.layer_norm1.weight', 'vision_model.encoder.layers.9.layer_norm2.bias', 'vision_model.encoder.layers.1.self_attn.q_proj.weight', 'vision_model.encoder.layers.8.self_attn.v_proj.weight', 'vision_model.encoder.layers.7.self_attn.k_proj.weight', 'vision_model.encoder.layers.0.self_attn.v_proj.bias', 'vision_model.encoder.layers.2.self_attn.out_proj.bias', 'vision_model.encoder.layers.5.layer_norm2.weight', 'vision_model.post_layernorm.bias', 'vision_model.encoder.layers.11.mlp.fc2.bias', 'vision_model.encoder.layers.1.mlp.fc1.bias', 'vision_model.encoder.layers.2.self_attn.v_proj.weight', 'vision_model.encoder.layers.6.mlp.fc2.bias', 'vision_model.encoder.layers.2.self_attn.q_proj.bias', 'vision_model.encoder.layers.2.layer_norm1.bias', 'vision_model.encoder.layers.4.self_attn.q_proj.weight', 'vision_model.encoder.layers.10.mlp.fc2.bias', 'vision_model.encoder.layers.9.self_attn.v_proj.weight', 'vision_model.encoder.layers.6.self_attn.out_proj.bias', 'vision_model.encoder.layers.10.mlp.fc1.weight', 'vision_model.encoder.layers.1.self_attn.k_proj.weight', 'vision_model.encoder.layers.6.mlp.fc1.weight', 'vision_model.encoder.layers.3.mlp.fc1.bias', 'vision_model.encoder.layers.10.self_attn.q_proj.weight', 'vision_model.encoder.layers.3.mlp.fc2.weight', 'vision_model.encoder.layers.8.layer_norm2.weight', 'vision_model.encoder.layers.1.layer_norm2.weight', 'vision_model.encoder.layers.8.layer_norm1.bias', 'vision_model.encoder.layers.9.mlp.fc1.bias', 'vision_model.encoder.layers.2.layer_norm2.weight', 'vision_model.encoder.layers.3.layer_norm2.weight', 'vision_model.encoder.layers.11.self_attn.v_proj.weight', 'vision_model.encoder.layers.2.mlp.fc1.weight', 'vision_model.encoder.layers.2.self_attn.q_proj.weight', 'vision_model.encoder.layers.8.self_attn.k_proj.bias', 'vision_model.encoder.layers.4.layer_norm2.bias', 'vision_model.encoder.layers.10.layer_norm2.bias', 'vision_model.encoder.layers.0.self_attn.k_proj.weight', 'vision_model.encoder.layers.6.self_attn.v_proj.bias', 'vision_model.encoder.layers.0.self_attn.out_proj.bias', 'vision_model.encoder.layers.11.mlp.fc2.weight', 'vision_model.encoder.layers.5.self_attn.out_proj.bias', 'vision_model.embeddings.class_embedding', 'vision_model.encoder.layers.9.mlp.fc2.bias', 'vision_model.encoder.layers.3.self_attn.q_proj.weight', 'vision_model.encoder.layers.3.mlp.fc2.bias', 'vision_model.encoder.layers.6.layer_norm1.bias', 'vision_model.encoder.layers.5.self_attn.q_proj.weight', 'vision_model.encoder.layers.5.mlp.fc2.weight', 'vision_model.encoder.layers.10.self_attn.k_proj.weight', 'vision_model.encoder.layers.10.mlp.fc1.bias', 'vision_model.encoder.layers.11.self_attn.k_proj.weight', 'vision_model.encoder.layers.1.self_attn.v_proj.bias']\n",
      "- This IS expected if you are initializing CLIPTextModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CLIPTextModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CLIPTextModel(\n",
       "  (text_model): CLIPTextTransformer(\n",
       "    (embeddings): CLIPTextEmbeddings(\n",
       "      (token_embedding): Embedding(49408, 512)\n",
       "      (position_embedding): Embedding(77, 512)\n",
       "    )\n",
       "    (encoder): CLIPEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (6): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (7): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (8): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (9): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (10): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (11): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global txt_model\n",
    "txt_model = CLIPTextModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "txt_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Models\n",
    "global processor\n",
    "processor = AutoProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Classes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ImageDataset & TextDataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ImageDataset and TextDataset classes are used to create datasets for torch dataloaders.\n",
    "The ImageDataset is used for the images and the TextDataset for the captions of the coco images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Classes for Batching\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, image_list, processor):\n",
    "        self.image_list = image_list\n",
    "        self.processor = processor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.image_list[idx])\n",
    "        image = self.processor(images=image, return_tensors=\"pt\", padding=True)\n",
    "        return image[\"pixel_values\"].squeeze()\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, text, max_length, processor):\n",
    "        self.text = processor(text=text, return_tensors=\"pt\", padding=\"max_length\", max_length=max_length)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text[\"input_ids\"])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.text[\"input_ids\"][idx]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subject Class"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Subject class is initialized with a valid subject id (e.g., \"subj01\"). It stores all relevant paths and can load the data for the given subject."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Subject:\n",
    "    \"\"\"Class to access all relevant data for a given subject\"\"\"\n",
    "    def __init__(self, subject=\"subj01\"):\n",
    "        assert subject in [\"subj01\", \"subj02\", \"subj03\", \"subj04\", \"subj05\", \"subj06\", \"subj07\", \"subj08\",], \"Invalid subject\"\n",
    "        self.subject = subject\n",
    "        self.data_dir = \"data/algonauts_2023_challenge_data\"\n",
    "        self.training_images_dir = f\"{self.data_dir}/{subject}/training_split/training_images\"\n",
    "        self.test_images_dir = f\"{self.data_dir}/{subject}/test_split/test_images\"\n",
    "        self.training_fmri_dir = f\"{self.data_dir}/{subject}/training_split/training_fmri\"\n",
    "        self.roi_masks_dir = f\"{self.data_dir}/{subject}/roi_masks\"\n",
    "        self.submission_dir = f\"algonauts_2023_challenge_submission\"\n",
    "        # Load these as needed\n",
    "        self.train_img_list = None\n",
    "        self.test_img_list = None\n",
    "        self.train_cap_list = None\n",
    "        self.test_cap_list = None\n",
    "        self.lh_fmri = None\n",
    "        self.rh_fmri = None\n",
    "        self.lh_roi_masks = None\n",
    "        self.rh_roi_masks = None\n",
    "        self.roi_name_maps = None\n",
    "        self.lh_challenge_rois = None\n",
    "        self.rh_challenge_rois = None\n",
    "        self.train_img_dataloader = None\n",
    "        self.test_img_dataloader = None\n",
    "        self.train_cap_dataloader = None\n",
    "        self.test_cap_dataloader = None            \n",
    "        \n",
    "    def load_image_paths(self) -> None:\n",
    "        \"\"\"Loads the image paths from the training and test directories\"\"\"\n",
    "        self.train_img_list = glob.glob(f\"{self.training_images_dir}/*.png\")\n",
    "        self.train_img_list.sort()\n",
    "        self.test_img_list = glob.glob(f\"{self.test_images_dir}/*.png\")\n",
    "        self.test_img_list.sort()\n",
    "        print(f\"Training images: {len(self.train_img_list)}\")\n",
    "        print(f\"Test images: {len(self.test_img_list)}\")\n",
    "\n",
    "    def load_captions(self) -> None:\n",
    "        \"\"\"Loads and matches the captions from the csv file\"\"\"\n",
    "        if self.train_img_list is None:\n",
    "            self.load_image_paths()\n",
    "        train_cap_file = pd.read_csv(f'{self.data_dir}/algonauts_2023_caption_data.csv')\n",
    "        img_match = [int(i[-9:-4]) for i in self.train_img_list]\n",
    "        self.train_cap_list = train_cap_file[(train_cap_file['subject'] == self.subject) & (train_cap_file['nsdId'].isin(img_match))]['caption'].tolist()\n",
    "        self.test_cap_list = train_cap_file[(train_cap_file['subject'] == self.subject) & (~train_cap_file['nsdId'].isin(img_match))]['caption'].tolist()\n",
    "        print(f\"Training captions: {len(self.train_cap_list)}\")\n",
    "        print(f\"Test captions: {len(self.test_cap_list)}\")\n",
    "    \n",
    "    def load_neural_data(self) -> None:\n",
    "        \"\"\"Loads the neural data from the .npy files\"\"\"\n",
    "        self.lh_fmri = np.load(f\"{self.training_fmri_dir}/lh_training_fmri.npy\")\n",
    "        self.rh_fmri = np.load(f\"{self.training_fmri_dir}/rh_training_fmri.npy\")\n",
    "        print(f\"Left hemisphere neural data loaded. Shape: {self.lh_fmri.shape}\")\n",
    "        print(f\"Right hemisphere neural data loaded. Shape: {self.rh_fmri.shape}\")\n",
    "\n",
    "    def create_dataloaders(self, processor, batch_size) -> None:\n",
    "        \"\"\"Creates the dataloaders for the images and captions\"\"\"\n",
    "        if self.train_img_list is None:\n",
    "            self.load_image_paths()\n",
    "        if self.train_cap_list is None:\n",
    "            self.load_captions()\n",
    "        max_caption_len = processor(text=self.train_cap_list + self.test_cap_list, return_tensors=\"pt\", padding=True)[\"input_ids\"].shape[1]   \n",
    "        train_txt_dataset = TextDataset(self.train_cap_list, max_caption_len, processor)\n",
    "        test_txt_dataset = TextDataset(self.test_cap_list, max_caption_len, processor)\n",
    "        train_img_dataset = ImageDataset(self.train_img_list, processor)\n",
    "        test_img_dataset = ImageDataset(self.test_img_list, processor)\n",
    "        self.train_img_dataloader = DataLoader(train_img_dataset, batch_size=batch_size, shuffle=False)\n",
    "        self.test_img_dataloader = DataLoader(test_img_dataset, batch_size=batch_size, shuffle=False)\n",
    "        self.train_txt_dataloader = DataLoader(train_txt_dataset, batch_size=batch_size, shuffle=False)\n",
    "        self.test_txt_dataloader = DataLoader(test_txt_dataset, batch_size=batch_size, shuffle=False)\n",
    "        print(f\"Train image dataloader: {len(self.train_img_dataloader)} batches\")\n",
    "        print(f\"Test image dataloader: {len(self.test_img_dataloader)} batches\")\n",
    "        print(f\"Train caption dataloader: {len(self.train_txt_dataloader)} batches\")\n",
    "        print(f\"Test caption dataloader: {len(self.test_txt_dataloader)} batches\")\n",
    "\n",
    "    def load_challenge_rois(self) -> None:\n",
    "        \"\"\"Loads the challenge rois from the .npy files\"\"\"\n",
    "        # Load the ROI classes mapping dictionaries\n",
    "        roi_mapping_files = ['mapping_prf-visualrois.npy', 'mapping_floc-bodies.npy',\n",
    "            'mapping_floc-faces.npy', 'mapping_floc-places.npy',\n",
    "            'mapping_floc-words.npy', 'mapping_streams.npy']\n",
    "        self.roi_name_maps = []\n",
    "        for r in roi_mapping_files:\n",
    "            self.roi_name_maps.append(np.load(f\"{self.roi_masks_dir}/{r}\", allow_pickle=True).item())\n",
    "\n",
    "        # Load the ROI brain surface maps\n",
    "        lh_challenge_roi_files = ['lh.prf-visualrois_challenge_space.npy',\n",
    "            'lh.floc-bodies_challenge_space.npy', 'lh.floc-faces_challenge_space.npy',\n",
    "            'lh.floc-places_challenge_space.npy', 'lh.floc-words_challenge_space.npy',\n",
    "            'lh.streams_challenge_space.npy']\n",
    "        rh_challenge_roi_files = ['rh.prf-visualrois_challenge_space.npy',\n",
    "            'rh.floc-bodies_challenge_space.npy', 'rh.floc-faces_challenge_space.npy',\n",
    "            'rh.floc-places_challenge_space.npy', 'rh.floc-words_challenge_space.npy',\n",
    "            'rh.streams_challenge_space.npy']\n",
    "        self.lh_challenge_rois = []\n",
    "        self.rh_challenge_rois = []\n",
    "        for r in range(len(lh_challenge_roi_files)):\n",
    "            self.lh_challenge_rois.append(np.load(f\"{self.roi_masks_dir}/{lh_challenge_roi_files[r]}\"))\n",
    "            self.rh_challenge_rois.append(np.load(f\"{self.roi_masks_dir}/{rh_challenge_roi_files[r]}\"))\n",
    "\n",
    "    def load_roi_masks(self, roi=\"V1v\", hemisphere=\"lh\"):\n",
    "        valid_roi = [\"V1v\", \"V1d\", \"V2v\", \"V2d\", \"V3v\", \n",
    "                     \"V3d\", \"hV4\", \"EBA\", \"FBA-1\", \"FBA-2\", \n",
    "                     \"mTL-bodies\", \"OFA\", \"FFA-1\", \"FFA-2\", \n",
    "                     \"mTL-faces\", \"aTL-faces\", \"OPA\", \"PPA\", \n",
    "                     \"RSC\", \"OWFA\", \"VWFA-1\", \"VWFA-2\", \"mfs-words\", \n",
    "                     \"mTL-words\", \"early\", \"midventral\", \"midlateral\", \n",
    "                     \"midparietal\", \"ventral\", \"lateral\", \"parietal\",\n",
    "                     \"all-vertices\"]\n",
    "        valid_hemisphere = [\"lh\", \"rh\"]\n",
    "        assert roi in valid_roi, \"Invalid ROI\"\n",
    "        assert hemisphere in valid_hemisphere, \"Invalid hemisphere\"\n",
    "\n",
    "        # Define the ROI class based on the selected ROI\n",
    "        if roi in [\"V1v\", \"V1d\", \"V2v\", \"V2d\", \"V3v\", \"V3d\", \"hV4\"]:\n",
    "            roi_class = 'prf-visualrois'\n",
    "        elif roi in [\"EBA\", \"FBA-1\", \"FBA-2\", \"mTL-bodies\"]:\n",
    "            roi_class = 'floc-bodies'\n",
    "        elif roi in [\"OFA\", \"FFA-1\", \"FFA-2\", \"mTL-faces\", \"aTL-faces\"]:\n",
    "            roi_class = 'floc-faces'\n",
    "        elif roi in [\"OPA\", \"PPA\", \"RSC\"]:\n",
    "            roi_class = 'floc-places'\n",
    "        elif roi in [\"OWFA\", \"VWFA-1\", \"VWFA-2\", \"mfs-words\", \"mTL-words\"]:\n",
    "            roi_class = 'floc-words'\n",
    "        elif roi in [\"early\", \"midventral\", \"midlateral\", \"midparietal\", \"ventral\", \"lateral\", \"parietal\"]:\n",
    "            roi_class = 'streams'\n",
    "        else:\n",
    "            roi_class = roi\n",
    "        roi_class_dir = f\"{hemisphere}.{roi_class}_fsaverage_space.npy\"\n",
    "        roi_map_dir = f\"mapping_{roi_class}.npy\"\n",
    "        fsaverage_roi_class = np.load(f\"{self.roi_masks_dir}/{roi_class_dir}\")\n",
    "        roi_map = None\n",
    "        if roi != \"all-vertices\":\n",
    "            roi_map = np.load(f\"{self.roi_masks_dir}/{roi_map_dir}\", allow_pickle=True).item()\n",
    "        return fsaverage_roi_class, roi_map"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CLIPFeatureExtractor Class"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CLIPFeatureExtractor class is used to extract the hidden states from a clip model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CLIPFeatureExtractor():\n",
    "    \"\"\"Extracts the features from hidden states of a CLIP model.\"\"\"\n",
    "    def __init__(\n",
    "            self, \n",
    "            idxs: list = [i for i in range(13)], # hidden layer indices to extract features from. Standard CLIP has an embedding layer and 12 transformer layers.\n",
    "            last_hidden_layer: bool = False, # whether to extract features from the last hidden layer\n",
    "            model: PreTrainedModel = None, # CLIP model\n",
    "            dataloader: DataLoader = None, # dataloader for batching\n",
    "            ) -> None:\n",
    "        self.idxs = idxs\n",
    "        self.last_hidden_layer = last_hidden_layer\n",
    "        self.generate_feature_dict()\n",
    "        if self.last_hidden_layer:\n",
    "            self.idxs.append(13) # adds an additional idx to allow for loop zip()\n",
    "        self.model = model\n",
    "        self.dataloader = dataloader\n",
    "    \n",
    "    def generate_feature_dict(self) -> None:\n",
    "        \"\"\"Generates a feature dict according to the idxs and last_hidden_layer attributes.\"\"\"\n",
    "        feature_dict = {}\n",
    "        for idx in self.idxs:\n",
    "            if idx == 0:\n",
    "                feature_dict[\"Embedding Layer\"] = None\n",
    "            else:\n",
    "                feature_dict[f\"Transformer Layer {idx}\"] = None\n",
    "        if self.last_hidden_layer:\n",
    "            feature_dict[\"Final Layer\"] = None\n",
    "        self.feature_dict = feature_dict\n",
    "    \n",
    "    def concat_features(self, features: dict) -> None:\n",
    "        \"\"\"Adds extracted features to the feature dict.\n",
    "        Args:\n",
    "            features: features extracted from the output of a CLIP model\"\"\"\n",
    "        keys = list(self.feature_dict.keys())\n",
    "        # check if feature_dict is empty\n",
    "        if self.feature_dict[keys[0]] is None:\n",
    "            self.feature_dict = features\n",
    "        else:\n",
    "            for key in keys:\n",
    "                self.feature_dict[key] = np.concatenate((self.feature_dict[key], features[key]), axis=0)\n",
    "\n",
    "    def extract_raw_features(self, output) -> None: \n",
    "        \"\"\"Extracts features from the hidden states of a CLIP model and concates them to the feature_dict.\n",
    "        Args:\n",
    "            output: output of a CLIP model\n",
    "        \"\"\"\n",
    "        features = {}\n",
    "        for idx, key in zip(self.idxs, self.feature_dict.keys()):\n",
    "            if key == \"Final Layer\":\n",
    "                features[key] = output.last_hidden_state.cpu().detach().numpy()\n",
    "            else:\n",
    "                features[key] = output.hidden_states[idx].cpu().detach().numpy()\n",
    "        self.concat_features(features)\n",
    "    \n",
    "    def extract_raw_features_from_model(self) -> None:\n",
    "        \"\"\"Runs the CLIP model on the dataloader and extracts features from the hidden states.\"\"\"\n",
    "        self.model = self.model.to(device)\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(self.dataloader):\n",
    "                batch = batch.to(device)\n",
    "                output = self.model(batch, output_hidden_states=True)\n",
    "                self.extract_raw_features(output)\n",
    "                batch = None # clear batch from memory\n",
    "                output = None # clear output from memory\n",
    "        self.model = self.model.to(\"cpu\")        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KFoldProcedure & KFold Classes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The KFoldProcedure class is used to define a procedure that is supposed to be executed during each fold of the k-fold validation. \n",
    "It can be supplied to a KFold class which executes its run() function on all folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KFoldProcedure:\n",
    "    \"\"\"This class is used to define a procedure that is run on each fold of a k-fold cross validation.\"\"\"\n",
    "    def __init__(self) -> None:\n",
    "        self.roi_names = []\n",
    "\n",
    "    def prepare(self) -> None:\n",
    "        \"\"\"Operations that should be executed before the fold loop\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def run(self, train_idxs: np.ndarray, val_idxs: np.ndarray) -> Dict[str, Dict[str, np.ndarray]]:\n",
    "        \"\"\"This should return a dict of correlations.\n",
    "        dict format: {\"layer\": {\"lh\": np.ndarray, \"lh\": np.ndarray}}\"\"\"\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def return_idxs(self):\n",
    "        \"\"\"Returns idxs to create folds in the KFold class.\"\"\"\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def return_roi_names(self) -> List[str]:\n",
    "        \"\"\"Required for the plot function in the KFold class.\"\"\"\n",
    "        return self.roi_names    \n",
    "    \n",
    "class KFold:\n",
    "    \"\"\"Run a k-fold cross validation with a given procedure.\"\"\"\n",
    "    def __init__(self, folds: int = 8, seed: int = 5, procedure: KFoldProcedure = None) -> None:\n",
    "        assert folds > 1, \"folds must be greater than 1\"\n",
    "        assert seed > 0, \"seed must be greater than 0\"\n",
    "        assert isinstance(folds, int), \"folds must be an integer\"\n",
    "        assert isinstance(seed, int), \"seed must be an integer\"\n",
    "        #assert isinstance(procedure, KFoldProcedure), \"procedure must be an instance of KFoldProcedure\"\n",
    "        self.folds = folds\n",
    "        self.seed = seed\n",
    "        self.procedure = procedure\n",
    "        self.fold_correlations = {}\n",
    "        self.mean_correlations = None\n",
    "\n",
    "    def run(self) -> None:\n",
    "        \"\"\"Runs the procedure on each fold and accesses the correlations.\"\"\"\n",
    "        self.procedure.prepare()\n",
    "        # Create k folds   \n",
    "        fold_idxs = self.procedure.return_idxs()\n",
    "        np.random.seed(self.seed)\n",
    "        np.random.shuffle(fold_idxs)\n",
    "        self.fold_idxs = np.array_split(fold_idxs, self.folds)\n",
    "\n",
    "        for fold in range(self.folds):\n",
    "            # Select validation and train set\n",
    "            val_idxs = self.fold_idxs[fold]\n",
    "            train_idxs = np.concatenate([self.fold_idxs[j] for j in range(self.folds) if j != fold])\n",
    "            \n",
    "            # Info for current fold\n",
    "            print(f\"#############################################\")\n",
    "            print(f\"# Fold: {fold+1}/ {self.folds}\")         \n",
    "            print(f\"# Train size: {len(train_idxs)}\")\n",
    "            print(f\"# Validation size: {len(val_idxs)}\")\n",
    "            print(f\"#############################################\")\n",
    "\n",
    "            # Run procedure\n",
    "            self.fold_correlations[fold] = self.procedure.run(train_idxs, val_idxs)\n",
    "        # Get ROI names\n",
    "        self.roi_names = self.procedure.return_roi_names()\n",
    "    \n",
    "    def calculate_mean_accross_folds(self):\n",
    "        \"\"\"Calculates the mean across folds for each layer\"\"\"\n",
    "        self.mean_correlations = {}\n",
    "        for layer in self.fold_correlations[0].keys():\n",
    "            self.mean_correlations[layer] = {}\n",
    "            for hemi in self.fold_correlations[0][layer].keys():\n",
    "                self.mean_correlations[layer][hemi] = np.nanmean([self.fold_correlations[fold][layer][hemi] for fold in range(self.folds)], axis=0)\n",
    "    \n",
    "    def plot_results(self):\n",
    "        \"\"\"Creates two side by side bar plots for the two hemispheres showing the mean correlations of each layer\"\"\"\n",
    "        if self.mean_correlations is None:\n",
    "            self.calculate_mean_accross_folds()\n",
    "        width = 0.5\n",
    "        fig, ax = plt.subplots(1, 2, figsize=(20, 10))\n",
    "        for i, layer in enumerate(self.mean_correlations):\n",
    "            ax[0].bar(np.arange(len(self.mean_correlations[layer][\"lh\"])) - width*i, self.mean_correlations[layer][\"lh\"], width, label=f\"{layer} lh\")\n",
    "            ax[1].bar(np.arange(len(self.mean_correlations[layer][\"rh\"])) - width*i, self.mean_correlations[layer][\"rh\"], width, label=f\"{layer} rh\")\n",
    "        ax[0].set_xticks(range(len(self.roi_names)))\n",
    "        ax[0].set_xticklabels(self.roi_names, rotation=90)\n",
    "        ax[0].set_ylabel(\"Correlation\")\n",
    "        ax[0].set_xlabel(\"ROI\")\n",
    "        ax[0].legend()\n",
    "        ax[0].set_title(\"Mean correlation with ROIs accross folds (left hemisphere))\")\n",
    "        ax[1].set_xticks(range(len(self.roi_names)))\n",
    "        ax[1].set_xticklabels(self.roi_names, rotation=90)\n",
    "        ax[1].set_ylabel(\"Correlation\")\n",
    "        ax[1].set_xlabel(\"ROI\")\n",
    "        ax[1].legend()\n",
    "        ax[1].set_title(\"Mean correlation with ROIs accross folds (right hemisphere)\")\n",
    "        plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the procedures we used to select our models for submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KFoldSingleCLIPSingleSubject(KFoldProcedure):\n",
    "    \"\"\"A procedure that runs k-fold on all layers of a single CLIP model on a single subject.\"\"\"\n",
    "    def __init__(self, \n",
    "                 feature_extractor: CLIPFeatureExtractor,\n",
    "                 subject: Subject, \n",
    "                 pca: PCA) -> None:\n",
    "        assert isinstance(feature_extractor, CLIPFeatureExtractor), \"feature_extractor must be an instance of CLIPFeatureExtractor\"\n",
    "        assert isinstance(subject, Subject), \"subject must be an instance of Subject\"\n",
    "        self.feature_extractor = feature_extractor\n",
    "        self.subject = subject\n",
    "        self.pca = pca\n",
    "        self.correlations = {}\n",
    "\n",
    "    def prepare(self):\n",
    "        # Extract raw features\n",
    "        self.feature_extractor.extract_raw_features_from_model()\n",
    "        self.raw_features = self.feature_extractor.feature_dict\n",
    "        self.feature_extractor = None # free memory\n",
    "\n",
    "        # Load challenge rois\n",
    "        self.subject.load_challenge_rois()\n",
    "        self.lh_challenge_rois = self.subject.lh_challenge_rois\n",
    "        self.rh_challenge_rois = self.subject.rh_challenge_rois\n",
    "        self.roi_name_maps = self.subject.roi_name_maps\n",
    "\n",
    "        # Load neural data\n",
    "        self.subject.load_neural_data()\n",
    "        self.lh_fmri = self.subject.lh_fmri\n",
    "        self.rh_fmri = self.subject.rh_fmri\n",
    "        self.subject = None # free memory\n",
    "\n",
    "        # Prepare correlation dict\n",
    "        self.fold_correlations = {}\n",
    "\n",
    "    def run(self, train_idxs: np.ndarray, val_idxs: np.ndarray) -> Dict[str, Dict[str, np.ndarray]]:\n",
    "        # Loop over all layers          \n",
    "        correlations = {}\n",
    "        for layer in self.raw_features.keys():\n",
    "            print(f\"> {layer}\")\n",
    "            # Assign train and val features\n",
    "            train_features = self.raw_features[layer][train_idxs]\n",
    "            val_features = self.raw_features[layer][val_idxs]\n",
    "\n",
    "            # Assign train and val fmri\n",
    "            train_lh_fmri = self.lh_fmri[train_idxs]\n",
    "            train_rh_fmri = self.rh_fmri[train_idxs]\n",
    "            val_lh_fmri = self.lh_fmri[val_idxs]\n",
    "            val_rh_fmri = self.rh_fmri[val_idxs]\n",
    "\n",
    "            # Fit PCA models\n",
    "            print(f\"Fitting PCA model for {layer}...\")\n",
    "            train_pca_features = self.pca.fit_transform(torch.tensor(train_features).flatten(1).numpy())\n",
    "            del train_features # free memory\n",
    "\n",
    "            # Fit linear regression\n",
    "            print(f\"Fitting linear regression models for {layer}...\")\n",
    "            lh_lin_reg = LinearRegression().fit(train_pca_features, train_lh_fmri)\n",
    "            rh_lin_reg = LinearRegression().fit(train_pca_features, train_rh_fmri)\n",
    "            del train_pca_features, train_lh_fmri, train_rh_fmri # free memory\n",
    "\n",
    "            # Transform validation features\n",
    "            print(f\"Transforming validation features for {layer}...\")\n",
    "            val_txt_pca_features = self.pca.transform(torch.tensor(val_features).flatten(1).numpy())\n",
    "            del val_features # free memory\n",
    "\n",
    "            # Predict validation set\n",
    "            print(f\"Predicting validation set for {layer}...\")\n",
    "            lh_val_pred = lh_lin_reg.predict(val_txt_pca_features)\n",
    "            rh_val_pred = rh_lin_reg.predict(val_txt_pca_features)\n",
    "            del val_txt_pca_features, lh_lin_reg, rh_lin_reg # free memory\n",
    "            \n",
    "            # Calculate correlations\n",
    "            print(f\"Calculating correlations for {layer}...\\n\")\n",
    "            # Left hemisphere\n",
    "            lh_correlation = np.zeros(lh_val_pred.shape[1])\n",
    "            for v in tqdm(range(lh_val_pred.shape[1])):\n",
    "                lh_correlation[v] = corr(lh_val_pred[:,v], val_lh_fmri[:,v])[0]\n",
    "            # Right hemisphere\n",
    "            rh_correlation = np.zeros(rh_val_pred.shape[1])\n",
    "            for v in tqdm(range(rh_val_pred.shape[1])):\n",
    "                rh_correlation[v] = corr(rh_val_pred[:,v], val_rh_fmri[:,v])[0]\n",
    "\n",
    "            # Get median correlations with ROI\n",
    "            print(f\"Calculating median correlation with ROIs for {layer}...\")\n",
    "            # Select the correlation results vertices of each ROI\n",
    "            lh_challange_rois = self.lh_challenge_rois\n",
    "            rh_challange_rois = self.rh_challenge_rois\n",
    "            self.roi_names = []\n",
    "            lh_roi_correlation = []\n",
    "            rh_roi_correlation = []\n",
    "            for r1 in range(len(lh_challange_rois)):\n",
    "                for r2 in self.roi_name_maps[r1].items():\n",
    "                    if r2[0] != 0: # zeros indicate to vertices falling outside the ROI of interest\n",
    "                        self.roi_names.append(r2[1])\n",
    "                        lh_roi_idx = np.where(lh_challange_rois[r1] == r2[0])[0]\n",
    "                        rh_roi_idx = np.where(rh_challange_rois[r1] == r2[0])[0]\n",
    "                        lh_roi_correlation.append(lh_correlation[lh_roi_idx])\n",
    "                        rh_roi_correlation.append(rh_correlation[rh_roi_idx])\n",
    "            self.roi_names.append('All vertices')\n",
    "            lh_roi_correlation.append(lh_correlation)\n",
    "            rh_roi_correlation.append(rh_correlation)\n",
    "            lh_median_roi_correlation = [np.median(lh_roi_correlation[r])\n",
    "                for r in range(len(lh_roi_correlation))]\n",
    "            rh_median_roi_correlation = [np.median(rh_roi_correlation[r])\n",
    "                for r in range(len(rh_roi_correlation))]\n",
    "            \n",
    "            # Store correlations\n",
    "            correlations[layer] = {\"lh\": lh_median_roi_correlation, \"rh\": rh_median_roi_correlation} \n",
    "        return correlations\n",
    "\n",
    "    def return_idxs(self) -> np.ndarray:\n",
    "        return np.arange(len(self.raw_features[list(self.raw_features.keys())[0]])) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SubmissionProcedure & CreateSubmission Classes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SubmissionProcedure class is used to define a procedure which fits a model to predict the test fmri activity. \n",
    "It can be supplied to a CreateSubmission class which executes its run() function on all subjects to generate a submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubmissionProcedure:\n",
    "    \"\"\"Used to create a submission procedure that is executed for each subject in the CreateSubmission class.\"\"\"\n",
    "\n",
    "    def run(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "class CreateSubmission:\n",
    "    \"\"\"Create a new challenge submission.\"\"\"\n",
    "    def __init__(self, \n",
    "                 subjects : List[Subject],\n",
    "                 procedure: SubmissionProcedure):\n",
    "        self.subjects = subjects\n",
    "        self.procedure = procedure\n",
    "\n",
    "    def create_submission_folder(self) -> None:\n",
    "        # create new submission folder with newest name\n",
    "        submissions = glob.glob(f\"submissions/submission*\")\n",
    "        if len(submissions) == 0:\n",
    "            # create first submission folder\n",
    "            self.folder_name = \"submission001\"\n",
    "            os.mkdir(f\"submissions/{self.folder_name}\")\n",
    "        else:\n",
    "            # create next submission folder\n",
    "            last_submission = sorted(submissions)[-1]\n",
    "            last_submission_number = int(last_submission.split(\"/\")[-1].split(\"submission\")[-1])\n",
    "            next_submission_number = last_submission_number + 1\n",
    "            self.folder_name = f\"submission{str(next_submission_number).zfill(3)}\"\n",
    "            os.mkdir(f\"submissions/{self.folder_name}\")\n",
    "        # Write text file with model description\n",
    "        with open(f\"submissions/{self.folder_name}/info.txt\", \"w\") as f:\n",
    "            f.write(self.procedure.description)\n",
    "        # create a folder for each subject\n",
    "        for subject in self.subjects:\n",
    "            os.mkdir(f\"submissions/{self.folder_name}/{subject.subject}\")\n",
    "\n",
    "    def save_predictions(self, subject: Subject, lh_predictions: np.ndarray, rh_predictions: np.ndarray) -> None:\n",
    "        \"\"\"Save predictions for a subject.\"\"\"\n",
    "        lh_predictions = lh_predictions.astype(np.float32)\n",
    "        rh_predictions = rh_predictions.astype(np.float32)\n",
    "        save_path = f\"submissions/{self.folder_name}/{subject.subject}\"\n",
    "        # Save predictions\n",
    "        np.save(f\"{save_path}/lh_pred_test.npy\", lh_predictions)\n",
    "        np.save(f\"{save_path}/rh_pred_test.npy\", rh_predictions)\n",
    "\n",
    "    def run(self):\n",
    "        self.create_submission_folder()\n",
    "        for subject in self.subjects:\n",
    "            lh_predictions, rh_predictions = self.procedure.run(subject)\n",
    "            self.save_predictions(subject, lh_predictions, rh_predictions)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the models we submitted to the algonauts 2023 competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CLIPVisionLayer12PCA100LinearRegression(SubmissionProcedure):\n",
    "    def __init__(self, description: str):\n",
    "        self.description = description\n",
    "\n",
    "    def run(self, subject: Subject) -> np.ndarray:\n",
    "        \"\"\"Run the model on a subject.\"\"\"\n",
    "        # Prepare data\n",
    "        subject.create_dataloaders(processor=processor, batch_size=300)\n",
    "        subject.load_neural_data()\n",
    "        train_img_dataloader = subject.train_img_dataloader\n",
    "        test_img_dataloader = subject.test_img_dataloader\n",
    "        lh_fmri = subject.lh_fmri\n",
    "        rh_fmri = subject.rh_fmri\n",
    "        del subject # free up memory\n",
    "\n",
    "        # Prepare feature extractor\n",
    "        train_feature_extractor = CLIPFeatureExtractor(idxs=[12], last_hidden_layer=False, model=vis_model, dataloader=train_img_dataloader)\n",
    "        test_feature_extractor = CLIPFeatureExtractor(idxs=[12], last_hidden_layer=False, model=vis_model, dataloader=test_img_dataloader)\n",
    "\n",
    "        # Extract features\n",
    "        train_feature_extractor.extract_raw_features_from_model()\n",
    "        raw_train_features = train_feature_extractor.feature_dict[\"Transformer Layer 12\"]\n",
    "        del train_feature_extractor\n",
    "\n",
    "        # Fit PCA\n",
    "        pca = PCA(n_components=100)\n",
    "        pca_transformed_train_features = pca.fit_transform(torch.tensor(raw_train_features).flatten(1).numpy())\n",
    "        del raw_train_features\n",
    "\n",
    "        # Fit linear regression\n",
    "        lh_lin_reg = LinearRegression().fit(pca_transformed_train_features, lh_fmri)\n",
    "        rh_lin_reg = LinearRegression().fit(pca_transformed_train_features, rh_fmri)\n",
    "        del pca_transformed_train_features\n",
    "\n",
    "        # Extract test features\n",
    "        test_feature_extractor.extract_raw_features_from_model()\n",
    "        raw_test_features = test_feature_extractor.feature_dict[\"Transformer Layer 12\"]\n",
    "        del test_feature_extractor\n",
    "\n",
    "        # Transform test features\n",
    "        pca_transformed_test_features = pca.transform(torch.tensor(raw_test_features).flatten(1).numpy())\n",
    "        del raw_test_features\n",
    "        \n",
    "        # Predict\n",
    "        lh_predictions = lh_lin_reg.predict(pca_transformed_test_features)\n",
    "        rh_predictions = rh_lin_reg.predict(pca_transformed_test_features)\n",
    "        return lh_predictions, rh_predictions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Cross Validation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on the selected kfold procedure, different requirements like creating a subject or feature extractor are needed.\n",
    "\n",
    "In this example we use the KFoldSingleCLIPSingleSubject procedure which requires a subject, feature extractor and pca."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training images: 9841\n",
      "Test images: 159\n",
      "Training captions: 9841\n",
      "Test captions: 159\n",
      "Train image dataloader: 33 batches\n",
      "Test image dataloader: 1 batches\n",
      "Train caption dataloader: 33 batches\n",
      "Test caption dataloader: 1 batches\n"
     ]
    }
   ],
   "source": [
    "subject = Subject(\"subj01\")\n",
    "subject.create_dataloaders(processor=processor, batch_size=300)\n",
    "feature_extractor = CLIPFeatureExtractor(idxs=[0,1,2,3,4,5,6,7,8,9,10,11,12], last_hidden_layer=True, model=vis_model, dataloader=subject.train_img_dataloader)\n",
    "pca = PCA(n_components=200)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After defining all required objects, we can create a the KFoldProcedure and KFold objects and run the cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold_procedure = KFoldSingleCLIPSingleSubject(feature_extractor=feature_extractor,  subject=subject, pca=pca)\n",
    "kfold = KFold(folds=8, procedure=kfold_procedure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 33/33 [03:21<00:00,  6.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left hemisphere neural data loaded. Shape: (9841, 19004)\n",
      "Right hemisphere neural data loaded. Shape: (9841, 20544)\n",
      "#############################################\n",
      "# Fold: 1/ 8\n",
      "# Train size: 8610\n",
      "# Validation size: 1231\n",
      "#############################################\n",
      "> Embedding Layer\n",
      "Fitting PCA model for Embedding Layer...\n",
      "Fitting linear regression models for Embedding Layer...\n",
      "Transforming validation features for Embedding Layer...\n",
      "Predicting validation set for Embedding Layer...\n",
      "Calculating correlations for Embedding Layer...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 19004/19004 [00:17<00:00, 1071.38it/s]\n",
      "100%|| 20544/20544 [00:18<00:00, 1129.12it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating median correlation with ROIs for Embedding Layer...\n",
      "> Transformer Layer 1\n",
      "Fitting PCA model for Transformer Layer 1...\n",
      "Fitting linear regression models for Transformer Layer 1...\n",
      "Transforming validation features for Transformer Layer 1...\n",
      "Predicting validation set for Transformer Layer 1...\n",
      "Calculating correlations for Transformer Layer 1...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 19004/19004 [00:16<00:00, 1128.40it/s]\n",
      "100%|| 20544/20544 [00:18<00:00, 1125.83it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating median correlation with ROIs for Transformer Layer 1...\n",
      "> Transformer Layer 2\n",
      "Fitting PCA model for Transformer Layer 2...\n",
      "Fitting linear regression models for Transformer Layer 2...\n",
      "Transforming validation features for Transformer Layer 2...\n",
      "Predicting validation set for Transformer Layer 2...\n",
      "Calculating correlations for Transformer Layer 2...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 19004/19004 [00:16<00:00, 1155.03it/s]\n",
      "100%|| 20544/20544 [00:18<00:00, 1120.10it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating median correlation with ROIs for Transformer Layer 2...\n",
      "> Transformer Layer 3\n",
      "Fitting PCA model for Transformer Layer 3...\n",
      "Fitting linear regression models for Transformer Layer 3...\n",
      "Transforming validation features for Transformer Layer 3...\n",
      "Predicting validation set for Transformer Layer 3...\n",
      "Calculating correlations for Transformer Layer 3...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 19004/19004 [00:16<00:00, 1127.58it/s]\n",
      "100%|| 20544/20544 [00:18<00:00, 1099.19it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating median correlation with ROIs for Transformer Layer 3...\n",
      "> Transformer Layer 4\n",
      "Fitting PCA model for Transformer Layer 4...\n",
      "Fitting linear regression models for Transformer Layer 4...\n",
      "Transforming validation features for Transformer Layer 4...\n",
      "Predicting validation set for Transformer Layer 4...\n",
      "Calculating correlations for Transformer Layer 4...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 19004/19004 [00:16<00:00, 1133.17it/s]\n",
      "100%|| 20544/20544 [00:18<00:00, 1120.30it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating median correlation with ROIs for Transformer Layer 4...\n",
      "> Transformer Layer 5\n",
      "Fitting PCA model for Transformer Layer 5...\n",
      "Fitting linear regression models for Transformer Layer 5...\n",
      "Transforming validation features for Transformer Layer 5...\n",
      "Predicting validation set for Transformer Layer 5...\n",
      "Calculating correlations for Transformer Layer 5...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 19004/19004 [00:16<00:00, 1137.16it/s]\n",
      "100%|| 20544/20544 [00:18<00:00, 1124.88it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating median correlation with ROIs for Transformer Layer 5...\n",
      "> Transformer Layer 6\n",
      "Fitting PCA model for Transformer Layer 6...\n",
      "Fitting linear regression models for Transformer Layer 6...\n",
      "Transforming validation features for Transformer Layer 6...\n",
      "Predicting validation set for Transformer Layer 6...\n",
      "Calculating correlations for Transformer Layer 6...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 19004/19004 [00:16<00:00, 1143.63it/s]\n",
      "100%|| 20544/20544 [00:18<00:00, 1131.37it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating median correlation with ROIs for Transformer Layer 6...\n",
      "> Transformer Layer 7\n",
      "Fitting PCA model for Transformer Layer 7...\n",
      "Fitting linear regression models for Transformer Layer 7...\n",
      "Transforming validation features for Transformer Layer 7...\n",
      "Predicting validation set for Transformer Layer 7...\n",
      "Calculating correlations for Transformer Layer 7...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 19004/19004 [00:16<00:00, 1140.44it/s]\n",
      "100%|| 20544/20544 [00:18<00:00, 1111.17it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating median correlation with ROIs for Transformer Layer 7...\n",
      "> Transformer Layer 8\n",
      "Fitting PCA model for Transformer Layer 8...\n",
      "Fitting linear regression models for Transformer Layer 8...\n",
      "Transforming validation features for Transformer Layer 8...\n",
      "Predicting validation set for Transformer Layer 8...\n",
      "Calculating correlations for Transformer Layer 8...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 19004/19004 [00:16<00:00, 1129.55it/s]\n",
      "100%|| 20544/20544 [00:18<00:00, 1108.20it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating median correlation with ROIs for Transformer Layer 8...\n",
      "> Transformer Layer 9\n",
      "Fitting PCA model for Transformer Layer 9...\n",
      "Fitting linear regression models for Transformer Layer 9...\n",
      "Transforming validation features for Transformer Layer 9...\n",
      "Predicting validation set for Transformer Layer 9...\n",
      "Calculating correlations for Transformer Layer 9...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 19004/19004 [00:16<00:00, 1138.92it/s]\n",
      "100%|| 20544/20544 [00:17<00:00, 1162.53it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating median correlation with ROIs for Transformer Layer 9...\n",
      "> Transformer Layer 10\n",
      "Fitting PCA model for Transformer Layer 10...\n",
      "Fitting linear regression models for Transformer Layer 10...\n",
      "Transforming validation features for Transformer Layer 10...\n",
      "Predicting validation set for Transformer Layer 10...\n",
      "Calculating correlations for Transformer Layer 10...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 19004/19004 [00:16<00:00, 1132.31it/s]\n",
      "100%|| 20544/20544 [00:18<00:00, 1137.40it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating median correlation with ROIs for Transformer Layer 10...\n",
      "> Transformer Layer 11\n",
      "Fitting PCA model for Transformer Layer 11...\n",
      "Fitting linear regression models for Transformer Layer 11...\n",
      "Transforming validation features for Transformer Layer 11...\n",
      "Predicting validation set for Transformer Layer 11...\n",
      "Calculating correlations for Transformer Layer 11...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 19004/19004 [00:17<00:00, 1109.09it/s]\n",
      "100%|| 20544/20544 [00:18<00:00, 1104.71it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating median correlation with ROIs for Transformer Layer 11...\n",
      "> Transformer Layer 12\n",
      "Fitting PCA model for Transformer Layer 12...\n",
      "Fitting linear regression models for Transformer Layer 12...\n",
      "Transforming validation features for Transformer Layer 12...\n",
      "Predicting validation set for Transformer Layer 12...\n",
      "Calculating correlations for Transformer Layer 12...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 19004/19004 [00:16<00:00, 1127.63it/s]\n",
      "100%|| 20544/20544 [00:17<00:00, 1155.59it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating median correlation with ROIs for Transformer Layer 12...\n",
      "> Final Layer\n",
      "Fitting PCA model for Final Layer...\n",
      "Fitting linear regression models for Final Layer...\n",
      "Transforming validation features for Final Layer...\n",
      "Predicting validation set for Final Layer...\n",
      "Calculating correlations for Final Layer...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 19004/19004 [00:17<00:00, 1072.44it/s]\n",
      "100%|| 20544/20544 [00:18<00:00, 1095.44it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating median correlation with ROIs for Final Layer...\n",
      "#############################################\n",
      "# Fold: 2/ 8\n",
      "# Train size: 8611\n",
      "# Validation size: 1230\n",
      "#############################################\n",
      "> Embedding Layer\n",
      "Fitting PCA model for Embedding Layer...\n",
      "Fitting linear regression models for Embedding Layer...\n",
      "Transforming validation features for Embedding Layer...\n",
      "Predicting validation set for Embedding Layer...\n",
      "Calculating correlations for Embedding Layer...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 19004/19004 [00:17<00:00, 1110.19it/s]\n",
      "100%|| 20544/20544 [00:18<00:00, 1123.00it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating median correlation with ROIs for Embedding Layer...\n",
      "> Transformer Layer 1\n",
      "Fitting PCA model for Transformer Layer 1...\n",
      "Fitting linear regression models for Transformer Layer 1...\n",
      "Transforming validation features for Transformer Layer 1...\n",
      "Predicting validation set for Transformer Layer 1...\n",
      "Calculating correlations for Transformer Layer 1...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 19004/19004 [00:16<00:00, 1125.17it/s]\n",
      "100%|| 20544/20544 [00:18<00:00, 1117.70it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating median correlation with ROIs for Transformer Layer 1...\n",
      "> Transformer Layer 2\n",
      "Fitting PCA model for Transformer Layer 2...\n",
      "Fitting linear regression models for Transformer Layer 2...\n",
      "Transforming validation features for Transformer Layer 2...\n",
      "Predicting validation set for Transformer Layer 2...\n",
      "Calculating correlations for Transformer Layer 2...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 19004/19004 [00:17<00:00, 1112.26it/s]\n",
      "100%|| 20544/20544 [00:18<00:00, 1138.44it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating median correlation with ROIs for Transformer Layer 2...\n",
      "> Transformer Layer 3\n",
      "Fitting PCA model for Transformer Layer 3...\n",
      "Fitting linear regression models for Transformer Layer 3...\n",
      "Transforming validation features for Transformer Layer 3...\n",
      "Predicting validation set for Transformer Layer 3...\n",
      "Calculating correlations for Transformer Layer 3...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 19004/19004 [00:16<00:00, 1123.89it/s]\n",
      "100%|| 20544/20544 [00:18<00:00, 1133.10it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating median correlation with ROIs for Transformer Layer 3...\n",
      "> Transformer Layer 4\n",
      "Fitting PCA model for Transformer Layer 4...\n",
      "Fitting linear regression models for Transformer Layer 4...\n",
      "Transforming validation features for Transformer Layer 4...\n",
      "Predicting validation set for Transformer Layer 4...\n",
      "Calculating correlations for Transformer Layer 4...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 19004/19004 [00:16<00:00, 1119.06it/s]\n",
      "100%|| 20544/20544 [00:18<00:00, 1139.03it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating median correlation with ROIs for Transformer Layer 4...\n",
      "> Transformer Layer 5\n",
      "Fitting PCA model for Transformer Layer 5...\n",
      "Fitting linear regression models for Transformer Layer 5...\n",
      "Transforming validation features for Transformer Layer 5...\n",
      "Predicting validation set for Transformer Layer 5...\n",
      "Calculating correlations for Transformer Layer 5...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 19004/19004 [00:16<00:00, 1158.50it/s]\n",
      "100%|| 20544/20544 [00:18<00:00, 1133.02it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating median correlation with ROIs for Transformer Layer 5...\n",
      "> Transformer Layer 6\n",
      "Fitting PCA model for Transformer Layer 6...\n",
      "Fitting linear regression models for Transformer Layer 6...\n",
      "Transforming validation features for Transformer Layer 6...\n",
      "Predicting validation set for Transformer Layer 6...\n",
      "Calculating correlations for Transformer Layer 6...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 19004/19004 [00:16<00:00, 1168.53it/s]\n",
      "100%|| 20544/20544 [00:17<00:00, 1176.88it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating median correlation with ROIs for Transformer Layer 6...\n",
      "> Transformer Layer 7\n",
      "Fitting PCA model for Transformer Layer 7...\n",
      "Fitting linear regression models for Transformer Layer 7...\n",
      "Transforming validation features for Transformer Layer 7...\n",
      "Predicting validation set for Transformer Layer 7...\n",
      "Calculating correlations for Transformer Layer 7...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 19004/19004 [00:16<00:00, 1164.51it/s]\n",
      "100%|| 20544/20544 [00:18<00:00, 1140.61it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating median correlation with ROIs for Transformer Layer 7...\n",
      "> Transformer Layer 8\n",
      "Fitting PCA model for Transformer Layer 8...\n",
      "Fitting linear regression models for Transformer Layer 8...\n",
      "Transforming validation features for Transformer Layer 8...\n",
      "Predicting validation set for Transformer Layer 8...\n",
      "Calculating correlations for Transformer Layer 8...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 19004/19004 [00:16<00:00, 1154.53it/s]\n",
      "100%|| 20544/20544 [00:17<00:00, 1144.81it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating median correlation with ROIs for Transformer Layer 8...\n",
      "> Transformer Layer 9\n",
      "Fitting PCA model for Transformer Layer 9...\n",
      "Fitting linear regression models for Transformer Layer 9...\n",
      "Transforming validation features for Transformer Layer 9...\n",
      "Predicting validation set for Transformer Layer 9...\n",
      "Calculating correlations for Transformer Layer 9...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 19004/19004 [00:16<00:00, 1163.46it/s]\n",
      "100%|| 20544/20544 [00:18<00:00, 1130.44it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating median correlation with ROIs for Transformer Layer 9...\n",
      "> Transformer Layer 10\n",
      "Fitting PCA model for Transformer Layer 10...\n",
      "Fitting linear regression models for Transformer Layer 10...\n",
      "Transforming validation features for Transformer Layer 10...\n",
      "Predicting validation set for Transformer Layer 10...\n",
      "Calculating correlations for Transformer Layer 10...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 19004/19004 [00:16<00:00, 1139.26it/s]\n",
      "100%|| 20544/20544 [00:17<00:00, 1143.26it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating median correlation with ROIs for Transformer Layer 10...\n",
      "> Transformer Layer 11\n",
      "Fitting PCA model for Transformer Layer 11...\n",
      "Fitting linear regression models for Transformer Layer 11...\n",
      "Transforming validation features for Transformer Layer 11...\n",
      "Predicting validation set for Transformer Layer 11...\n",
      "Calculating correlations for Transformer Layer 11...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 19004/19004 [00:16<00:00, 1149.76it/s]\n",
      "100%|| 20544/20544 [00:17<00:00, 1161.18it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating median correlation with ROIs for Transformer Layer 11...\n",
      "> Transformer Layer 12\n",
      "Fitting PCA model for Transformer Layer 12...\n",
      "Fitting linear regression models for Transformer Layer 12...\n",
      "Transforming validation features for Transformer Layer 12...\n",
      "Predicting validation set for Transformer Layer 12...\n",
      "Calculating correlations for Transformer Layer 12...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 19004/19004 [00:15<00:00, 1200.20it/s]\n",
      "100%|| 20544/20544 [00:18<00:00, 1138.19it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating median correlation with ROIs for Transformer Layer 12...\n",
      "> Final Layer\n",
      "Fitting PCA model for Final Layer...\n",
      "Fitting linear regression models for Final Layer...\n",
      "Transforming validation features for Final Layer...\n",
      "Predicting validation set for Final Layer...\n",
      "Calculating correlations for Final Layer...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 19004/19004 [00:16<00:00, 1134.13it/s]\n",
      "100%|| 20544/20544 [00:18<00:00, 1130.89it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating median correlation with ROIs for Final Layer...\n",
      "#############################################\n",
      "# Fold: 3/ 8\n",
      "# Train size: 8611\n",
      "# Validation size: 1230\n",
      "#############################################\n",
      "> Embedding Layer\n",
      "Fitting PCA model for Embedding Layer...\n",
      "Fitting linear regression models for Embedding Layer...\n",
      "Transforming validation features for Embedding Layer...\n",
      "Predicting validation set for Embedding Layer...\n",
      "Calculating correlations for Embedding Layer...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 19004/19004 [00:16<00:00, 1140.74it/s]\n",
      "100%|| 20544/20544 [00:18<00:00, 1117.04it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating median correlation with ROIs for Embedding Layer...\n",
      "> Transformer Layer 1\n",
      "Fitting PCA model for Transformer Layer 1...\n",
      "Fitting linear regression models for Transformer Layer 1...\n",
      "Transforming validation features for Transformer Layer 1...\n",
      "Predicting validation set for Transformer Layer 1...\n",
      "Calculating correlations for Transformer Layer 1...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 19004/19004 [00:16<00:00, 1130.73it/s]\n",
      "100%|| 20544/20544 [00:18<00:00, 1110.53it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating median correlation with ROIs for Transformer Layer 1...\n",
      "> Transformer Layer 2\n",
      "Fitting PCA model for Transformer Layer 2...\n",
      "Fitting linear regression models for Transformer Layer 2...\n",
      "Transforming validation features for Transformer Layer 2...\n",
      "Predicting validation set for Transformer Layer 2...\n",
      "Calculating correlations for Transformer Layer 2...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 19004/19004 [00:16<00:00, 1127.21it/s]\n",
      "100%|| 20544/20544 [00:18<00:00, 1122.02it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating median correlation with ROIs for Transformer Layer 2...\n",
      "> Transformer Layer 3\n",
      "Fitting PCA model for Transformer Layer 3...\n",
      "Fitting linear regression models for Transformer Layer 3...\n",
      "Transforming validation features for Transformer Layer 3...\n",
      "Predicting validation set for Transformer Layer 3...\n",
      "Calculating correlations for Transformer Layer 3...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 19004/19004 [00:16<00:00, 1135.93it/s]\n",
      "100%|| 20544/20544 [00:17<00:00, 1155.93it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating median correlation with ROIs for Transformer Layer 3...\n",
      "> Transformer Layer 4\n",
      "Fitting PCA model for Transformer Layer 4...\n",
      "Fitting linear regression models for Transformer Layer 4...\n",
      "Transforming validation features for Transformer Layer 4...\n",
      "Predicting validation set for Transformer Layer 4...\n",
      "Calculating correlations for Transformer Layer 4...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 19004/19004 [00:16<00:00, 1141.03it/s]\n",
      "100%|| 20544/20544 [00:18<00:00, 1137.36it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating median correlation with ROIs for Transformer Layer 4...\n",
      "> Transformer Layer 5\n",
      "Fitting PCA model for Transformer Layer 5...\n",
      "Fitting linear regression models for Transformer Layer 5...\n",
      "Transforming validation features for Transformer Layer 5...\n",
      "Predicting validation set for Transformer Layer 5...\n",
      "Calculating correlations for Transformer Layer 5...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 19004/19004 [00:16<00:00, 1154.71it/s]\n",
      "100%|| 20544/20544 [00:18<00:00, 1140.92it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating median correlation with ROIs for Transformer Layer 5...\n",
      "> Transformer Layer 6\n",
      "Fitting PCA model for Transformer Layer 6...\n",
      "Fitting linear regression models for Transformer Layer 6...\n",
      "Transforming validation features for Transformer Layer 6...\n",
      "Predicting validation set for Transformer Layer 6...\n",
      "Calculating correlations for Transformer Layer 6...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 19004/19004 [00:16<00:00, 1162.14it/s]\n",
      "100%|| 20544/20544 [00:18<00:00, 1124.04it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating median correlation with ROIs for Transformer Layer 6...\n",
      "> Transformer Layer 7\n",
      "Fitting PCA model for Transformer Layer 7...\n",
      "Fitting linear regression models for Transformer Layer 7...\n",
      "Transforming validation features for Transformer Layer 7...\n",
      "Predicting validation set for Transformer Layer 7...\n",
      "Calculating correlations for Transformer Layer 7...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 19004/19004 [00:16<00:00, 1141.04it/s]\n",
      "100%|| 20544/20544 [00:17<00:00, 1165.79it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating median correlation with ROIs for Transformer Layer 7...\n",
      "> Transformer Layer 8\n",
      "Fitting PCA model for Transformer Layer 8...\n",
      "Fitting linear regression models for Transformer Layer 8...\n",
      "Transforming validation features for Transformer Layer 8...\n",
      "Predicting validation set for Transformer Layer 8...\n",
      "Calculating correlations for Transformer Layer 8...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 19004/19004 [00:16<00:00, 1136.40it/s]\n",
      "100%|| 20544/20544 [00:18<00:00, 1138.56it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating median correlation with ROIs for Transformer Layer 8...\n",
      "> Transformer Layer 9\n",
      "Fitting PCA model for Transformer Layer 9...\n",
      "Fitting linear regression models for Transformer Layer 9...\n",
      "Transforming validation features for Transformer Layer 9...\n",
      "Predicting validation set for Transformer Layer 9...\n",
      "Calculating correlations for Transformer Layer 9...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 19004/19004 [00:16<00:00, 1140.57it/s]\n",
      "100%|| 20544/20544 [00:18<00:00, 1140.14it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating median correlation with ROIs for Transformer Layer 9...\n",
      "> Transformer Layer 10\n",
      "Fitting PCA model for Transformer Layer 10...\n",
      "Fitting linear regression models for Transformer Layer 10...\n",
      "Transforming validation features for Transformer Layer 10...\n",
      "Predicting validation set for Transformer Layer 10...\n",
      "Calculating correlations for Transformer Layer 10...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 19004/19004 [00:16<00:00, 1132.38it/s]\n",
      "100%|| 20544/20544 [00:18<00:00, 1129.66it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating median correlation with ROIs for Transformer Layer 10...\n",
      "> Transformer Layer 11\n",
      "Fitting PCA model for Transformer Layer 11...\n",
      "Fitting linear regression models for Transformer Layer 11...\n",
      "Transforming validation features for Transformer Layer 11...\n",
      "Predicting validation set for Transformer Layer 11...\n",
      "Calculating correlations for Transformer Layer 11...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 19004/19004 [00:16<00:00, 1129.33it/s]\n",
      "100%|| 20544/20544 [00:18<00:00, 1135.21it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating median correlation with ROIs for Transformer Layer 11...\n",
      "> Transformer Layer 12\n",
      "Fitting PCA model for Transformer Layer 12...\n",
      "Fitting linear regression models for Transformer Layer 12...\n",
      "Transforming validation features for Transformer Layer 12...\n",
      "Predicting validation set for Transformer Layer 12...\n",
      "Calculating correlations for Transformer Layer 12...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 19004/19004 [00:16<00:00, 1129.65it/s]\n",
      "100%|| 20544/20544 [00:18<00:00, 1099.26it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating median correlation with ROIs for Transformer Layer 12...\n",
      "> Final Layer\n",
      "Fitting PCA model for Final Layer...\n",
      "Fitting linear regression models for Final Layer...\n",
      "Transforming validation features for Final Layer...\n",
      "Predicting validation set for Final Layer...\n",
      "Calculating correlations for Final Layer...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 19004/19004 [00:16<00:00, 1152.10it/s]\n",
      "100%|| 20544/20544 [00:17<00:00, 1143.72it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating median correlation with ROIs for Final Layer...\n",
      "#############################################\n",
      "# Fold: 4/ 8\n",
      "# Train size: 8611\n",
      "# Validation size: 1230\n",
      "#############################################\n",
      "> Embedding Layer\n",
      "Fitting PCA model for Embedding Layer...\n",
      "Fitting linear regression models for Embedding Layer...\n",
      "Transforming validation features for Embedding Layer...\n",
      "Predicting validation set for Embedding Layer...\n",
      "Calculating correlations for Embedding Layer...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 19004/19004 [00:16<00:00, 1134.03it/s]\n",
      "100%|| 20544/20544 [00:18<00:00, 1131.73it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating median correlation with ROIs for Embedding Layer...\n",
      "> Transformer Layer 1\n",
      "Fitting PCA model for Transformer Layer 1...\n",
      "Fitting linear regression models for Transformer Layer 1...\n",
      "Transforming validation features for Transformer Layer 1...\n",
      "Predicting validation set for Transformer Layer 1...\n",
      "Calculating correlations for Transformer Layer 1...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 19004/19004 [00:16<00:00, 1141.37it/s]\n",
      "100%|| 20544/20544 [00:18<00:00, 1129.44it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating median correlation with ROIs for Transformer Layer 1...\n",
      "> Transformer Layer 2\n",
      "Fitting PCA model for Transformer Layer 2...\n",
      "Fitting linear regression models for Transformer Layer 2...\n",
      "Transforming validation features for Transformer Layer 2...\n",
      "Predicting validation set for Transformer Layer 2...\n",
      "Calculating correlations for Transformer Layer 2...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 19004/19004 [00:16<00:00, 1149.70it/s]\n",
      "100%|| 20544/20544 [00:17<00:00, 1176.11it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating median correlation with ROIs for Transformer Layer 2...\n",
      "> Transformer Layer 3\n",
      "Fitting PCA model for Transformer Layer 3...\n",
      "Fitting linear regression models for Transformer Layer 3...\n",
      "Transforming validation features for Transformer Layer 3...\n",
      "Predicting validation set for Transformer Layer 3...\n",
      "Calculating correlations for Transformer Layer 3...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 19004/19004 [00:16<00:00, 1128.03it/s]\n",
      "100%|| 20544/20544 [00:18<00:00, 1133.24it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating median correlation with ROIs for Transformer Layer 3...\n",
      "> Transformer Layer 4\n",
      "Fitting PCA model for Transformer Layer 4...\n",
      "Fitting linear regression models for Transformer Layer 4...\n",
      "Transforming validation features for Transformer Layer 4...\n",
      "Predicting validation set for Transformer Layer 4...\n",
      "Calculating correlations for Transformer Layer 4...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 19004/19004 [00:17<00:00, 1087.01it/s]\n",
      "100%|| 20544/20544 [00:18<00:00, 1122.84it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating median correlation with ROIs for Transformer Layer 4...\n",
      "> Transformer Layer 5\n",
      "Fitting PCA model for Transformer Layer 5...\n",
      "Fitting linear regression models for Transformer Layer 5...\n",
      "Transforming validation features for Transformer Layer 5...\n",
      "Predicting validation set for Transformer Layer 5...\n",
      "Calculating correlations for Transformer Layer 5...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 19004/19004 [00:16<00:00, 1127.95it/s]\n",
      "100%|| 20544/20544 [00:18<00:00, 1133.79it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating median correlation with ROIs for Transformer Layer 5...\n",
      "> Transformer Layer 6\n",
      "Fitting PCA model for Transformer Layer 6...\n",
      "Fitting linear regression models for Transformer Layer 6...\n",
      "Transforming validation features for Transformer Layer 6...\n",
      "Predicting validation set for Transformer Layer 6...\n",
      "Calculating correlations for Transformer Layer 6...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 19004/19004 [00:16<00:00, 1128.09it/s]\n",
      "100%|| 20544/20544 [00:18<00:00, 1123.97it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating median correlation with ROIs for Transformer Layer 6...\n",
      "> Transformer Layer 7\n",
      "Fitting PCA model for Transformer Layer 7...\n",
      "Fitting linear regression models for Transformer Layer 7...\n",
      "Transforming validation features for Transformer Layer 7...\n",
      "Predicting validation set for Transformer Layer 7...\n",
      "Calculating correlations for Transformer Layer 7...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 19004/19004 [00:16<00:00, 1127.60it/s]\n",
      "100%|| 20544/20544 [00:18<00:00, 1126.70it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating median correlation with ROIs for Transformer Layer 7...\n",
      "> Transformer Layer 8\n",
      "Fitting PCA model for Transformer Layer 8...\n",
      "Fitting linear regression models for Transformer Layer 8...\n",
      "Transforming validation features for Transformer Layer 8...\n",
      "Predicting validation set for Transformer Layer 8...\n",
      "Calculating correlations for Transformer Layer 8...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 19004/19004 [00:17<00:00, 1076.11it/s]\n",
      "100%|| 20544/20544 [00:18<00:00, 1085.98it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating median correlation with ROIs for Transformer Layer 8...\n",
      "> Transformer Layer 9\n",
      "Fitting PCA model for Transformer Layer 9...\n",
      "Fitting linear regression models for Transformer Layer 9...\n",
      "Transforming validation features for Transformer Layer 9...\n",
      "Predicting validation set for Transformer Layer 9...\n",
      "Calculating correlations for Transformer Layer 9...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 19004/19004 [00:16<00:00, 1135.27it/s]\n",
      "100%|| 20544/20544 [00:18<00:00, 1129.26it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating median correlation with ROIs for Transformer Layer 9...\n",
      "> Transformer Layer 10\n",
      "Fitting PCA model for Transformer Layer 10...\n",
      "Fitting linear regression models for Transformer Layer 10...\n",
      "Transforming validation features for Transformer Layer 10...\n",
      "Predicting validation set for Transformer Layer 10...\n",
      "Calculating correlations for Transformer Layer 10...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 19004/19004 [00:16<00:00, 1134.48it/s]\n",
      "100%|| 20544/20544 [00:18<00:00, 1122.20it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating median correlation with ROIs for Transformer Layer 10...\n",
      "> Transformer Layer 11\n",
      "Fitting PCA model for Transformer Layer 11...\n",
      "Fitting linear regression models for Transformer Layer 11...\n",
      "Transforming validation features for Transformer Layer 11...\n",
      "Predicting validation set for Transformer Layer 11...\n",
      "Calculating correlations for Transformer Layer 11...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 19004/19004 [00:16<00:00, 1131.71it/s]\n",
      "100%|| 20544/20544 [00:18<00:00, 1133.67it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating median correlation with ROIs for Transformer Layer 11...\n",
      "> Transformer Layer 12\n",
      "Fitting PCA model for Transformer Layer 12...\n",
      "Fitting linear regression models for Transformer Layer 12...\n",
      "Transforming validation features for Transformer Layer 12...\n",
      "Predicting validation set for Transformer Layer 12...\n",
      "Calculating correlations for Transformer Layer 12...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 19004/19004 [00:16<00:00, 1127.26it/s]\n",
      "100%|| 20544/20544 [00:18<00:00, 1115.57it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating median correlation with ROIs for Transformer Layer 12...\n",
      "> Final Layer\n",
      "Fitting PCA model for Final Layer...\n",
      "Fitting linear regression models for Final Layer...\n",
      "Transforming validation features for Final Layer...\n",
      "Predicting validation set for Final Layer...\n",
      "Calculating correlations for Final Layer...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 19004/19004 [00:16<00:00, 1129.80it/s]\n",
      "100%|| 20544/20544 [00:18<00:00, 1114.49it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating median correlation with ROIs for Final Layer...\n",
      "#############################################\n",
      "# Fold: 5/ 8\n",
      "# Train size: 8611\n",
      "# Validation size: 1230\n",
      "#############################################\n",
      "> Embedding Layer\n",
      "Fitting PCA model for Embedding Layer...\n",
      "Fitting linear regression models for Embedding Layer...\n",
      "Transforming validation features for Embedding Layer...\n",
      "Predicting validation set for Embedding Layer...\n",
      "Calculating correlations for Embedding Layer...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 19004/19004 [00:16<00:00, 1173.71it/s]\n",
      "100%|| 20544/20544 [00:17<00:00, 1155.54it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating median correlation with ROIs for Embedding Layer...\n",
      "> Transformer Layer 1\n",
      "Fitting PCA model for Transformer Layer 1...\n",
      "Fitting linear regression models for Transformer Layer 1...\n",
      "Transforming validation features for Transformer Layer 1...\n",
      "Predicting validation set for Transformer Layer 1...\n",
      "Calculating correlations for Transformer Layer 1...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 19004/19004 [00:16<00:00, 1158.68it/s]\n",
      "100%|| 20544/20544 [00:17<00:00, 1165.16it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating median correlation with ROIs for Transformer Layer 1...\n",
      "> Transformer Layer 2\n",
      "Fitting PCA model for Transformer Layer 2...\n",
      "Fitting linear regression models for Transformer Layer 2...\n",
      "Transforming validation features for Transformer Layer 2...\n",
      "Predicting validation set for Transformer Layer 2...\n",
      "Calculating correlations for Transformer Layer 2...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 19004/19004 [00:16<00:00, 1122.14it/s]\n",
      "100%|| 20544/20544 [00:18<00:00, 1120.16it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating median correlation with ROIs for Transformer Layer 2...\n",
      "> Transformer Layer 3\n",
      "Fitting PCA model for Transformer Layer 3...\n",
      "Fitting linear regression models for Transformer Layer 3...\n",
      "Transforming validation features for Transformer Layer 3...\n",
      "Predicting validation set for Transformer Layer 3...\n",
      "Calculating correlations for Transformer Layer 3...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 19004/19004 [00:16<00:00, 1121.62it/s]\n",
      "100%|| 20544/20544 [00:18<00:00, 1135.05it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating median correlation with ROIs for Transformer Layer 3...\n",
      "> Transformer Layer 4\n",
      "Fitting PCA model for Transformer Layer 4...\n",
      "Fitting linear regression models for Transformer Layer 4...\n",
      "Transforming validation features for Transformer Layer 4...\n",
      "Predicting validation set for Transformer Layer 4...\n",
      "Calculating correlations for Transformer Layer 4...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 19004/19004 [00:17<00:00, 1100.34it/s]\n",
      "100%|| 20544/20544 [00:18<00:00, 1130.28it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating median correlation with ROIs for Transformer Layer 4...\n",
      "> Transformer Layer 5\n",
      "Fitting PCA model for Transformer Layer 5...\n",
      "Fitting linear regression models for Transformer Layer 5...\n",
      "Transforming validation features for Transformer Layer 5...\n",
      "Predicting validation set for Transformer Layer 5...\n",
      "Calculating correlations for Transformer Layer 5...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 19004/19004 [00:16<00:00, 1129.69it/s]\n",
      "100%|| 20544/20544 [00:18<00:00, 1137.27it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating median correlation with ROIs for Transformer Layer 5...\n",
      "> Transformer Layer 6\n",
      "Fitting PCA model for Transformer Layer 6...\n",
      "Fitting linear regression models for Transformer Layer 6...\n",
      "Transforming validation features for Transformer Layer 6...\n",
      "Predicting validation set for Transformer Layer 6...\n",
      "Calculating correlations for Transformer Layer 6...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 19004/19004 [00:16<00:00, 1134.78it/s]\n",
      "100%|| 20544/20544 [00:18<00:00, 1135.98it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating median correlation with ROIs for Transformer Layer 6...\n",
      "> Transformer Layer 7\n",
      "Fitting PCA model for Transformer Layer 7...\n",
      "Fitting linear regression models for Transformer Layer 7...\n",
      "Transforming validation features for Transformer Layer 7...\n",
      "Predicting validation set for Transformer Layer 7...\n",
      "Calculating correlations for Transformer Layer 7...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 19004/19004 [00:16<00:00, 1122.92it/s]\n",
      "100%|| 20544/20544 [00:18<00:00, 1135.17it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating median correlation with ROIs for Transformer Layer 7...\n",
      "> Transformer Layer 8\n",
      "Fitting PCA model for Transformer Layer 8...\n",
      "Fitting linear regression models for Transformer Layer 8...\n",
      "Transforming validation features for Transformer Layer 8...\n",
      "Predicting validation set for Transformer Layer 8...\n",
      "Calculating correlations for Transformer Layer 8...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 19004/19004 [00:16<00:00, 1147.16it/s]\n",
      "100%|| 20544/20544 [00:18<00:00, 1123.59it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating median correlation with ROIs for Transformer Layer 8...\n",
      "> Transformer Layer 9\n",
      "Fitting PCA model for Transformer Layer 9...\n",
      "Fitting linear regression models for Transformer Layer 9...\n",
      "Transforming validation features for Transformer Layer 9...\n",
      "Predicting validation set for Transformer Layer 9...\n",
      "Calculating correlations for Transformer Layer 9...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 19004/19004 [00:16<00:00, 1132.96it/s]\n",
      "100%|| 20544/20544 [00:18<00:00, 1127.72it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating median correlation with ROIs for Transformer Layer 9...\n",
      "> Transformer Layer 10\n",
      "Fitting PCA model for Transformer Layer 10...\n",
      "Fitting linear regression models for Transformer Layer 10...\n",
      "Transforming validation features for Transformer Layer 10...\n",
      "Predicting validation set for Transformer Layer 10...\n",
      "Calculating correlations for Transformer Layer 10...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 19004/19004 [00:17<00:00, 1115.79it/s]\n",
      "100%|| 20544/20544 [00:18<00:00, 1125.12it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating median correlation with ROIs for Transformer Layer 10...\n",
      "> Transformer Layer 11\n",
      "Fitting PCA model for Transformer Layer 11...\n",
      "Fitting linear regression models for Transformer Layer 11...\n",
      "Transforming validation features for Transformer Layer 11...\n",
      "Predicting validation set for Transformer Layer 11...\n",
      "Calculating correlations for Transformer Layer 11...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 19004/19004 [00:16<00:00, 1136.57it/s]\n",
      "100%|| 20544/20544 [00:18<00:00, 1129.93it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating median correlation with ROIs for Transformer Layer 11...\n",
      "> Transformer Layer 12\n",
      "Fitting PCA model for Transformer Layer 12...\n",
      "Fitting linear regression models for Transformer Layer 12...\n",
      "Transforming validation features for Transformer Layer 12...\n",
      "Predicting validation set for Transformer Layer 12...\n",
      "Calculating correlations for Transformer Layer 12...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 19004/19004 [00:16<00:00, 1136.15it/s]\n",
      "100%|| 20544/20544 [00:18<00:00, 1125.53it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating median correlation with ROIs for Transformer Layer 12...\n",
      "> Final Layer\n",
      "Fitting PCA model for Final Layer...\n",
      "Fitting linear regression models for Final Layer...\n",
      "Transforming validation features for Final Layer...\n",
      "Predicting validation set for Final Layer...\n",
      "Calculating correlations for Final Layer...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 19004/19004 [00:16<00:00, 1122.08it/s]\n",
      "100%|| 20544/20544 [00:18<00:00, 1137.36it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating median correlation with ROIs for Final Layer...\n",
      "#############################################\n",
      "# Fold: 6/ 8\n",
      "# Train size: 8611\n",
      "# Validation size: 1230\n",
      "#############################################\n",
      "> Embedding Layer\n",
      "Fitting PCA model for Embedding Layer...\n",
      "Fitting linear regression models for Embedding Layer...\n",
      "Transforming validation features for Embedding Layer...\n",
      "Predicting validation set for Embedding Layer...\n",
      "Calculating correlations for Embedding Layer...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 19004/19004 [00:16<00:00, 1147.58it/s]\n",
      "100%|| 20544/20544 [00:17<00:00, 1150.56it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating median correlation with ROIs for Embedding Layer...\n",
      "> Transformer Layer 1\n",
      "Fitting PCA model for Transformer Layer 1...\n",
      "Fitting linear regression models for Transformer Layer 1...\n",
      "Transforming validation features for Transformer Layer 1...\n",
      "Predicting validation set for Transformer Layer 1...\n",
      "Calculating correlations for Transformer Layer 1...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 19004/19004 [00:16<00:00, 1171.14it/s]\n",
      "100%|| 20544/20544 [00:17<00:00, 1164.49it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating median correlation with ROIs for Transformer Layer 1...\n",
      "> Transformer Layer 2\n",
      "Fitting PCA model for Transformer Layer 2...\n",
      "Fitting linear regression models for Transformer Layer 2...\n",
      "Transforming validation features for Transformer Layer 2...\n",
      "Predicting validation set for Transformer Layer 2...\n",
      "Calculating correlations for Transformer Layer 2...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 19004/19004 [00:16<00:00, 1149.85it/s]\n",
      "100%|| 20544/20544 [00:17<00:00, 1169.86it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating median correlation with ROIs for Transformer Layer 2...\n",
      "> Transformer Layer 3\n",
      "Fitting PCA model for Transformer Layer 3...\n",
      "Fitting linear regression models for Transformer Layer 3...\n",
      "Transforming validation features for Transformer Layer 3...\n",
      "Predicting validation set for Transformer Layer 3...\n",
      "Calculating correlations for Transformer Layer 3...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 19004/19004 [00:16<00:00, 1165.39it/s]\n",
      "100%|| 20544/20544 [00:17<00:00, 1155.82it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating median correlation with ROIs for Transformer Layer 3...\n",
      "> Transformer Layer 4\n",
      "Fitting PCA model for Transformer Layer 4...\n",
      "Fitting linear regression models for Transformer Layer 4...\n",
      "Transforming validation features for Transformer Layer 4...\n",
      "Predicting validation set for Transformer Layer 4...\n",
      "Calculating correlations for Transformer Layer 4...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 19004/19004 [00:16<00:00, 1148.84it/s]\n",
      "100%|| 20544/20544 [00:17<00:00, 1163.21it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating median correlation with ROIs for Transformer Layer 4...\n",
      "> Transformer Layer 5\n",
      "Fitting PCA model for Transformer Layer 5...\n",
      "Fitting linear regression models for Transformer Layer 5...\n",
      "Transforming validation features for Transformer Layer 5...\n",
      "Predicting validation set for Transformer Layer 5...\n",
      "Calculating correlations for Transformer Layer 5...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 19004/19004 [00:16<00:00, 1139.64it/s]\n",
      "100%|| 20544/20544 [00:18<00:00, 1120.52it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating median correlation with ROIs for Transformer Layer 5...\n",
      "> Transformer Layer 6\n",
      "Fitting PCA model for Transformer Layer 6...\n",
      "Fitting linear regression models for Transformer Layer 6...\n",
      "Transforming validation features for Transformer Layer 6...\n",
      "Predicting validation set for Transformer Layer 6...\n",
      "Calculating correlations for Transformer Layer 6...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 19004/19004 [00:16<00:00, 1136.08it/s]\n",
      "100%|| 20544/20544 [00:18<00:00, 1135.45it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating median correlation with ROIs for Transformer Layer 6...\n",
      "> Transformer Layer 7\n",
      "Fitting PCA model for Transformer Layer 7...\n",
      "Fitting linear regression models for Transformer Layer 7...\n",
      "Transforming validation features for Transformer Layer 7...\n",
      "Predicting validation set for Transformer Layer 7...\n",
      "Calculating correlations for Transformer Layer 7...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 19004/19004 [00:16<00:00, 1134.81it/s]\n",
      "100%|| 20544/20544 [00:18<00:00, 1128.42it/s]\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\luke-\\Desktop\\Python Repositories\\algonauts-2023\\.conda\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating median correlation with ROIs for Transformer Layer 7...\n",
      "> Transformer Layer 8\n",
      "Fitting PCA model for Transformer Layer 8...\n",
      "Fitting linear regression models for Transformer Layer 8...\n",
      "Transforming validation features for Transformer Layer 8...\n",
      "Predicting validation set for Transformer Layer 8...\n",
      "Calculating correlations for Transformer Layer 8...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 19004/19004 [00:16<00:00, 1137.07it/s]\n",
      " 52%|    | 10660/20544 [00:09<00:08, 1131.50it/s]"
     ]
    }
   ],
   "source": [
    "kfold.run()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the Kfold procedure the mean correlations across all folds are plotted for each layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luke-\\AppData\\Local\\Temp\\ipykernel_12384\\3314571769.py:69: RuntimeWarning: Mean of empty slice\n",
      "  self.mean_correlations[layer][hemi] = np.nanmean([self.fold_correlations[fold][layer][hemi] for fold in range(self.folds)], axis=0)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "kfold.plot_results()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
